{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ahmed\\anaconda3\\envs\\vstp\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No CUDA runtime is found, using CUDA_HOME='C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.7'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "# # Inside the /Multimodal-Deep-Regression/notebooks\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from util.utilities import train, evaluate, get_device\n",
    "from util.data_utilities import  process_data, get_train_and_val_loader\n",
    "\n",
    "# import all the models from models module\n",
    "from models import Swin_Transformer\n",
    "# from util.video_swin_transformer import SwinTransformer3D\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "import warnings\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "EXTRACT_DATA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT_DATA:\n",
    "    # # Data inputs for CNN and Swin Transformer baseline\n",
    "    # disable pyav warning\n",
    "    warnings.filterwarnings(\"ignore\", message=\"Accurate seek is not implemented for pyav backend\")\n",
    "    process_data(\n",
    "        input_type='video_pack_1000_swin', \n",
    "        # addition_parameters={'first_n_videos': 10}, \n",
    "        verbose=False,\n",
    "        device=get_device(),\n",
    "        skip_frames=True,\n",
    "        frames_to_skip=200,\n",
    "        resize_tensors=True,\n",
    "        uniform_frames=True,\n",
    "        set_frame_count=20,\n",
    "        shrink=8,\n",
    "        clean_dir=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using device: cpu\n",
      "torch.Size([3, 20, 128, 72])\n",
      "torch.Size([3, 20, 128, 72])\n",
      "800\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "device = get_device()\n",
    "train_loader, val_loader = get_train_and_val_loader(\n",
    "    input_type='video_pack_1000_swin',\n",
    "    batch_size=15,\n",
    "    verbose=True,\n",
    "    # tensor_upper_limit=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swin_Transformer_model(\n",
      "  (swin_transformer): SwinTransformer3D(\n",
      "    (patch_embed): PatchEmbed3D(\n",
      "      (proj): Conv3d(3, 96, kernel_size=(4, 4, 4), stride=(4, 4, 4))\n",
      "      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.1, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): SwinTransformerBlock3D(\n",
      "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention3D(\n",
      "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "              (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (drop): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): SwinTransformerBlock3D(\n",
      "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention3D(\n",
      "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "              (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.018)\n",
      "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (drop): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchMerging(\n",
      "          (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
      "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): SwinTransformerBlock3D(\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention3D(\n",
      "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.036)\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): SwinTransformerBlock3D(\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention3D(\n",
      "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.055)\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchMerging(\n",
      "          (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
      "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (2): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): SwinTransformerBlock3D(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention3D(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.073)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): SwinTransformerBlock3D(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention3D(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.091)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): SwinTransformerBlock3D(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention3D(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.109)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): SwinTransformerBlock3D(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention3D(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.127)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): SwinTransformerBlock3D(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention3D(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.145)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): SwinTransformerBlock3D(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention3D(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.164)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchMerging(\n",
      "          (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
      "          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (3): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): SwinTransformerBlock3D(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention3D(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.182)\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): SwinTransformerBlock3D(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention3D(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.200)\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (relu): ReLU()\n",
      "  (linear1): Linear(in_features=46080, out_features=1, bias=True)\n",
      ")\n",
      "Total parameters: 27,625,903\n",
      "Adjusting learning rate of group 0 to 3.3333e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ahmed\\anaconda3\\envs\\vstp\\Lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# linear_in_dim work for default network with frames input uniform at 100 and HxW at 1024x576\n",
    "# model = Swin_Transformer.Swin_Transformer_model(linear_in_dim=768*25*32*18)\n",
    "# linear_in_dim work for default network with frames input uniform at 15 and HxW at 128x72\n",
    "model = Swin_Transformer.Swin_Transformer_model(\n",
    "    # patch_size=(2,2,2), \n",
    "    # num_heads=[6, 12, 24, 48],\n",
    "    # depths=[4, 4, 12, 4],\n",
    "    drop_rate=0.1,\n",
    "    patch_norm=True,\n",
    "    linear_in_dim=46080\n",
    ") # .train(mode=True)\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001,\n",
    "    weight_decay=0.0001)\n",
    "\n",
    "print(model)\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "\n",
    "scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1/3, total_iters=10, verbose=True)\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[93.3357],\n",
      "        [79.8821],\n",
      "        [99.1073],\n",
      "        [95.8779],\n",
      "        [88.0152],\n",
      "        [99.0959],\n",
      "        [97.6651],\n",
      "        [96.1470],\n",
      "        [98.9529],\n",
      "        [98.6774],\n",
      "        [98.9356],\n",
      "        [79.0990],\n",
      "        [98.8749],\n",
      "        [98.2003],\n",
      "        [90.4644]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  462.4000],\n",
      "        [ 2100.0000],\n",
      "        [  413.8000],\n",
      "        [  855.7000],\n",
      "        [ 7500.0000],\n",
      "        [ 7100.0000],\n",
      "        [ 3700.0000],\n",
      "        [ 1100.0000],\n",
      "        [10300.0000],\n",
      "        [ 9000.0000],\n",
      "        [ 1400.0000],\n",
      "        [ 2200.0000],\n",
      "        [ 2000.0000],\n",
      "        [  178.4000],\n",
      "        [ 1400.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[97.3332],\n",
      "        [80.1108],\n",
      "        [86.8978],\n",
      "        [89.6696],\n",
      "        [95.7811],\n",
      "        [97.7470],\n",
      "        [89.6225],\n",
      "        [98.8463],\n",
      "        [86.8877],\n",
      "        [88.4233],\n",
      "        [90.9735],\n",
      "        [84.9710],\n",
      "        [92.8271],\n",
      "        [99.1835],\n",
      "        [99.0089]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.5000e+03],\n",
      "        [3.7000e+03],\n",
      "        [4.0000e+03],\n",
      "        [5.8910e+02],\n",
      "        [1.3200e+01],\n",
      "        [1.4800e+04],\n",
      "        [1.8300e+01],\n",
      "        [1.0600e+04],\n",
      "        [6.8000e+03],\n",
      "        [6.6910e+02],\n",
      "        [9.9100e+01],\n",
      "        [4.5700e+01],\n",
      "        [7.6100e+03],\n",
      "        [1.3000e+03],\n",
      "        [4.7000e+03]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[79.4715],\n",
      "        [97.8625],\n",
      "        [87.5650],\n",
      "        [97.7512],\n",
      "        [80.1045],\n",
      "        [89.5241],\n",
      "        [97.4848],\n",
      "        [79.7787],\n",
      "        [97.5783],\n",
      "        [98.8275],\n",
      "        [98.8776],\n",
      "        [79.5226],\n",
      "        [96.6651],\n",
      "        [98.1991],\n",
      "        [98.0839]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[3200.0000],\n",
      "        [8900.0000],\n",
      "        [  14.6000],\n",
      "        [5200.0000],\n",
      "        [ 369.8000],\n",
      "        [2324.0000],\n",
      "        [ 626.9000],\n",
      "        [  10.5000],\n",
      "        [1800.0000],\n",
      "        [ 118.0000],\n",
      "        [4200.0000],\n",
      "        [  10.3000],\n",
      "        [2000.0000],\n",
      "        [2400.0000],\n",
      "        [4600.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[99.0152],\n",
      "        [98.6743],\n",
      "        [92.5962],\n",
      "        [97.2511],\n",
      "        [97.5838],\n",
      "        [79.8441],\n",
      "        [97.8835],\n",
      "        [93.3744],\n",
      "        [98.7177],\n",
      "        [78.0097],\n",
      "        [99.1096],\n",
      "        [99.0698],\n",
      "        [97.8256],\n",
      "        [87.0471],\n",
      "        [92.9004]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 6000.0000],\n",
      "        [ 3180.0000],\n",
      "        [ 1900.0000],\n",
      "        [  153.6000],\n",
      "        [  514.3000],\n",
      "        [ 6245.0000],\n",
      "        [ 1100.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 1300.0000],\n",
      "        [  319.8000],\n",
      "        [ 1100.0000],\n",
      "        [  285.7000],\n",
      "        [15100.0000],\n",
      "        [ 4900.0000],\n",
      "        [ 1000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[89.9574],\n",
      "        [97.7102],\n",
      "        [97.9918],\n",
      "        [79.5230],\n",
      "        [80.9159],\n",
      "        [92.9468],\n",
      "        [97.7407],\n",
      "        [95.1294],\n",
      "        [98.9296],\n",
      "        [80.8112],\n",
      "        [98.9110],\n",
      "        [98.0158],\n",
      "        [98.8143],\n",
      "        [99.0592],\n",
      "        [97.1210]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.9250e+03],\n",
      "        [3.8750e+02],\n",
      "        [8.5900e+01],\n",
      "        [2.2000e+03],\n",
      "        [4.1000e+03],\n",
      "        [9.4000e+03],\n",
      "        [1.0600e+01],\n",
      "        [2.5000e+03],\n",
      "        [2.6700e+01],\n",
      "        [1.7920e+02],\n",
      "        [1.1400e+04],\n",
      "        [7.0000e+01],\n",
      "        [1.3330e+02],\n",
      "        [9.7100e+02],\n",
      "        [8.2500e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[98.2314],\n",
      "        [81.8225],\n",
      "        [97.9049],\n",
      "        [97.4979],\n",
      "        [98.7330],\n",
      "        [97.3526],\n",
      "        [98.3177],\n",
      "        [98.0055],\n",
      "        [97.5163],\n",
      "        [97.8296],\n",
      "        [95.8349],\n",
      "        [89.3900],\n",
      "        [98.9055],\n",
      "        [98.8167],\n",
      "        [98.7662]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  177.4000],\n",
      "        [ 1600.0000],\n",
      "        [ 3000.0000],\n",
      "        [ 2300.0000],\n",
      "        [ 4000.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5700.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 1800.0000],\n",
      "        [11500.0000],\n",
      "        [ 8800.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 6542.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 5000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[88.6935],\n",
      "        [96.0540],\n",
      "        [98.9454],\n",
      "        [98.7965],\n",
      "        [88.8714],\n",
      "        [92.7453],\n",
      "        [97.0031],\n",
      "        [97.6892],\n",
      "        [98.1433],\n",
      "        [98.2671],\n",
      "        [86.9027],\n",
      "        [92.9535],\n",
      "        [98.8791],\n",
      "        [97.0092],\n",
      "        [90.7991]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[19400.0000],\n",
      "        [12500.0000],\n",
      "        [  959.8000],\n",
      "        [  360.8000],\n",
      "        [ 1500.0000],\n",
      "        [  470.5000],\n",
      "        [12800.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 4400.0000],\n",
      "        [ 2500.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5400.0000],\n",
      "        [ 8500.0000],\n",
      "        [ 4600.0000],\n",
      "        [  233.7000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[98.1677],\n",
      "        [98.6142],\n",
      "        [97.5172],\n",
      "        [98.6241],\n",
      "        [98.6843],\n",
      "        [98.7515],\n",
      "        [98.8195],\n",
      "        [98.9238],\n",
      "        [87.8315],\n",
      "        [97.9215],\n",
      "        [85.9413],\n",
      "        [97.9049],\n",
      "        [90.6979],\n",
      "        [98.5128],\n",
      "        [98.4735]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.8900e+04],\n",
      "        [1.5000e+03],\n",
      "        [7.5080e+02],\n",
      "        [8.5110e+03],\n",
      "        [6.7000e+03],\n",
      "        [4.0000e+04],\n",
      "        [1.0900e+01],\n",
      "        [5.0890e+03],\n",
      "        [6.9900e+01],\n",
      "        [3.0000e+03],\n",
      "        [6.3700e+01],\n",
      "        [1.8200e+04],\n",
      "        [2.3300e+04],\n",
      "        [7.2000e+03],\n",
      "        [7.2190e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[98.8079],\n",
      "        [93.2770],\n",
      "        [97.1361],\n",
      "        [97.8211],\n",
      "        [92.7834],\n",
      "        [88.4810],\n",
      "        [83.3163],\n",
      "        [98.2676],\n",
      "        [78.7391],\n",
      "        [98.8230],\n",
      "        [98.6262],\n",
      "        [98.4047],\n",
      "        [85.0958],\n",
      "        [81.3516],\n",
      "        [79.6723]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 1200.0000],\n",
      "        [  220.3000],\n",
      "        [ 2100.0000],\n",
      "        [ 1600.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 9800.0000],\n",
      "        [ 9800.0000],\n",
      "        [  233.4000],\n",
      "        [ 3600.0000],\n",
      "        [ 4100.0000],\n",
      "        [  604.7000],\n",
      "        [ 3885.0000],\n",
      "        [31500.0000],\n",
      "        [ 3200.0000],\n",
      "        [  794.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[98.6222],\n",
      "        [96.8617],\n",
      "        [92.7250],\n",
      "        [98.6112],\n",
      "        [97.3200],\n",
      "        [92.6328],\n",
      "        [96.2377],\n",
      "        [97.9401],\n",
      "        [87.7394],\n",
      "        [87.9057],\n",
      "        [81.7252],\n",
      "        [98.9391],\n",
      "        [79.9515],\n",
      "        [79.7947],\n",
      "        [97.5442]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.1000e+03],\n",
      "        [2.2000e+03],\n",
      "        [4.3000e+03],\n",
      "        [6.5100e+02],\n",
      "        [9.1700e+01],\n",
      "        [1.5000e+03],\n",
      "        [6.7000e+01],\n",
      "        [2.2600e+04],\n",
      "        [2.1000e+03],\n",
      "        [5.7000e+03],\n",
      "        [1.4600e+04],\n",
      "        [1.8700e+01],\n",
      "        [2.7000e+03],\n",
      "        [5.5000e+01],\n",
      "        [6.6330e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[96.3950],\n",
      "        [98.7570],\n",
      "        [87.3797],\n",
      "        [98.7152],\n",
      "        [91.4058],\n",
      "        [98.7100],\n",
      "        [80.5542],\n",
      "        [97.3805],\n",
      "        [86.8916],\n",
      "        [89.4531],\n",
      "        [98.8770],\n",
      "        [87.6083],\n",
      "        [98.2426],\n",
      "        [97.7724],\n",
      "        [86.5566]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.0600e+02],\n",
      "        [1.1000e+03],\n",
      "        [9.4450e+02],\n",
      "        [2.9000e+03],\n",
      "        [1.6400e+04],\n",
      "        [4.6000e+03],\n",
      "        [7.0700e+04],\n",
      "        [7.9800e+01],\n",
      "        [1.2100e+04],\n",
      "        [9.3000e+03],\n",
      "        [7.0000e+03],\n",
      "        [1.9000e+01],\n",
      "        [3.9000e+03],\n",
      "        [3.8000e+03],\n",
      "        [1.9700e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[98.8255],\n",
      "        [97.8871],\n",
      "        [97.7082],\n",
      "        [98.8057],\n",
      "        [98.8091],\n",
      "        [98.9001],\n",
      "        [97.4695],\n",
      "        [97.3716],\n",
      "        [92.9416],\n",
      "        [97.3112],\n",
      "        [97.8551],\n",
      "        [97.3104],\n",
      "        [98.1742],\n",
      "        [97.1507],\n",
      "        [87.2393]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.8000e+03],\n",
      "        [2.0000e+03],\n",
      "        [5.4980e+02],\n",
      "        [1.8700e+04],\n",
      "        [4.1300e+01],\n",
      "        [2.6450e+02],\n",
      "        [3.9000e+03],\n",
      "        [1.0450e+02],\n",
      "        [7.7000e+03],\n",
      "        [1.6000e+01],\n",
      "        [5.8340e+03],\n",
      "        [3.7000e+03],\n",
      "        [3.1360e+02],\n",
      "        [2.3000e+03],\n",
      "        [1.3300e+01]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[98.9036],\n",
      "        [98.2988],\n",
      "        [98.6552],\n",
      "        [97.3549],\n",
      "        [97.3446],\n",
      "        [98.5632],\n",
      "        [78.7470],\n",
      "        [95.8684],\n",
      "        [88.6315],\n",
      "        [94.1656],\n",
      "        [97.7570],\n",
      "        [97.7511],\n",
      "        [90.4780],\n",
      "        [89.0775],\n",
      "        [99.0659]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 315.3000],\n",
      "        [  25.5000],\n",
      "        [2100.0000],\n",
      "        [1000.0000],\n",
      "        [4942.0000],\n",
      "        [1700.0000],\n",
      "        [ 995.5000],\n",
      "        [3300.0000],\n",
      "        [ 114.9000],\n",
      "        [ 239.1000],\n",
      "        [  12.7000],\n",
      "        [6500.0000],\n",
      "        [ 196.2000],\n",
      "        [1100.0000],\n",
      "        [  75.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([5, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([5, 1])): tensor([[98.0715],\n",
      "        [97.8867],\n",
      "        [98.8091],\n",
      "        [98.7605],\n",
      "        [92.5431]])\n",
      "Target (shape: torch.Size([5, 1])): tensor([[1300.0000],\n",
      "        [ 370.3000],\n",
      "        [8947.0000],\n",
      "        [5217.0000],\n",
      "        [  38.7000]])\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "First epoch took 5.7 minutes.\n",
      "Epoch 1/20, Train_Loss: 394799.27, Avg: 7311.10; Val_Loss: 65075.84, Avg: 4648.27\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[184.4375],\n",
      "        [172.1098],\n",
      "        [189.8830],\n",
      "        [187.1269],\n",
      "        [176.1099],\n",
      "        [190.4509],\n",
      "        [189.5256],\n",
      "        [187.7979],\n",
      "        [190.5409],\n",
      "        [190.3269],\n",
      "        [190.2436],\n",
      "        [171.1300],\n",
      "        [190.5112],\n",
      "        [190.0355],\n",
      "        [179.4358]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  462.4000],\n",
      "        [ 2100.0000],\n",
      "        [  413.8000],\n",
      "        [  855.7000],\n",
      "        [ 7500.0000],\n",
      "        [ 7100.0000],\n",
      "        [ 3700.0000],\n",
      "        [ 1100.0000],\n",
      "        [10300.0000],\n",
      "        [ 9000.0000],\n",
      "        [ 1400.0000],\n",
      "        [ 2200.0000],\n",
      "        [ 2000.0000],\n",
      "        [  178.4000],\n",
      "        [ 1400.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[188.7666],\n",
      "        [171.3321],\n",
      "        [174.6424],\n",
      "        [179.3719],\n",
      "        [187.5980],\n",
      "        [189.5608],\n",
      "        [179.4049],\n",
      "        [190.4694],\n",
      "        [174.9561],\n",
      "        [176.5413],\n",
      "        [180.8435],\n",
      "        [177.3160],\n",
      "        [184.7327],\n",
      "        [190.3370],\n",
      "        [190.5177]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.5000e+03],\n",
      "        [3.7000e+03],\n",
      "        [4.0000e+03],\n",
      "        [5.8910e+02],\n",
      "        [1.3200e+01],\n",
      "        [1.4800e+04],\n",
      "        [1.8300e+01],\n",
      "        [1.0600e+04],\n",
      "        [6.8000e+03],\n",
      "        [6.6910e+02],\n",
      "        [9.9100e+01],\n",
      "        [4.5700e+01],\n",
      "        [7.6100e+03],\n",
      "        [1.3000e+03],\n",
      "        [4.7000e+03]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[171.5689],\n",
      "        [189.7380],\n",
      "        [175.6247],\n",
      "        [189.3163],\n",
      "        [172.3386],\n",
      "        [179.4710],\n",
      "        [189.0143],\n",
      "        [172.0547],\n",
      "        [189.3771],\n",
      "        [190.4924],\n",
      "        [190.4846],\n",
      "        [171.6135],\n",
      "        [188.4495],\n",
      "        [190.0167],\n",
      "        [190.1523]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[3200.0000],\n",
      "        [8900.0000],\n",
      "        [  14.6000],\n",
      "        [5200.0000],\n",
      "        [ 369.8000],\n",
      "        [2324.0000],\n",
      "        [ 626.9000],\n",
      "        [  10.5000],\n",
      "        [1800.0000],\n",
      "        [ 118.0000],\n",
      "        [4200.0000],\n",
      "        [  10.3000],\n",
      "        [2000.0000],\n",
      "        [2400.0000],\n",
      "        [4600.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[190.5169],\n",
      "        [190.3531],\n",
      "        [184.7103],\n",
      "        [188.6721],\n",
      "        [189.0721],\n",
      "        [172.0722],\n",
      "        [189.5418],\n",
      "        [185.4862],\n",
      "        [190.3881],\n",
      "        [170.2614],\n",
      "        [190.5238],\n",
      "        [190.2981],\n",
      "        [189.7008],\n",
      "        [179.1070],\n",
      "        [185.0536]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 6000.0000],\n",
      "        [ 3180.0000],\n",
      "        [ 1900.0000],\n",
      "        [  153.6000],\n",
      "        [  514.3000],\n",
      "        [ 6245.0000],\n",
      "        [ 1100.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 1300.0000],\n",
      "        [  319.8000],\n",
      "        [ 1100.0000],\n",
      "        [  285.7000],\n",
      "        [15100.0000],\n",
      "        [ 4900.0000],\n",
      "        [ 1000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[179.1039],\n",
      "        [189.5251],\n",
      "        [189.8481],\n",
      "        [171.6309],\n",
      "        [171.0663],\n",
      "        [183.1582],\n",
      "        [189.2932],\n",
      "        [186.5502],\n",
      "        [190.5432],\n",
      "        [173.2742],\n",
      "        [190.4966],\n",
      "        [189.8008],\n",
      "        [190.4748],\n",
      "        [190.4518],\n",
      "        [188.7258]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.9250e+03],\n",
      "        [3.8750e+02],\n",
      "        [8.5900e+01],\n",
      "        [2.2000e+03],\n",
      "        [4.1000e+03],\n",
      "        [9.4000e+03],\n",
      "        [1.0600e+01],\n",
      "        [2.5000e+03],\n",
      "        [2.6700e+01],\n",
      "        [1.7920e+02],\n",
      "        [1.1400e+04],\n",
      "        [7.0000e+01],\n",
      "        [1.3330e+02],\n",
      "        [9.7100e+02],\n",
      "        [8.2500e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[190.1665],\n",
      "        [172.8988],\n",
      "        [189.8412],\n",
      "        [188.9060],\n",
      "        [190.4112],\n",
      "        [189.1837],\n",
      "        [190.2741],\n",
      "        [189.7332],\n",
      "        [189.3540],\n",
      "        [189.4125],\n",
      "        [187.2749],\n",
      "        [178.6582],\n",
      "        [190.5130],\n",
      "        [190.4900],\n",
      "        [190.4245]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  177.4000],\n",
      "        [ 1600.0000],\n",
      "        [ 3000.0000],\n",
      "        [ 2300.0000],\n",
      "        [ 4000.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5700.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 1800.0000],\n",
      "        [11500.0000],\n",
      "        [ 8800.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 6542.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 5000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[177.9091],\n",
      "        [187.6057],\n",
      "        [190.5525],\n",
      "        [190.4647],\n",
      "        [177.8250],\n",
      "        [183.9734],\n",
      "        [188.8221],\n",
      "        [189.1207],\n",
      "        [189.9949],\n",
      "        [190.2074],\n",
      "        [174.9918],\n",
      "        [184.7598],\n",
      "        [190.5075],\n",
      "        [188.6586],\n",
      "        [180.1738]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[19400.0000],\n",
      "        [12500.0000],\n",
      "        [  959.8000],\n",
      "        [  360.8000],\n",
      "        [ 1500.0000],\n",
      "        [  470.5000],\n",
      "        [12800.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 4400.0000],\n",
      "        [ 2500.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5400.0000],\n",
      "        [ 8500.0000],\n",
      "        [ 4600.0000],\n",
      "        [  233.7000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[190.0185],\n",
      "        [190.3409],\n",
      "        [188.9695],\n",
      "        [190.3099],\n",
      "        [190.3665],\n",
      "        [190.3986],\n",
      "        [190.4873],\n",
      "        [190.5294],\n",
      "        [175.7984],\n",
      "        [189.8023],\n",
      "        [177.6538],\n",
      "        [189.8294],\n",
      "        [179.8280],\n",
      "        [190.2832],\n",
      "        [190.1875]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.8900e+04],\n",
      "        [1.5000e+03],\n",
      "        [7.5080e+02],\n",
      "        [8.5110e+03],\n",
      "        [6.7000e+03],\n",
      "        [4.0000e+04],\n",
      "        [1.0900e+01],\n",
      "        [5.0890e+03],\n",
      "        [6.9900e+01],\n",
      "        [3.0000e+03],\n",
      "        [6.3700e+01],\n",
      "        [1.8200e+04],\n",
      "        [2.3300e+04],\n",
      "        [7.2000e+03],\n",
      "        [7.2190e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[190.4928],\n",
      "        [185.9321],\n",
      "        [188.3694],\n",
      "        [189.6912],\n",
      "        [184.8746],\n",
      "        [177.1655],\n",
      "        [175.1200],\n",
      "        [189.9533],\n",
      "        [171.4127],\n",
      "        [190.4706],\n",
      "        [190.3508],\n",
      "        [190.2649],\n",
      "        [176.8599],\n",
      "        [172.5856],\n",
      "        [171.8193]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 1200.0000],\n",
      "        [  220.3000],\n",
      "        [ 2100.0000],\n",
      "        [ 1600.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 9800.0000],\n",
      "        [ 9800.0000],\n",
      "        [  233.4000],\n",
      "        [ 3600.0000],\n",
      "        [ 4100.0000],\n",
      "        [  604.7000],\n",
      "        [ 3885.0000],\n",
      "        [31500.0000],\n",
      "        [ 3200.0000],\n",
      "        [  794.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[190.4208],\n",
      "        [188.6642],\n",
      "        [184.7762],\n",
      "        [190.2422],\n",
      "        [188.7670],\n",
      "        [183.2592],\n",
      "        [187.9610],\n",
      "        [189.8457],\n",
      "        [175.6525],\n",
      "        [176.2187],\n",
      "        [172.8606],\n",
      "        [190.4904],\n",
      "        [172.2063],\n",
      "        [172.0079],\n",
      "        [189.0529]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.1000e+03],\n",
      "        [2.2000e+03],\n",
      "        [4.3000e+03],\n",
      "        [6.5100e+02],\n",
      "        [9.1700e+01],\n",
      "        [1.5000e+03],\n",
      "        [6.7000e+01],\n",
      "        [2.2600e+04],\n",
      "        [2.1000e+03],\n",
      "        [5.7000e+03],\n",
      "        [1.4600e+04],\n",
      "        [1.8700e+01],\n",
      "        [2.7000e+03],\n",
      "        [5.5000e+01],\n",
      "        [6.6330e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[187.2640],\n",
      "        [190.4604],\n",
      "        [175.5600],\n",
      "        [190.4080],\n",
      "        [180.2352],\n",
      "        [190.3677],\n",
      "        [172.8017],\n",
      "        [188.8303],\n",
      "        [174.9723],\n",
      "        [176.8941],\n",
      "        [190.4467],\n",
      "        [175.3158],\n",
      "        [190.1555],\n",
      "        [189.3269],\n",
      "        [174.2622]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.0600e+02],\n",
      "        [1.1000e+03],\n",
      "        [9.4450e+02],\n",
      "        [2.9000e+03],\n",
      "        [1.6400e+04],\n",
      "        [4.6000e+03],\n",
      "        [7.0700e+04],\n",
      "        [7.9800e+01],\n",
      "        [1.2100e+04],\n",
      "        [9.3000e+03],\n",
      "        [7.0000e+03],\n",
      "        [1.9000e+01],\n",
      "        [3.9000e+03],\n",
      "        [3.8000e+03],\n",
      "        [1.9700e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[190.5237],\n",
      "        [189.7410],\n",
      "        [189.2754],\n",
      "        [190.4219],\n",
      "        [190.4948],\n",
      "        [190.5334],\n",
      "        [188.8035],\n",
      "        [189.2966],\n",
      "        [185.2221],\n",
      "        [188.7110],\n",
      "        [189.7196],\n",
      "        [188.7406],\n",
      "        [190.0798],\n",
      "        [189.2693],\n",
      "        [175.1827]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.8000e+03],\n",
      "        [2.0000e+03],\n",
      "        [5.4980e+02],\n",
      "        [1.8700e+04],\n",
      "        [4.1300e+01],\n",
      "        [2.6450e+02],\n",
      "        [3.9000e+03],\n",
      "        [1.0450e+02],\n",
      "        [7.7000e+03],\n",
      "        [1.6000e+01],\n",
      "        [5.8340e+03],\n",
      "        [3.7000e+03],\n",
      "        [3.1360e+02],\n",
      "        [2.3000e+03],\n",
      "        [1.3300e+01]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[190.5231],\n",
      "        [190.1173],\n",
      "        [189.5742],\n",
      "        [188.7574],\n",
      "        [188.7146],\n",
      "        [190.2678],\n",
      "        [170.4950],\n",
      "        [187.1344],\n",
      "        [180.1606],\n",
      "        [186.0544],\n",
      "        [189.7806],\n",
      "        [189.3121],\n",
      "        [179.5310],\n",
      "        [179.2829],\n",
      "        [190.5089]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 315.3000],\n",
      "        [  25.5000],\n",
      "        [2100.0000],\n",
      "        [1000.0000],\n",
      "        [4942.0000],\n",
      "        [1700.0000],\n",
      "        [ 995.5000],\n",
      "        [3300.0000],\n",
      "        [ 114.9000],\n",
      "        [ 239.1000],\n",
      "        [  12.7000],\n",
      "        [6500.0000],\n",
      "        [ 196.2000],\n",
      "        [1100.0000],\n",
      "        [  75.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([5, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([5, 1])): tensor([[189.8876],\n",
      "        [189.7274],\n",
      "        [190.3335],\n",
      "        [190.4183],\n",
      "        [181.9495]])\n",
      "Target (shape: torch.Size([5, 1])): tensor([[1300.0000],\n",
      "        [ 370.3000],\n",
      "        [8947.0000],\n",
      "        [5217.0000],\n",
      "        [  38.7000]])\n",
      "Adjusting learning rate of group 0 to 4.6667e-05.\n",
      "Epoch 2/20, Train_Loss: 423595.08, Avg: 7844.35; Val_Loss: 64194.20, Avg: 4585.30\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[290.0591],\n",
      "        [279.6944],\n",
      "        [293.6646],\n",
      "        [292.1565],\n",
      "        [283.8987],\n",
      "        [293.7544],\n",
      "        [293.4098],\n",
      "        [291.2790],\n",
      "        [293.7892],\n",
      "        [293.6287],\n",
      "        [293.7280],\n",
      "        [279.7700],\n",
      "        [293.8615],\n",
      "        [293.8601],\n",
      "        [289.0593]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  462.4000],\n",
      "        [ 2100.0000],\n",
      "        [  413.8000],\n",
      "        [  855.7000],\n",
      "        [ 7500.0000],\n",
      "        [ 7100.0000],\n",
      "        [ 3700.0000],\n",
      "        [ 1100.0000],\n",
      "        [10300.0000],\n",
      "        [ 9000.0000],\n",
      "        [ 1400.0000],\n",
      "        [ 2200.0000],\n",
      "        [ 2000.0000],\n",
      "        [  178.4000],\n",
      "        [ 1400.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[292.8593],\n",
      "        [278.7280],\n",
      "        [282.9266],\n",
      "        [290.2440],\n",
      "        [291.1725],\n",
      "        [293.7304],\n",
      "        [290.4342],\n",
      "        [293.7595],\n",
      "        [284.2350],\n",
      "        [289.3561],\n",
      "        [287.8453],\n",
      "        [282.4627],\n",
      "        [291.6390],\n",
      "        [293.8057],\n",
      "        [293.7598]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.5000e+03],\n",
      "        [3.7000e+03],\n",
      "        [4.0000e+03],\n",
      "        [5.8910e+02],\n",
      "        [1.3200e+01],\n",
      "        [1.4800e+04],\n",
      "        [1.8300e+01],\n",
      "        [1.0600e+04],\n",
      "        [6.8000e+03],\n",
      "        [6.6910e+02],\n",
      "        [9.9100e+01],\n",
      "        [4.5700e+01],\n",
      "        [7.6100e+03],\n",
      "        [1.3000e+03],\n",
      "        [4.7000e+03]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[279.2249],\n",
      "        [293.7867],\n",
      "        [284.3426],\n",
      "        [293.4219],\n",
      "        [279.5228],\n",
      "        [290.3590],\n",
      "        [293.1978],\n",
      "        [280.0041],\n",
      "        [293.5361],\n",
      "        [293.7877],\n",
      "        [293.8353],\n",
      "        [279.5143],\n",
      "        [291.7879],\n",
      "        [293.8104],\n",
      "        [293.7778]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[3200.0000],\n",
      "        [8900.0000],\n",
      "        [  14.6000],\n",
      "        [5200.0000],\n",
      "        [ 369.8000],\n",
      "        [2324.0000],\n",
      "        [ 626.9000],\n",
      "        [  10.5000],\n",
      "        [1800.0000],\n",
      "        [ 118.0000],\n",
      "        [4200.0000],\n",
      "        [  10.3000],\n",
      "        [2000.0000],\n",
      "        [2400.0000],\n",
      "        [4600.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[293.8803],\n",
      "        [293.5971],\n",
      "        [291.5783],\n",
      "        [292.7829],\n",
      "        [293.1829],\n",
      "        [279.7668],\n",
      "        [293.5461],\n",
      "        [291.7397],\n",
      "        [293.8348],\n",
      "        [279.3629],\n",
      "        [293.7302],\n",
      "        [293.7636],\n",
      "        [293.7540],\n",
      "        [284.9116],\n",
      "        [291.7285]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 6000.0000],\n",
      "        [ 3180.0000],\n",
      "        [ 1900.0000],\n",
      "        [  153.6000],\n",
      "        [  514.3000],\n",
      "        [ 6245.0000],\n",
      "        [ 1100.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 1300.0000],\n",
      "        [  319.8000],\n",
      "        [ 1100.0000],\n",
      "        [  285.7000],\n",
      "        [15100.0000],\n",
      "        [ 4900.0000],\n",
      "        [ 1000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[286.9432],\n",
      "        [293.7072],\n",
      "        [293.7854],\n",
      "        [279.6320],\n",
      "        [277.8453],\n",
      "        [290.2992],\n",
      "        [293.3260],\n",
      "        [290.9540],\n",
      "        [293.8194],\n",
      "        [279.1821],\n",
      "        [293.8264],\n",
      "        [293.1258],\n",
      "        [293.7681],\n",
      "        [293.8051],\n",
      "        [292.4171]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.9250e+03],\n",
      "        [3.8750e+02],\n",
      "        [8.5900e+01],\n",
      "        [2.2000e+03],\n",
      "        [4.1000e+03],\n",
      "        [9.4000e+03],\n",
      "        [1.0600e+01],\n",
      "        [2.5000e+03],\n",
      "        [2.6700e+01],\n",
      "        [1.7920e+02],\n",
      "        [1.1400e+04],\n",
      "        [7.0000e+01],\n",
      "        [1.3330e+02],\n",
      "        [9.7100e+02],\n",
      "        [8.2500e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[293.7561],\n",
      "        [281.0546],\n",
      "        [293.7988],\n",
      "        [292.8604],\n",
      "        [293.7351],\n",
      "        [293.4569],\n",
      "        [293.8629],\n",
      "        [293.3623],\n",
      "        [293.6103],\n",
      "        [293.4800],\n",
      "        [290.7426],\n",
      "        [290.6360],\n",
      "        [293.8177],\n",
      "        [293.7976],\n",
      "        [293.7027]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  177.4000],\n",
      "        [ 1600.0000],\n",
      "        [ 3000.0000],\n",
      "        [ 2300.0000],\n",
      "        [ 4000.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5700.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 1800.0000],\n",
      "        [11500.0000],\n",
      "        [ 8800.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 6542.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 5000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[290.0316],\n",
      "        [292.5245],\n",
      "        [293.8178],\n",
      "        [293.7370],\n",
      "        [287.4567],\n",
      "        [289.0997],\n",
      "        [292.4587],\n",
      "        [293.1288],\n",
      "        [293.8163],\n",
      "        [293.6471],\n",
      "        [284.2613],\n",
      "        [291.4171],\n",
      "        [293.7835],\n",
      "        [292.2245],\n",
      "        [289.5438]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[19400.0000],\n",
      "        [12500.0000],\n",
      "        [  959.8000],\n",
      "        [  360.8000],\n",
      "        [ 1500.0000],\n",
      "        [  470.5000],\n",
      "        [12800.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 4400.0000],\n",
      "        [ 2500.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5400.0000],\n",
      "        [ 8500.0000],\n",
      "        [ 4600.0000],\n",
      "        [  233.7000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[293.7901],\n",
      "        [293.7005],\n",
      "        [293.1104],\n",
      "        [293.6308],\n",
      "        [293.6341],\n",
      "        [293.6657],\n",
      "        [293.7003],\n",
      "        [293.7798],\n",
      "        [283.2169],\n",
      "        [293.8191],\n",
      "        [282.9884],\n",
      "        [293.8224],\n",
      "        [287.0816],\n",
      "        [293.8723],\n",
      "        [293.6464]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.8900e+04],\n",
      "        [1.5000e+03],\n",
      "        [7.5080e+02],\n",
      "        [8.5110e+03],\n",
      "        [6.7000e+03],\n",
      "        [4.0000e+04],\n",
      "        [1.0900e+01],\n",
      "        [5.0890e+03],\n",
      "        [6.9900e+01],\n",
      "        [3.0000e+03],\n",
      "        [6.3700e+01],\n",
      "        [1.8200e+04],\n",
      "        [2.3300e+04],\n",
      "        [7.2000e+03],\n",
      "        [7.2190e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[293.7948],\n",
      "        [292.2921],\n",
      "        [292.2388],\n",
      "        [293.7606],\n",
      "        [291.7000],\n",
      "        [287.1663],\n",
      "        [280.4832],\n",
      "        [293.3375],\n",
      "        [279.6802],\n",
      "        [293.7825],\n",
      "        [293.6693],\n",
      "        [293.8828],\n",
      "        [282.7780],\n",
      "        [279.2596],\n",
      "        [279.9016]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 1200.0000],\n",
      "        [  220.3000],\n",
      "        [ 2100.0000],\n",
      "        [ 1600.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 9800.0000],\n",
      "        [ 9800.0000],\n",
      "        [  233.4000],\n",
      "        [ 3600.0000],\n",
      "        [ 4100.0000],\n",
      "        [  604.7000],\n",
      "        [ 3885.0000],\n",
      "        [31500.0000],\n",
      "        [ 3200.0000],\n",
      "        [  794.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[293.7666],\n",
      "        [292.2742],\n",
      "        [291.6603],\n",
      "        [293.6125],\n",
      "        [292.8158],\n",
      "        [291.0112],\n",
      "        [292.7898],\n",
      "        [293.8281],\n",
      "        [283.1350],\n",
      "        [283.8708],\n",
      "        [280.4884],\n",
      "        [293.6925],\n",
      "        [279.8902],\n",
      "        [279.4981],\n",
      "        [293.1963]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.1000e+03],\n",
      "        [2.2000e+03],\n",
      "        [4.3000e+03],\n",
      "        [6.5100e+02],\n",
      "        [9.1700e+01],\n",
      "        [1.5000e+03],\n",
      "        [6.7000e+01],\n",
      "        [2.2600e+04],\n",
      "        [2.1000e+03],\n",
      "        [5.7000e+03],\n",
      "        [1.4600e+04],\n",
      "        [1.8700e+01],\n",
      "        [2.7000e+03],\n",
      "        [5.5000e+01],\n",
      "        [6.6330e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[291.0510],\n",
      "        [293.7701],\n",
      "        [284.4020],\n",
      "        [293.7169],\n",
      "        [288.9518],\n",
      "        [293.7045],\n",
      "        [280.0062],\n",
      "        [293.0702],\n",
      "        [284.1683],\n",
      "        [289.0094],\n",
      "        [293.7735],\n",
      "        [282.0527],\n",
      "        [293.8661],\n",
      "        [293.4363],\n",
      "        [281.9956]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.0600e+02],\n",
      "        [1.1000e+03],\n",
      "        [9.4450e+02],\n",
      "        [2.9000e+03],\n",
      "        [1.6400e+04],\n",
      "        [4.6000e+03],\n",
      "        [7.0700e+04],\n",
      "        [7.9800e+01],\n",
      "        [1.2100e+04],\n",
      "        [9.3000e+03],\n",
      "        [7.0000e+03],\n",
      "        [1.9000e+01],\n",
      "        [3.9000e+03],\n",
      "        [3.8000e+03],\n",
      "        [1.9700e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[293.7812],\n",
      "        [293.8078],\n",
      "        [293.4131],\n",
      "        [293.6739],\n",
      "        [293.7836],\n",
      "        [293.8109],\n",
      "        [292.6883],\n",
      "        [293.6842],\n",
      "        [291.7257],\n",
      "        [292.7682],\n",
      "        [293.7636],\n",
      "        [292.8391],\n",
      "        [293.4895],\n",
      "        [293.0349],\n",
      "        [281.6136]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.8000e+03],\n",
      "        [2.0000e+03],\n",
      "        [5.4980e+02],\n",
      "        [1.8700e+04],\n",
      "        [4.1300e+01],\n",
      "        [2.6450e+02],\n",
      "        [3.9000e+03],\n",
      "        [1.0450e+02],\n",
      "        [7.7000e+03],\n",
      "        [1.6000e+01],\n",
      "        [5.8340e+03],\n",
      "        [3.7000e+03],\n",
      "        [3.1360e+02],\n",
      "        [2.3000e+03],\n",
      "        [1.3300e+01]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[293.8009],\n",
      "        [293.8444],\n",
      "        [293.5015],\n",
      "        [292.8065],\n",
      "        [292.7315],\n",
      "        [293.5685],\n",
      "        [277.9282],\n",
      "        [292.1932],\n",
      "        [284.7404],\n",
      "        [291.7227],\n",
      "        [293.7895],\n",
      "        [293.4296],\n",
      "        [289.1509],\n",
      "        [288.3560],\n",
      "        [293.8546]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 315.3000],\n",
      "        [  25.5000],\n",
      "        [2100.0000],\n",
      "        [1000.0000],\n",
      "        [4942.0000],\n",
      "        [1700.0000],\n",
      "        [ 995.5000],\n",
      "        [3300.0000],\n",
      "        [ 114.9000],\n",
      "        [ 239.1000],\n",
      "        [  12.7000],\n",
      "        [6500.0000],\n",
      "        [ 196.2000],\n",
      "        [1100.0000],\n",
      "        [  75.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([5, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([5, 1])): tensor([[293.8011],\n",
      "        [293.6835],\n",
      "        [293.6201],\n",
      "        [293.6646],\n",
      "        [289.0127]])\n",
      "Target (shape: torch.Size([5, 1])): tensor([[1300.0000],\n",
      "        [ 370.3000],\n",
      "        [8947.0000],\n",
      "        [5217.0000],\n",
      "        [  38.7000]])\n",
      "Adjusting learning rate of group 0 to 5.3333e-05.\n",
      "Epoch 3/20, Train_Loss: 380644.35, Avg: 7048.97; Val_Loss: 63289.61, Avg: 4520.69\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[404.2014],\n",
      "        [395.3390],\n",
      "        [407.0568],\n",
      "        [405.7123],\n",
      "        [399.4008],\n",
      "        [406.9510],\n",
      "        [406.6363],\n",
      "        [404.1188],\n",
      "        [406.9138],\n",
      "        [406.6961],\n",
      "        [406.9144],\n",
      "        [395.7149],\n",
      "        [406.9397],\n",
      "        [406.8071],\n",
      "        [404.8376]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  462.4000],\n",
      "        [ 2100.0000],\n",
      "        [  413.8000],\n",
      "        [  855.7000],\n",
      "        [ 7500.0000],\n",
      "        [ 7100.0000],\n",
      "        [ 3700.0000],\n",
      "        [ 1100.0000],\n",
      "        [10300.0000],\n",
      "        [ 9000.0000],\n",
      "        [ 1400.0000],\n",
      "        [ 2200.0000],\n",
      "        [ 2000.0000],\n",
      "        [  178.4000],\n",
      "        [ 1400.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[406.5699],\n",
      "        [394.9809],\n",
      "        [399.5270],\n",
      "        [405.5194],\n",
      "        [403.9686],\n",
      "        [406.6756],\n",
      "        [405.5790],\n",
      "        [406.8573],\n",
      "        [400.4942],\n",
      "        [405.0497],\n",
      "        [402.7025],\n",
      "        [397.5429],\n",
      "        [405.8737],\n",
      "        [407.0068],\n",
      "        [406.9103]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.5000e+03],\n",
      "        [3.7000e+03],\n",
      "        [4.0000e+03],\n",
      "        [5.8910e+02],\n",
      "        [1.3200e+01],\n",
      "        [1.4800e+04],\n",
      "        [1.8300e+01],\n",
      "        [1.0600e+04],\n",
      "        [6.8000e+03],\n",
      "        [6.6910e+02],\n",
      "        [9.9100e+01],\n",
      "        [4.5700e+01],\n",
      "        [7.6100e+03],\n",
      "        [1.3000e+03],\n",
      "        [4.7000e+03]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[394.9294],\n",
      "        [406.7312],\n",
      "        [400.0552],\n",
      "        [406.7030],\n",
      "        [395.0516],\n",
      "        [405.5861],\n",
      "        [406.7198],\n",
      "        [395.5570],\n",
      "        [406.6606],\n",
      "        [406.9550],\n",
      "        [406.9525],\n",
      "        [395.1693],\n",
      "        [404.7405],\n",
      "        [406.7570],\n",
      "        [406.8281]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[3200.0000],\n",
      "        [8900.0000],\n",
      "        [  14.6000],\n",
      "        [5200.0000],\n",
      "        [ 369.8000],\n",
      "        [2324.0000],\n",
      "        [ 626.9000],\n",
      "        [  10.5000],\n",
      "        [1800.0000],\n",
      "        [ 118.0000],\n",
      "        [4200.0000],\n",
      "        [  10.3000],\n",
      "        [2000.0000],\n",
      "        [2400.0000],\n",
      "        [4600.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[406.9701],\n",
      "        [406.6565],\n",
      "        [405.8776],\n",
      "        [406.5388],\n",
      "        [406.7115],\n",
      "        [395.1253],\n",
      "        [406.8350],\n",
      "        [405.8354],\n",
      "        [406.9706],\n",
      "        [395.0459],\n",
      "        [406.7999],\n",
      "        [406.9575],\n",
      "        [406.7801],\n",
      "        [399.1895],\n",
      "        [405.9343]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 6000.0000],\n",
      "        [ 3180.0000],\n",
      "        [ 1900.0000],\n",
      "        [  153.6000],\n",
      "        [  514.3000],\n",
      "        [ 6245.0000],\n",
      "        [ 1100.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 1300.0000],\n",
      "        [  319.8000],\n",
      "        [ 1100.0000],\n",
      "        [  285.7000],\n",
      "        [15100.0000],\n",
      "        [ 4900.0000],\n",
      "        [ 1000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[402.6609],\n",
      "        [406.7587],\n",
      "        [406.8071],\n",
      "        [395.5340],\n",
      "        [394.5913],\n",
      "        [404.9330],\n",
      "        [406.7303],\n",
      "        [403.8033],\n",
      "        [406.9803],\n",
      "        [394.1497],\n",
      "        [406.8954],\n",
      "        [406.4756],\n",
      "        [406.8164],\n",
      "        [406.8825],\n",
      "        [404.7324]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.9250e+03],\n",
      "        [3.8750e+02],\n",
      "        [8.5900e+01],\n",
      "        [2.2000e+03],\n",
      "        [4.1000e+03],\n",
      "        [9.4000e+03],\n",
      "        [1.0600e+01],\n",
      "        [2.5000e+03],\n",
      "        [2.6700e+01],\n",
      "        [1.7920e+02],\n",
      "        [1.1400e+04],\n",
      "        [7.0000e+01],\n",
      "        [1.3330e+02],\n",
      "        [9.7100e+02],\n",
      "        [8.2500e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[406.8709],\n",
      "        [395.1118],\n",
      "        [406.7885],\n",
      "        [406.5791],\n",
      "        [406.7840],\n",
      "        [406.5043],\n",
      "        [406.8500],\n",
      "        [406.4213],\n",
      "        [406.6966],\n",
      "        [406.7657],\n",
      "        [403.3674],\n",
      "        [405.4291],\n",
      "        [406.9033],\n",
      "        [406.8792],\n",
      "        [406.7629]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  177.4000],\n",
      "        [ 1600.0000],\n",
      "        [ 3000.0000],\n",
      "        [ 2300.0000],\n",
      "        [ 4000.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5700.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 1800.0000],\n",
      "        [11500.0000],\n",
      "        [ 8800.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 6542.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 5000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[405.3162],\n",
      "        [405.8999],\n",
      "        [406.9450],\n",
      "        [406.8490],\n",
      "        [402.9141],\n",
      "        [402.4174],\n",
      "        [405.2939],\n",
      "        [406.5798],\n",
      "        [406.7894],\n",
      "        [406.7698],\n",
      "        [400.5510],\n",
      "        [405.7482],\n",
      "        [406.8957],\n",
      "        [404.3960],\n",
      "        [405.0221]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[19400.0000],\n",
      "        [12500.0000],\n",
      "        [  959.8000],\n",
      "        [  360.8000],\n",
      "        [ 1500.0000],\n",
      "        [  470.5000],\n",
      "        [12800.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 4400.0000],\n",
      "        [ 2500.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5400.0000],\n",
      "        [ 8500.0000],\n",
      "        [ 4600.0000],\n",
      "        [  233.7000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[406.7451],\n",
      "        [406.7619],\n",
      "        [406.7114],\n",
      "        [406.7101],\n",
      "        [406.6985],\n",
      "        [406.7297],\n",
      "        [406.8155],\n",
      "        [406.9256],\n",
      "        [399.1318],\n",
      "        [406.8167],\n",
      "        [398.2849],\n",
      "        [406.8252],\n",
      "        [401.9425],\n",
      "        [406.8546],\n",
      "        [406.7889]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.8900e+04],\n",
      "        [1.5000e+03],\n",
      "        [7.5080e+02],\n",
      "        [8.5110e+03],\n",
      "        [6.7000e+03],\n",
      "        [4.0000e+04],\n",
      "        [1.0900e+01],\n",
      "        [5.0890e+03],\n",
      "        [6.9900e+01],\n",
      "        [3.0000e+03],\n",
      "        [6.3700e+01],\n",
      "        [1.8200e+04],\n",
      "        [2.3300e+04],\n",
      "        [7.2000e+03],\n",
      "        [7.2190e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[406.8816],\n",
      "        [406.1071],\n",
      "        [406.2564],\n",
      "        [406.7869],\n",
      "        [405.9225],\n",
      "        [402.8895],\n",
      "        [392.9380],\n",
      "        [406.4559],\n",
      "        [395.5930],\n",
      "        [406.8215],\n",
      "        [406.7891],\n",
      "        [406.8574],\n",
      "        [398.7804],\n",
      "        [396.1772],\n",
      "        [395.4794]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 1200.0000],\n",
      "        [  220.3000],\n",
      "        [ 2100.0000],\n",
      "        [ 1600.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 9800.0000],\n",
      "        [ 9800.0000],\n",
      "        [  233.4000],\n",
      "        [ 3600.0000],\n",
      "        [ 4100.0000],\n",
      "        [  604.7000],\n",
      "        [ 3885.0000],\n",
      "        [31500.0000],\n",
      "        [ 3200.0000],\n",
      "        [  794.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[406.9118],\n",
      "        [404.8667],\n",
      "        [405.8326],\n",
      "        [406.9417],\n",
      "        [406.5498],\n",
      "        [405.6786],\n",
      "        [406.1723],\n",
      "        [406.8347],\n",
      "        [398.9255],\n",
      "        [399.2697],\n",
      "        [395.9265],\n",
      "        [406.8424],\n",
      "        [395.4210],\n",
      "        [395.3215],\n",
      "        [406.7283]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.1000e+03],\n",
      "        [2.2000e+03],\n",
      "        [4.3000e+03],\n",
      "        [6.5100e+02],\n",
      "        [9.1700e+01],\n",
      "        [1.5000e+03],\n",
      "        [6.7000e+01],\n",
      "        [2.2600e+04],\n",
      "        [2.1000e+03],\n",
      "        [5.7000e+03],\n",
      "        [1.4600e+04],\n",
      "        [1.8700e+01],\n",
      "        [2.7000e+03],\n",
      "        [5.5000e+01],\n",
      "        [6.6330e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[404.8226],\n",
      "        [406.8483],\n",
      "        [401.0194],\n",
      "        [406.7676],\n",
      "        [404.5334],\n",
      "        [406.6988],\n",
      "        [395.4071],\n",
      "        [406.6896],\n",
      "        [400.8091],\n",
      "        [404.4749],\n",
      "        [406.8688],\n",
      "        [398.5112],\n",
      "        [406.8426],\n",
      "        [406.7093],\n",
      "        [399.4568]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.0600e+02],\n",
      "        [1.1000e+03],\n",
      "        [9.4450e+02],\n",
      "        [2.9000e+03],\n",
      "        [1.6400e+04],\n",
      "        [4.6000e+03],\n",
      "        [7.0700e+04],\n",
      "        [7.9800e+01],\n",
      "        [1.2100e+04],\n",
      "        [9.3000e+03],\n",
      "        [7.0000e+03],\n",
      "        [1.9000e+01],\n",
      "        [3.9000e+03],\n",
      "        [3.8000e+03],\n",
      "        [1.9700e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[406.9213],\n",
      "        [406.7851],\n",
      "        [406.7138],\n",
      "        [406.7375],\n",
      "        [406.8605],\n",
      "        [406.9316],\n",
      "        [406.4988],\n",
      "        [406.7298],\n",
      "        [405.8966],\n",
      "        [406.5417],\n",
      "        [406.7950],\n",
      "        [406.5706],\n",
      "        [406.6508],\n",
      "        [406.5705],\n",
      "        [398.5793]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.8000e+03],\n",
      "        [2.0000e+03],\n",
      "        [5.4980e+02],\n",
      "        [1.8700e+04],\n",
      "        [4.1300e+01],\n",
      "        [2.6450e+02],\n",
      "        [3.9000e+03],\n",
      "        [1.0450e+02],\n",
      "        [7.7000e+03],\n",
      "        [1.6000e+01],\n",
      "        [5.8340e+03],\n",
      "        [3.7000e+03],\n",
      "        [3.1360e+02],\n",
      "        [2.3000e+03],\n",
      "        [1.3300e+01]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[406.9174],\n",
      "        [406.8375],\n",
      "        [406.9564],\n",
      "        [406.5488],\n",
      "        [406.5690],\n",
      "        [406.6048],\n",
      "        [394.8232],\n",
      "        [405.6809],\n",
      "        [399.9996],\n",
      "        [405.7900],\n",
      "        [406.7859],\n",
      "        [406.7026],\n",
      "        [404.8177],\n",
      "        [403.3109],\n",
      "        [406.9265]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 315.3000],\n",
      "        [  25.5000],\n",
      "        [2100.0000],\n",
      "        [1000.0000],\n",
      "        [4942.0000],\n",
      "        [1700.0000],\n",
      "        [ 995.5000],\n",
      "        [3300.0000],\n",
      "        [ 114.9000],\n",
      "        [ 239.1000],\n",
      "        [  12.7000],\n",
      "        [6500.0000],\n",
      "        [ 196.2000],\n",
      "        [1100.0000],\n",
      "        [  75.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([5, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([5, 1])): tensor([[406.7713],\n",
      "        [406.7473],\n",
      "        [406.6721],\n",
      "        [406.7076],\n",
      "        [402.4132]])\n",
      "Target (shape: torch.Size([5, 1])): tensor([[1300.0000],\n",
      "        [ 370.3000],\n",
      "        [8947.0000],\n",
      "        [5217.0000],\n",
      "        [  38.7000]])\n",
      "Adjusting learning rate of group 0 to 6.0000e-05.\n",
      "Epoch 4/20, Train_Loss: 377307.59, Avg: 6987.18; Val_Loss: 62425.52, Avg: 4458.97\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[531.3638],\n",
      "        [527.1339],\n",
      "        [533.0334],\n",
      "        [533.0388],\n",
      "        [528.7379],\n",
      "        [533.2376],\n",
      "        [533.1646],\n",
      "        [532.1965],\n",
      "        [533.2933],\n",
      "        [533.2772],\n",
      "        [533.1286],\n",
      "        [527.1611],\n",
      "        [533.2845],\n",
      "        [533.2650],\n",
      "        [532.1099]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  462.4000],\n",
      "        [ 2100.0000],\n",
      "        [  413.8000],\n",
      "        [  855.7000],\n",
      "        [ 7500.0000],\n",
      "        [ 7100.0000],\n",
      "        [ 3700.0000],\n",
      "        [ 1100.0000],\n",
      "        [10300.0000],\n",
      "        [ 9000.0000],\n",
      "        [ 1400.0000],\n",
      "        [ 2200.0000],\n",
      "        [ 2000.0000],\n",
      "        [  178.4000],\n",
      "        [ 1400.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[532.9168],\n",
      "        [527.3871],\n",
      "        [528.7227],\n",
      "        [532.2934],\n",
      "        [532.1611],\n",
      "        [533.1729],\n",
      "        [532.2973],\n",
      "        [533.2871],\n",
      "        [529.2890],\n",
      "        [532.0458],\n",
      "        [530.5876],\n",
      "        [528.3561],\n",
      "        [532.5787],\n",
      "        [533.2101],\n",
      "        [533.2644]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.5000e+03],\n",
      "        [3.7000e+03],\n",
      "        [4.0000e+03],\n",
      "        [5.8910e+02],\n",
      "        [1.3200e+01],\n",
      "        [1.4800e+04],\n",
      "        [1.8300e+01],\n",
      "        [1.0600e+04],\n",
      "        [6.8000e+03],\n",
      "        [6.6910e+02],\n",
      "        [9.9100e+01],\n",
      "        [4.5700e+01],\n",
      "        [7.6100e+03],\n",
      "        [1.3000e+03],\n",
      "        [4.7000e+03]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[526.6631],\n",
      "        [533.2224],\n",
      "        [529.1438],\n",
      "        [533.1359],\n",
      "        [527.1221],\n",
      "        [532.2440],\n",
      "        [532.9921],\n",
      "        [527.1414],\n",
      "        [533.2056],\n",
      "        [533.2410],\n",
      "        [533.2184],\n",
      "        [526.8683],\n",
      "        [532.5022],\n",
      "        [533.2532],\n",
      "        [533.0869]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[3200.0000],\n",
      "        [8900.0000],\n",
      "        [  14.6000],\n",
      "        [5200.0000],\n",
      "        [ 369.8000],\n",
      "        [2324.0000],\n",
      "        [ 626.9000],\n",
      "        [  10.5000],\n",
      "        [1800.0000],\n",
      "        [ 118.0000],\n",
      "        [4200.0000],\n",
      "        [  10.3000],\n",
      "        [2000.0000],\n",
      "        [2400.0000],\n",
      "        [4600.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[533.2540],\n",
      "        [533.2856],\n",
      "        [532.6400],\n",
      "        [532.9443],\n",
      "        [533.0388],\n",
      "        [527.2133],\n",
      "        [533.1469],\n",
      "        [532.5659],\n",
      "        [533.2214],\n",
      "        [526.6713],\n",
      "        [533.2762],\n",
      "        [533.1563],\n",
      "        [533.1974],\n",
      "        [529.3884],\n",
      "        [532.6505]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 6000.0000],\n",
      "        [ 3180.0000],\n",
      "        [ 1900.0000],\n",
      "        [  153.6000],\n",
      "        [  514.3000],\n",
      "        [ 6245.0000],\n",
      "        [ 1100.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 1300.0000],\n",
      "        [  319.8000],\n",
      "        [ 1100.0000],\n",
      "        [  285.7000],\n",
      "        [15100.0000],\n",
      "        [ 4900.0000],\n",
      "        [ 1000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[531.1113],\n",
      "        [533.1973],\n",
      "        [533.1857],\n",
      "        [527.3356],\n",
      "        [525.8652],\n",
      "        [531.6343],\n",
      "        [533.0598],\n",
      "        [531.9474],\n",
      "        [533.2768],\n",
      "        [526.8986],\n",
      "        [533.2357],\n",
      "        [533.1026],\n",
      "        [533.2933],\n",
      "        [533.2507],\n",
      "        [532.3472]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.9250e+03],\n",
      "        [3.8750e+02],\n",
      "        [8.5900e+01],\n",
      "        [2.2000e+03],\n",
      "        [4.1000e+03],\n",
      "        [9.4000e+03],\n",
      "        [1.0600e+01],\n",
      "        [2.5000e+03],\n",
      "        [2.6700e+01],\n",
      "        [1.7920e+02],\n",
      "        [1.1400e+04],\n",
      "        [7.0000e+01],\n",
      "        [1.3330e+02],\n",
      "        [9.7100e+02],\n",
      "        [8.2500e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[533.2264],\n",
      "        [526.9802],\n",
      "        [533.2017],\n",
      "        [533.0255],\n",
      "        [533.2592],\n",
      "        [533.1660],\n",
      "        [533.1716],\n",
      "        [532.9016],\n",
      "        [533.1913],\n",
      "        [533.1528],\n",
      "        [532.0798],\n",
      "        [532.1652],\n",
      "        [533.2737],\n",
      "        [533.2838],\n",
      "        [533.2881]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  177.4000],\n",
      "        [ 1600.0000],\n",
      "        [ 3000.0000],\n",
      "        [ 2300.0000],\n",
      "        [ 4000.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5700.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 1800.0000],\n",
      "        [11500.0000],\n",
      "        [ 8800.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 6542.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 5000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[531.9599],\n",
      "        [533.0685],\n",
      "        [533.2830],\n",
      "        [533.2973],\n",
      "        [531.0771],\n",
      "        [530.0579],\n",
      "        [532.9037],\n",
      "        [532.9317],\n",
      "        [533.2564],\n",
      "        [533.2325],\n",
      "        [529.2059],\n",
      "        [532.5314],\n",
      "        [533.3000],\n",
      "        [532.2972],\n",
      "        [532.1045]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[19400.0000],\n",
      "        [12500.0000],\n",
      "        [  959.8000],\n",
      "        [  360.8000],\n",
      "        [ 1500.0000],\n",
      "        [  470.5000],\n",
      "        [12800.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 4400.0000],\n",
      "        [ 2500.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5400.0000],\n",
      "        [ 8500.0000],\n",
      "        [ 4600.0000],\n",
      "        [  233.7000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[533.2267],\n",
      "        [533.2824],\n",
      "        [533.0339],\n",
      "        [533.2693],\n",
      "        [533.2943],\n",
      "        [533.2860],\n",
      "        [533.2986],\n",
      "        [533.2758],\n",
      "        [528.8731],\n",
      "        [533.2253],\n",
      "        [528.8248],\n",
      "        [533.2093],\n",
      "        [530.0313],\n",
      "        [533.2737],\n",
      "        [533.1105]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.8900e+04],\n",
      "        [1.5000e+03],\n",
      "        [7.5080e+02],\n",
      "        [8.5110e+03],\n",
      "        [6.7000e+03],\n",
      "        [4.0000e+04],\n",
      "        [1.0900e+01],\n",
      "        [5.0890e+03],\n",
      "        [6.9900e+01],\n",
      "        [3.0000e+03],\n",
      "        [6.3700e+01],\n",
      "        [1.8200e+04],\n",
      "        [2.3300e+04],\n",
      "        [7.2000e+03],\n",
      "        [7.2190e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[533.2918],\n",
      "        [532.7018],\n",
      "        [532.6759],\n",
      "        [533.1902],\n",
      "        [532.6629],\n",
      "        [531.0789],\n",
      "        [525.8038],\n",
      "        [533.2485],\n",
      "        [526.9883],\n",
      "        [533.2778],\n",
      "        [533.3038],\n",
      "        [533.2383],\n",
      "        [529.2238],\n",
      "        [527.7346],\n",
      "        [527.1387]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 1200.0000],\n",
      "        [  220.3000],\n",
      "        [ 2100.0000],\n",
      "        [ 1600.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 9800.0000],\n",
      "        [ 9800.0000],\n",
      "        [  233.4000],\n",
      "        [ 3600.0000],\n",
      "        [ 4100.0000],\n",
      "        [  604.7000],\n",
      "        [ 3885.0000],\n",
      "        [31500.0000],\n",
      "        [ 3200.0000],\n",
      "        [  794.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[533.2512],\n",
      "        [532.6909],\n",
      "        [532.5613],\n",
      "        [533.1096],\n",
      "        [532.9706],\n",
      "        [532.2499],\n",
      "        [533.1116],\n",
      "        [533.2134],\n",
      "        [528.7559],\n",
      "        [528.7294],\n",
      "        [527.2390],\n",
      "        [533.2950],\n",
      "        [527.2620],\n",
      "        [527.1030],\n",
      "        [533.0283]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.1000e+03],\n",
      "        [2.2000e+03],\n",
      "        [4.3000e+03],\n",
      "        [6.5100e+02],\n",
      "        [9.1700e+01],\n",
      "        [1.5000e+03],\n",
      "        [6.7000e+01],\n",
      "        [2.2600e+04],\n",
      "        [2.1000e+03],\n",
      "        [5.7000e+03],\n",
      "        [1.4600e+04],\n",
      "        [1.8700e+01],\n",
      "        [2.7000e+03],\n",
      "        [5.5000e+01],\n",
      "        [6.6330e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[532.7493],\n",
      "        [533.2844],\n",
      "        [529.4976],\n",
      "        [533.2960],\n",
      "        [532.0756],\n",
      "        [533.2568],\n",
      "        [527.3072],\n",
      "        [533.0371],\n",
      "        [529.4129],\n",
      "        [531.7515],\n",
      "        [533.2449],\n",
      "        [528.7368],\n",
      "        [533.2634],\n",
      "        [533.1591],\n",
      "        [528.6493]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.0600e+02],\n",
      "        [1.1000e+03],\n",
      "        [9.4450e+02],\n",
      "        [2.9000e+03],\n",
      "        [1.6400e+04],\n",
      "        [4.6000e+03],\n",
      "        [7.0700e+04],\n",
      "        [7.9800e+01],\n",
      "        [1.2100e+04],\n",
      "        [9.3000e+03],\n",
      "        [7.0000e+03],\n",
      "        [1.9000e+01],\n",
      "        [3.9000e+03],\n",
      "        [3.8000e+03],\n",
      "        [1.9700e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[533.2982],\n",
      "        [533.2209],\n",
      "        [533.1639],\n",
      "        [533.2859],\n",
      "        [533.2820],\n",
      "        [533.2933],\n",
      "        [532.9859],\n",
      "        [533.1621],\n",
      "        [532.5865],\n",
      "        [532.9377],\n",
      "        [533.2083],\n",
      "        [532.9703],\n",
      "        [533.2488],\n",
      "        [532.6470],\n",
      "        [528.8246]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.8000e+03],\n",
      "        [2.0000e+03],\n",
      "        [5.4980e+02],\n",
      "        [1.8700e+04],\n",
      "        [4.1300e+01],\n",
      "        [2.6450e+02],\n",
      "        [3.9000e+03],\n",
      "        [1.0450e+02],\n",
      "        [7.7000e+03],\n",
      "        [1.6000e+01],\n",
      "        [5.8340e+03],\n",
      "        [3.7000e+03],\n",
      "        [3.1360e+02],\n",
      "        [2.3000e+03],\n",
      "        [1.3300e+01]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[533.2961],\n",
      "        [533.2310],\n",
      "        [533.0578],\n",
      "        [532.9823],\n",
      "        [532.9830],\n",
      "        [533.2720],\n",
      "        [526.4433],\n",
      "        [533.0071],\n",
      "        [529.7007],\n",
      "        [532.3151],\n",
      "        [533.2108],\n",
      "        [533.1378],\n",
      "        [532.0359],\n",
      "        [531.0120],\n",
      "        [533.2779]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 315.3000],\n",
      "        [  25.5000],\n",
      "        [2100.0000],\n",
      "        [1000.0000],\n",
      "        [4942.0000],\n",
      "        [1700.0000],\n",
      "        [ 995.5000],\n",
      "        [3300.0000],\n",
      "        [ 114.9000],\n",
      "        [ 239.1000],\n",
      "        [  12.7000],\n",
      "        [6500.0000],\n",
      "        [ 196.2000],\n",
      "        [1100.0000],\n",
      "        [  75.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([5, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([5, 1])): tensor([[533.2572],\n",
      "        [533.2245],\n",
      "        [533.2541],\n",
      "        [533.2712],\n",
      "        [531.3109]])\n",
      "Target (shape: torch.Size([5, 1])): tensor([[1300.0000],\n",
      "        [ 370.3000],\n",
      "        [8947.0000],\n",
      "        [5217.0000],\n",
      "        [  38.7000]])\n",
      "Adjusting learning rate of group 0 to 6.6667e-05.\n",
      "Epoch 5/20, Train_Loss: 375896.91, Avg: 6961.05; Val_Loss: 61579.23, Avg: 4398.52\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[653.6253],\n",
      "        [618.1365],\n",
      "        [661.8866],\n",
      "        [661.2092],\n",
      "        [642.6179],\n",
      "        [661.9526],\n",
      "        [661.3311],\n",
      "        [660.7448],\n",
      "        [662.0103],\n",
      "        [661.7961],\n",
      "        [662.0791],\n",
      "        [618.1949],\n",
      "        [661.9391],\n",
      "        [662.1010],\n",
      "        [656.7776]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  462.4000],\n",
      "        [ 2100.0000],\n",
      "        [  413.8000],\n",
      "        [  855.7000],\n",
      "        [ 7500.0000],\n",
      "        [ 7100.0000],\n",
      "        [ 3700.0000],\n",
      "        [ 1100.0000],\n",
      "        [10300.0000],\n",
      "        [ 9000.0000],\n",
      "        [ 1400.0000],\n",
      "        [ 2200.0000],\n",
      "        [ 2000.0000],\n",
      "        [  178.4000],\n",
      "        [ 1400.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[661.7990],\n",
      "        [618.1968],\n",
      "        [644.5318],\n",
      "        [656.2241],\n",
      "        [660.7430],\n",
      "        [662.1148],\n",
      "        [656.2712],\n",
      "        [661.8477],\n",
      "        [646.8611],\n",
      "        [656.1393],\n",
      "        [650.3628],\n",
      "        [633.4032],\n",
      "        [655.8074],\n",
      "        [661.9871],\n",
      "        [662.0207]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.5000e+03],\n",
      "        [3.7000e+03],\n",
      "        [4.0000e+03],\n",
      "        [5.8910e+02],\n",
      "        [1.3200e+01],\n",
      "        [1.4800e+04],\n",
      "        [1.8300e+01],\n",
      "        [1.0600e+04],\n",
      "        [6.8000e+03],\n",
      "        [6.6910e+02],\n",
      "        [9.9100e+01],\n",
      "        [4.5700e+01],\n",
      "        [7.6100e+03],\n",
      "        [1.3000e+03],\n",
      "        [4.7000e+03]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[617.0193],\n",
      "        [662.0883],\n",
      "        [645.6110],\n",
      "        [661.2958],\n",
      "        [618.0267],\n",
      "        [656.5364],\n",
      "        [661.5801],\n",
      "        [618.0618],\n",
      "        [661.2505],\n",
      "        [662.0231],\n",
      "        [661.9012],\n",
      "        [617.7962],\n",
      "        [661.1320],\n",
      "        [662.0587],\n",
      "        [661.1898]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[3200.0000],\n",
      "        [8900.0000],\n",
      "        [  14.6000],\n",
      "        [5200.0000],\n",
      "        [ 369.8000],\n",
      "        [2324.0000],\n",
      "        [ 626.9000],\n",
      "        [  10.5000],\n",
      "        [1800.0000],\n",
      "        [ 118.0000],\n",
      "        [4200.0000],\n",
      "        [  10.3000],\n",
      "        [2000.0000],\n",
      "        [2400.0000],\n",
      "        [4600.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[661.9159],\n",
      "        [661.8226],\n",
      "        [655.5235],\n",
      "        [661.7908],\n",
      "        [661.6141],\n",
      "        [617.1157],\n",
      "        [661.2570],\n",
      "        [655.0573],\n",
      "        [661.7957],\n",
      "        [614.4067],\n",
      "        [661.8882],\n",
      "        [662.1114],\n",
      "        [661.2630],\n",
      "        [638.4565],\n",
      "        [655.4928]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 6000.0000],\n",
      "        [ 3180.0000],\n",
      "        [ 1900.0000],\n",
      "        [  153.6000],\n",
      "        [  514.3000],\n",
      "        [ 6245.0000],\n",
      "        [ 1100.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 1300.0000],\n",
      "        [  319.8000],\n",
      "        [ 1100.0000],\n",
      "        [  285.7000],\n",
      "        [15100.0000],\n",
      "        [ 4900.0000],\n",
      "        [ 1000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[653.3013],\n",
      "        [661.3045],\n",
      "        [661.2330],\n",
      "        [617.5833],\n",
      "        [601.7988],\n",
      "        [654.5894],\n",
      "        [661.5988],\n",
      "        [660.7183],\n",
      "        [661.6488],\n",
      "        [616.1467],\n",
      "        [661.9730],\n",
      "        [661.9926],\n",
      "        [661.8295],\n",
      "        [661.8634],\n",
      "        [660.6212]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.9250e+03],\n",
      "        [3.8750e+02],\n",
      "        [8.5900e+01],\n",
      "        [2.2000e+03],\n",
      "        [4.1000e+03],\n",
      "        [9.4000e+03],\n",
      "        [1.0600e+01],\n",
      "        [2.5000e+03],\n",
      "        [2.6700e+01],\n",
      "        [1.7920e+02],\n",
      "        [1.1400e+04],\n",
      "        [7.0000e+01],\n",
      "        [1.3330e+02],\n",
      "        [9.7100e+02],\n",
      "        [8.2500e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[661.7953],\n",
      "        [599.8945],\n",
      "        [661.1853],\n",
      "        [661.7744],\n",
      "        [661.8202],\n",
      "        [661.0730],\n",
      "        [661.9811],\n",
      "        [661.7375],\n",
      "        [661.3070],\n",
      "        [661.3134],\n",
      "        [660.4339],\n",
      "        [656.4078],\n",
      "        [661.9885],\n",
      "        [661.7292],\n",
      "        [661.8154]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  177.4000],\n",
      "        [ 1600.0000],\n",
      "        [ 3000.0000],\n",
      "        [ 2300.0000],\n",
      "        [ 4000.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5700.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 1800.0000],\n",
      "        [11500.0000],\n",
      "        [ 8800.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 6542.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 5000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[656.5928],\n",
      "        [661.0657],\n",
      "        [661.9144],\n",
      "        [661.9315],\n",
      "        [653.7499],\n",
      "        [652.6757],\n",
      "        [661.5223],\n",
      "        [661.7018],\n",
      "        [662.0375],\n",
      "        [661.8570],\n",
      "        [647.3112],\n",
      "        [655.1932],\n",
      "        [661.9709],\n",
      "        [660.4031],\n",
      "        [656.1096]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[19400.0000],\n",
      "        [12500.0000],\n",
      "        [  959.8000],\n",
      "        [  360.8000],\n",
      "        [ 1500.0000],\n",
      "        [  470.5000],\n",
      "        [12800.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 4400.0000],\n",
      "        [ 2500.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5400.0000],\n",
      "        [ 8500.0000],\n",
      "        [ 4600.0000],\n",
      "        [  233.7000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[662.0428],\n",
      "        [661.7990],\n",
      "        [661.6271],\n",
      "        [661.7960],\n",
      "        [661.8301],\n",
      "        [661.7885],\n",
      "        [661.9763],\n",
      "        [661.9011],\n",
      "        [643.9728],\n",
      "        [661.2204],\n",
      "        [631.7509],\n",
      "        [661.2711],\n",
      "        [654.2235],\n",
      "        [662.0565],\n",
      "        [662.1346]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.8900e+04],\n",
      "        [1.5000e+03],\n",
      "        [7.5080e+02],\n",
      "        [8.5110e+03],\n",
      "        [6.7000e+03],\n",
      "        [4.0000e+04],\n",
      "        [1.0900e+01],\n",
      "        [5.0890e+03],\n",
      "        [6.9900e+01],\n",
      "        [3.0000e+03],\n",
      "        [6.3700e+01],\n",
      "        [1.8200e+04],\n",
      "        [2.3300e+04],\n",
      "        [7.2000e+03],\n",
      "        [7.2190e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[661.8500],\n",
      "        [655.7964],\n",
      "        [661.7625],\n",
      "        [661.3175],\n",
      "        [655.6459],\n",
      "        [653.4650],\n",
      "        [625.2061],\n",
      "        [661.7791],\n",
      "        [617.4341],\n",
      "        [661.6505],\n",
      "        [661.9551],\n",
      "        [662.0925],\n",
      "        [633.1392],\n",
      "        [626.8196],\n",
      "        [617.8438]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 1200.0000],\n",
      "        [  220.3000],\n",
      "        [ 2100.0000],\n",
      "        [ 1600.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 9800.0000],\n",
      "        [ 9800.0000],\n",
      "        [  233.4000],\n",
      "        [ 3600.0000],\n",
      "        [ 4100.0000],\n",
      "        [  604.7000],\n",
      "        [ 3885.0000],\n",
      "        [31500.0000],\n",
      "        [ 3200.0000],\n",
      "        [  794.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[661.7613],\n",
      "        [661.2643],\n",
      "        [655.2047],\n",
      "        [661.0009],\n",
      "        [661.7417],\n",
      "        [655.6829],\n",
      "        [661.0534],\n",
      "        [661.2346],\n",
      "        [643.1677],\n",
      "        [642.5977],\n",
      "        [607.2766],\n",
      "        [661.9412],\n",
      "        [618.2739],\n",
      "        [618.0167],\n",
      "        [661.5295]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.1000e+03],\n",
      "        [2.2000e+03],\n",
      "        [4.3000e+03],\n",
      "        [6.5100e+02],\n",
      "        [9.1700e+01],\n",
      "        [1.5000e+03],\n",
      "        [6.7000e+01],\n",
      "        [2.2600e+04],\n",
      "        [2.1000e+03],\n",
      "        [5.7000e+03],\n",
      "        [1.4600e+04],\n",
      "        [1.8700e+01],\n",
      "        [2.7000e+03],\n",
      "        [5.5000e+01],\n",
      "        [6.6330e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[661.4427],\n",
      "        [661.7910],\n",
      "        [646.9303],\n",
      "        [661.7601],\n",
      "        [656.0439],\n",
      "        [662.0291],\n",
      "        [618.2767],\n",
      "        [661.5837],\n",
      "        [647.1733],\n",
      "        [653.8080],\n",
      "        [661.7423],\n",
      "        [642.5328],\n",
      "        [662.0049],\n",
      "        [661.3088],\n",
      "        [645.3990]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.0600e+02],\n",
      "        [1.1000e+03],\n",
      "        [9.4450e+02],\n",
      "        [2.9000e+03],\n",
      "        [1.6400e+04],\n",
      "        [4.6000e+03],\n",
      "        [7.0700e+04],\n",
      "        [7.9800e+01],\n",
      "        [1.2100e+04],\n",
      "        [9.3000e+03],\n",
      "        [7.0000e+03],\n",
      "        [1.9000e+01],\n",
      "        [3.9000e+03],\n",
      "        [3.8000e+03],\n",
      "        [1.9700e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[661.9358],\n",
      "        [661.2384],\n",
      "        [661.3256],\n",
      "        [661.8442],\n",
      "        [661.8175],\n",
      "        [661.8917],\n",
      "        [661.7317],\n",
      "        [661.2618],\n",
      "        [655.5574],\n",
      "        [661.7878],\n",
      "        [661.2227],\n",
      "        [661.8168],\n",
      "        [661.8647],\n",
      "        [660.9911],\n",
      "        [644.4036]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.8000e+03],\n",
      "        [2.0000e+03],\n",
      "        [5.4980e+02],\n",
      "        [1.8700e+04],\n",
      "        [4.1300e+01],\n",
      "        [2.6450e+02],\n",
      "        [3.9000e+03],\n",
      "        [1.0450e+02],\n",
      "        [7.7000e+03],\n",
      "        [1.6000e+01],\n",
      "        [5.8340e+03],\n",
      "        [3.7000e+03],\n",
      "        [3.1360e+02],\n",
      "        [2.3000e+03],\n",
      "        [1.3300e+01]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[661.8944],\n",
      "        [662.0466],\n",
      "        [661.8748],\n",
      "        [661.8070],\n",
      "        [661.8059],\n",
      "        [661.7865],\n",
      "        [617.3918],\n",
      "        [661.1432],\n",
      "        [640.2487],\n",
      "        [655.5828],\n",
      "        [662.0878],\n",
      "        [661.3331],\n",
      "        [656.4665],\n",
      "        [651.0126],\n",
      "        [661.9095]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 315.3000],\n",
      "        [  25.5000],\n",
      "        [2100.0000],\n",
      "        [1000.0000],\n",
      "        [4942.0000],\n",
      "        [1700.0000],\n",
      "        [ 995.5000],\n",
      "        [3300.0000],\n",
      "        [ 114.9000],\n",
      "        [ 239.1000],\n",
      "        [  12.7000],\n",
      "        [6500.0000],\n",
      "        [ 196.2000],\n",
      "        [1100.0000],\n",
      "        [  75.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([5, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([5, 1])): tensor([[662.0924],\n",
      "        [661.2386],\n",
      "        [661.7666],\n",
      "        [661.8259],\n",
      "        [660.0099]])\n",
      "Target (shape: torch.Size([5, 1])): tensor([[1300.0000],\n",
      "        [ 370.3000],\n",
      "        [8947.0000],\n",
      "        [5217.0000],\n",
      "        [  38.7000]])\n",
      "Adjusting learning rate of group 0 to 7.3333e-05.\n",
      "Epoch 6/20, Train_Loss: 372993.50, Avg: 6907.29; Val_Loss: 60828.50, Avg: 4344.89\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[786.1147],\n",
      "        [779.0228],\n",
      "        [788.3254],\n",
      "        [783.9764],\n",
      "        [782.0981],\n",
      "        [788.0885],\n",
      "        [784.6239],\n",
      "        [785.8185],\n",
      "        [788.2355],\n",
      "        [787.9646],\n",
      "        [787.4573],\n",
      "        [779.7779],\n",
      "        [788.3748],\n",
      "        [788.0507],\n",
      "        [787.7314]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  462.4000],\n",
      "        [ 2100.0000],\n",
      "        [  413.8000],\n",
      "        [  855.7000],\n",
      "        [ 7500.0000],\n",
      "        [ 7100.0000],\n",
      "        [ 3700.0000],\n",
      "        [ 1100.0000],\n",
      "        [10300.0000],\n",
      "        [ 9000.0000],\n",
      "        [ 1400.0000],\n",
      "        [ 2200.0000],\n",
      "        [ 2000.0000],\n",
      "        [  178.4000],\n",
      "        [ 1400.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[788.0398],\n",
      "        [776.9389],\n",
      "        [783.2394],\n",
      "        [785.6788],\n",
      "        [785.8906],\n",
      "        [787.7797],\n",
      "        [786.3942],\n",
      "        [788.1874],\n",
      "        [784.7611],\n",
      "        [787.3447],\n",
      "        [785.2754],\n",
      "        [780.3365],\n",
      "        [780.9579],\n",
      "        [787.8098],\n",
      "        [788.0558]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.5000e+03],\n",
      "        [3.7000e+03],\n",
      "        [4.0000e+03],\n",
      "        [5.8910e+02],\n",
      "        [1.3200e+01],\n",
      "        [1.4800e+04],\n",
      "        [1.8300e+01],\n",
      "        [1.0600e+04],\n",
      "        [6.8000e+03],\n",
      "        [6.6910e+02],\n",
      "        [9.9100e+01],\n",
      "        [4.5700e+01],\n",
      "        [7.6100e+03],\n",
      "        [1.3000e+03],\n",
      "        [4.7000e+03]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[778.8177],\n",
      "        [787.9908],\n",
      "        [783.8062],\n",
      "        [788.3197],\n",
      "        [778.9906],\n",
      "        [787.2573],\n",
      "        [788.2374],\n",
      "        [778.9122],\n",
      "        [784.5694],\n",
      "        [788.1920],\n",
      "        [788.3187],\n",
      "        [779.0291],\n",
      "        [786.2666],\n",
      "        [788.0555],\n",
      "        [787.5536]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[3200.0000],\n",
      "        [8900.0000],\n",
      "        [  14.6000],\n",
      "        [5200.0000],\n",
      "        [ 369.8000],\n",
      "        [2324.0000],\n",
      "        [ 626.9000],\n",
      "        [  10.5000],\n",
      "        [1800.0000],\n",
      "        [ 118.0000],\n",
      "        [4200.0000],\n",
      "        [  10.3000],\n",
      "        [2000.0000],\n",
      "        [2400.0000],\n",
      "        [4600.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[788.4005],\n",
      "        [788.4155],\n",
      "        [780.6872],\n",
      "        [788.1069],\n",
      "        [788.3232],\n",
      "        [777.5155],\n",
      "        [788.4703],\n",
      "        [780.9598],\n",
      "        [788.3264],\n",
      "        [770.8350],\n",
      "        [788.0399],\n",
      "        [787.6559],\n",
      "        [784.9958],\n",
      "        [772.8793],\n",
      "        [780.7415]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 6000.0000],\n",
      "        [ 3180.0000],\n",
      "        [ 1900.0000],\n",
      "        [  153.6000],\n",
      "        [  514.3000],\n",
      "        [ 6245.0000],\n",
      "        [ 1100.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 1300.0000],\n",
      "        [  319.8000],\n",
      "        [ 1100.0000],\n",
      "        [  285.7000],\n",
      "        [15100.0000],\n",
      "        [ 4900.0000],\n",
      "        [ 1000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[777.0088],\n",
      "        [785.0394],\n",
      "        [784.9102],\n",
      "        [778.5508],\n",
      "        [553.4541],\n",
      "        [786.5472],\n",
      "        [788.2147],\n",
      "        [785.8403],\n",
      "        [788.4410],\n",
      "        [774.8539],\n",
      "        [788.3077],\n",
      "        [788.1292],\n",
      "        [788.4492],\n",
      "        [788.3136],\n",
      "        [784.4302]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.9250e+03],\n",
      "        [3.8750e+02],\n",
      "        [8.5900e+01],\n",
      "        [2.2000e+03],\n",
      "        [4.1000e+03],\n",
      "        [9.4000e+03],\n",
      "        [1.0600e+01],\n",
      "        [2.5000e+03],\n",
      "        [2.6700e+01],\n",
      "        [1.7920e+02],\n",
      "        [1.1400e+04],\n",
      "        [7.0000e+01],\n",
      "        [1.3330e+02],\n",
      "        [9.7100e+02],\n",
      "        [8.2500e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[788.1790],\n",
      "        [552.0960],\n",
      "        [784.4689],\n",
      "        [788.1725],\n",
      "        [788.4104],\n",
      "        [786.7842],\n",
      "        [788.0397],\n",
      "        [787.9092],\n",
      "        [784.8578],\n",
      "        [788.2705],\n",
      "        [785.4358],\n",
      "        [786.3671],\n",
      "        [788.2821],\n",
      "        [788.4261],\n",
      "        [788.4170]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  177.4000],\n",
      "        [ 1600.0000],\n",
      "        [ 3000.0000],\n",
      "        [ 2300.0000],\n",
      "        [ 4000.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5700.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 1800.0000],\n",
      "        [11500.0000],\n",
      "        [ 8800.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 6542.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 5000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[786.7593],\n",
      "        [783.8281],\n",
      "        [788.2258],\n",
      "        [788.3374],\n",
      "        [775.3239],\n",
      "        [782.4254],\n",
      "        [786.7806],\n",
      "        [787.9811],\n",
      "        [788.0238],\n",
      "        [788.3689],\n",
      "        [785.0949],\n",
      "        [780.6890],\n",
      "        [788.3516],\n",
      "        [783.7070],\n",
      "        [787.3895]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[19400.0000],\n",
      "        [12500.0000],\n",
      "        [  959.8000],\n",
      "        [  360.8000],\n",
      "        [ 1500.0000],\n",
      "        [  470.5000],\n",
      "        [12800.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 4400.0000],\n",
      "        [ 2500.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5400.0000],\n",
      "        [ 8500.0000],\n",
      "        [ 4600.0000],\n",
      "        [  233.7000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[787.9846],\n",
      "        [788.3387],\n",
      "        [788.2776],\n",
      "        [788.2435],\n",
      "        [788.4352],\n",
      "        [788.4167],\n",
      "        [788.2476],\n",
      "        [788.2573],\n",
      "        [783.5577],\n",
      "        [784.4279],\n",
      "        [780.2066],\n",
      "        [784.8433],\n",
      "        [785.2266],\n",
      "        [788.0841],\n",
      "        [786.9637]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.8900e+04],\n",
      "        [1.5000e+03],\n",
      "        [7.5080e+02],\n",
      "        [8.5110e+03],\n",
      "        [6.7000e+03],\n",
      "        [4.0000e+04],\n",
      "        [1.0900e+01],\n",
      "        [5.0890e+03],\n",
      "        [6.9900e+01],\n",
      "        [3.0000e+03],\n",
      "        [6.3700e+01],\n",
      "        [1.8200e+04],\n",
      "        [2.3300e+04],\n",
      "        [7.2000e+03],\n",
      "        [7.2190e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[788.3763],\n",
      "        [780.4433],\n",
      "        [787.9469],\n",
      "        [784.8379],\n",
      "        [780.8138],\n",
      "        [775.2599],\n",
      "        [775.2332],\n",
      "        [787.7493],\n",
      "        [773.2221],\n",
      "        [788.4315],\n",
      "        [788.3457],\n",
      "        [788.0558],\n",
      "        [781.5823],\n",
      "        [776.0618],\n",
      "        [778.2610]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 1200.0000],\n",
      "        [  220.3000],\n",
      "        [ 2100.0000],\n",
      "        [ 1600.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 9800.0000],\n",
      "        [ 9800.0000],\n",
      "        [  233.4000],\n",
      "        [ 3600.0000],\n",
      "        [ 4100.0000],\n",
      "        [  604.7000],\n",
      "        [ 3885.0000],\n",
      "        [31500.0000],\n",
      "        [ 3200.0000],\n",
      "        [  794.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[788.4017],\n",
      "        [786.1195],\n",
      "        [780.3541],\n",
      "        [783.9967],\n",
      "        [788.1091],\n",
      "        [787.0497],\n",
      "        [783.9835],\n",
      "        [784.5252],\n",
      "        [783.1794],\n",
      "        [781.2837],\n",
      "        [553.7364],\n",
      "        [788.2834],\n",
      "        [778.8328],\n",
      "        [779.2325],\n",
      "        [788.3052]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.1000e+03],\n",
      "        [2.2000e+03],\n",
      "        [4.3000e+03],\n",
      "        [6.5100e+02],\n",
      "        [9.1700e+01],\n",
      "        [1.5000e+03],\n",
      "        [6.7000e+01],\n",
      "        [2.2600e+04],\n",
      "        [2.1000e+03],\n",
      "        [5.7000e+03],\n",
      "        [1.4600e+04],\n",
      "        [1.8700e+01],\n",
      "        [2.7000e+03],\n",
      "        [5.5000e+01],\n",
      "        [6.6330e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[786.4787],\n",
      "        [788.4073],\n",
      "        [784.5945],\n",
      "        [788.2444],\n",
      "        [787.6935],\n",
      "        [788.0268],\n",
      "        [778.6569],\n",
      "        [788.2963],\n",
      "        [785.0615],\n",
      "        [785.1259],\n",
      "        [788.3059],\n",
      "        [781.6071],\n",
      "        [788.1562],\n",
      "        [788.2708],\n",
      "        [784.4156]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.0600e+02],\n",
      "        [1.1000e+03],\n",
      "        [9.4450e+02],\n",
      "        [2.9000e+03],\n",
      "        [1.6400e+04],\n",
      "        [4.6000e+03],\n",
      "        [7.0700e+04],\n",
      "        [7.9800e+01],\n",
      "        [1.2100e+04],\n",
      "        [9.3000e+03],\n",
      "        [7.0000e+03],\n",
      "        [1.9000e+01],\n",
      "        [3.9000e+03],\n",
      "        [3.8000e+03],\n",
      "        [1.9700e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[788.3228],\n",
      "        [784.7335],\n",
      "        [788.3846],\n",
      "        [788.4282],\n",
      "        [788.4321],\n",
      "        [788.3810],\n",
      "        [788.0173],\n",
      "        [784.9670],\n",
      "        [780.8196],\n",
      "        [788.0406],\n",
      "        [784.6381],\n",
      "        [788.1078],\n",
      "        [788.0312],\n",
      "        [787.8911],\n",
      "        [783.8198]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.8000e+03],\n",
      "        [2.0000e+03],\n",
      "        [5.4980e+02],\n",
      "        [1.8700e+04],\n",
      "        [4.1300e+01],\n",
      "        [2.6450e+02],\n",
      "        [3.9000e+03],\n",
      "        [1.0450e+02],\n",
      "        [7.7000e+03],\n",
      "        [1.6000e+01],\n",
      "        [5.8340e+03],\n",
      "        [3.7000e+03],\n",
      "        [3.1360e+02],\n",
      "        [2.3000e+03],\n",
      "        [1.3300e+01]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[788.3908],\n",
      "        [787.9822],\n",
      "        [787.5314],\n",
      "        [788.0562],\n",
      "        [788.0972],\n",
      "        [788.2936],\n",
      "        [779.3839],\n",
      "        [784.0214],\n",
      "        [780.9644],\n",
      "        [786.3805],\n",
      "        [788.0172],\n",
      "        [788.3326],\n",
      "        [787.4989],\n",
      "        [780.7651],\n",
      "        [788.3399]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 315.3000],\n",
      "        [  25.5000],\n",
      "        [2100.0000],\n",
      "        [1000.0000],\n",
      "        [4942.0000],\n",
      "        [1700.0000],\n",
      "        [ 995.5000],\n",
      "        [3300.0000],\n",
      "        [ 114.9000],\n",
      "        [ 239.1000],\n",
      "        [  12.7000],\n",
      "        [6500.0000],\n",
      "        [ 196.2000],\n",
      "        [1100.0000],\n",
      "        [  75.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([5, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([5, 1])): tensor([[787.9758],\n",
      "        [785.1902],\n",
      "        [788.2057],\n",
      "        [788.3760],\n",
      "        [783.1084]])\n",
      "Target (shape: torch.Size([5, 1])): tensor([[1300.0000],\n",
      "        [ 370.3000],\n",
      "        [8947.0000],\n",
      "        [5217.0000],\n",
      "        [  38.7000]])\n",
      "Adjusting learning rate of group 0 to 8.0000e-05.\n",
      "Epoch 7/20, Train_Loss: 376102.20, Avg: 6964.86; Val_Loss: 60170.94, Avg: 4297.92\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[914.4532],\n",
      "        [892.9153],\n",
      "        [916.0984],\n",
      "        [914.8115],\n",
      "        [889.4361],\n",
      "        [916.0755],\n",
      "        [915.3652],\n",
      "        [915.2770],\n",
      "        [916.1588],\n",
      "        [916.4107],\n",
      "        [915.9108],\n",
      "        [892.9533],\n",
      "        [916.2021],\n",
      "        [916.0513],\n",
      "        [915.2323]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  462.4000],\n",
      "        [ 2100.0000],\n",
      "        [  413.8000],\n",
      "        [  855.7000],\n",
      "        [ 7500.0000],\n",
      "        [ 7100.0000],\n",
      "        [ 3700.0000],\n",
      "        [ 1100.0000],\n",
      "        [10300.0000],\n",
      "        [ 9000.0000],\n",
      "        [ 1400.0000],\n",
      "        [ 2200.0000],\n",
      "        [ 2000.0000],\n",
      "        [  178.4000],\n",
      "        [ 1400.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[915.0886],\n",
      "        [889.9611],\n",
      "        [884.6290],\n",
      "        [914.0358],\n",
      "        [915.4684],\n",
      "        [915.9872],\n",
      "        [914.6687],\n",
      "        [916.1971],\n",
      "        [899.2731],\n",
      "        [915.0984],\n",
      "        [911.9141],\n",
      "        [909.6883],\n",
      "        [911.9709],\n",
      "        [916.0291],\n",
      "        [916.0520]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.5000e+03],\n",
      "        [3.7000e+03],\n",
      "        [4.0000e+03],\n",
      "        [5.8910e+02],\n",
      "        [1.3200e+01],\n",
      "        [1.4800e+04],\n",
      "        [1.8300e+01],\n",
      "        [1.0600e+04],\n",
      "        [6.8000e+03],\n",
      "        [6.6910e+02],\n",
      "        [9.9100e+01],\n",
      "        [4.5700e+01],\n",
      "        [7.6100e+03],\n",
      "        [1.3000e+03],\n",
      "        [4.7000e+03]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[891.1097],\n",
      "        [916.0414],\n",
      "        [893.7242],\n",
      "        [915.8402],\n",
      "        [893.3553],\n",
      "        [914.9863],\n",
      "        [915.3881],\n",
      "        [893.1412],\n",
      "        [915.2860],\n",
      "        [916.0735],\n",
      "        [916.2618],\n",
      "        [892.5193],\n",
      "        [915.6384],\n",
      "        [916.0977],\n",
      "        [916.0807]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[3200.0000],\n",
      "        [8900.0000],\n",
      "        [  14.6000],\n",
      "        [5200.0000],\n",
      "        [ 369.8000],\n",
      "        [2324.0000],\n",
      "        [ 626.9000],\n",
      "        [  10.5000],\n",
      "        [1800.0000],\n",
      "        [ 118.0000],\n",
      "        [4200.0000],\n",
      "        [  10.3000],\n",
      "        [2000.0000],\n",
      "        [2400.0000],\n",
      "        [4600.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[916.1931],\n",
      "        [916.4637],\n",
      "        [911.8706],\n",
      "        [915.2698],\n",
      "        [915.4579],\n",
      "        [892.9007],\n",
      "        [915.8032],\n",
      "        [912.0653],\n",
      "        [916.1914],\n",
      "        [890.7739],\n",
      "        [916.2990],\n",
      "        [916.0269],\n",
      "        [915.4264],\n",
      "        [910.6631],\n",
      "        [911.8340]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 6000.0000],\n",
      "        [ 3180.0000],\n",
      "        [ 1900.0000],\n",
      "        [  153.6000],\n",
      "        [  514.3000],\n",
      "        [ 6245.0000],\n",
      "        [ 1100.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 1300.0000],\n",
      "        [  319.8000],\n",
      "        [ 1100.0000],\n",
      "        [  285.7000],\n",
      "        [15100.0000],\n",
      "        [ 4900.0000],\n",
      "        [ 1000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[910.0084],\n",
      "        [915.3469],\n",
      "        [915.4957],\n",
      "        [892.5590],\n",
      "        [636.9626],\n",
      "        [914.8645],\n",
      "        [915.5443],\n",
      "        [915.0846],\n",
      "        [916.1985],\n",
      "        [893.4198],\n",
      "        [916.0941],\n",
      "        [916.1843],\n",
      "        [916.4135],\n",
      "        [916.2660],\n",
      "        [915.3436]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.9250e+03],\n",
      "        [3.8750e+02],\n",
      "        [8.5900e+01],\n",
      "        [2.2000e+03],\n",
      "        [4.1000e+03],\n",
      "        [9.4000e+03],\n",
      "        [1.0600e+01],\n",
      "        [2.5000e+03],\n",
      "        [2.6700e+01],\n",
      "        [1.7920e+02],\n",
      "        [1.1400e+04],\n",
      "        [7.0000e+01],\n",
      "        [1.3330e+02],\n",
      "        [9.7100e+02],\n",
      "        [8.2500e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[916.2357],\n",
      "        [630.3042],\n",
      "        [915.3182],\n",
      "        [915.3383],\n",
      "        [916.4197],\n",
      "        [915.7972],\n",
      "        [916.1743],\n",
      "        [916.1633],\n",
      "        [915.4352],\n",
      "        [915.8486],\n",
      "        [915.2312],\n",
      "        [914.5502],\n",
      "        [916.2199],\n",
      "        [916.3755],\n",
      "        [916.4127]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  177.4000],\n",
      "        [ 1600.0000],\n",
      "        [ 3000.0000],\n",
      "        [ 2300.0000],\n",
      "        [ 4000.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5700.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 1800.0000],\n",
      "        [11500.0000],\n",
      "        [ 8800.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 6542.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 5000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[915.0204],\n",
      "        [914.8043],\n",
      "        [916.1856],\n",
      "        [916.2543],\n",
      "        [909.3188],\n",
      "        [914.0426],\n",
      "        [915.9772],\n",
      "        [914.9406],\n",
      "        [916.0721],\n",
      "        [916.1849],\n",
      "        [898.3159],\n",
      "        [911.7482],\n",
      "        [916.1919],\n",
      "        [915.2244],\n",
      "        [915.1395]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[19400.0000],\n",
      "        [12500.0000],\n",
      "        [  959.8000],\n",
      "        [  360.8000],\n",
      "        [ 1500.0000],\n",
      "        [  470.5000],\n",
      "        [12800.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 4400.0000],\n",
      "        [ 2500.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5400.0000],\n",
      "        [ 8500.0000],\n",
      "        [ 4600.0000],\n",
      "        [  233.7000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[916.1750],\n",
      "        [916.4351],\n",
      "        [915.3024],\n",
      "        [916.3759],\n",
      "        [916.4597],\n",
      "        [916.4609],\n",
      "        [916.2645],\n",
      "        [916.2318],\n",
      "        [891.5012],\n",
      "        [915.4423],\n",
      "        [910.1942],\n",
      "        [915.4756],\n",
      "        [914.6024],\n",
      "        [916.0925],\n",
      "        [915.8217]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.8900e+04],\n",
      "        [1.5000e+03],\n",
      "        [7.5080e+02],\n",
      "        [8.5110e+03],\n",
      "        [6.7000e+03],\n",
      "        [4.0000e+04],\n",
      "        [1.0900e+01],\n",
      "        [5.0890e+03],\n",
      "        [6.9900e+01],\n",
      "        [3.0000e+03],\n",
      "        [6.3700e+01],\n",
      "        [1.8200e+04],\n",
      "        [2.3300e+04],\n",
      "        [7.2000e+03],\n",
      "        [7.2190e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[916.3180],\n",
      "        [911.2358],\n",
      "        [915.1615],\n",
      "        [915.3430],\n",
      "        [911.6150],\n",
      "        [909.8663],\n",
      "        [898.9620],\n",
      "        [916.3579],\n",
      "        [891.0176],\n",
      "        [916.3999],\n",
      "        [916.2678],\n",
      "        [916.0883],\n",
      "        [911.5053],\n",
      "        [907.0731],\n",
      "        [891.0880]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 1200.0000],\n",
      "        [  220.3000],\n",
      "        [ 2100.0000],\n",
      "        [ 1600.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 9800.0000],\n",
      "        [ 9800.0000],\n",
      "        [  233.4000],\n",
      "        [ 3600.0000],\n",
      "        [ 4100.0000],\n",
      "        [  604.7000],\n",
      "        [ 3885.0000],\n",
      "        [31500.0000],\n",
      "        [ 3200.0000],\n",
      "        [  794.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[916.3128],\n",
      "        [915.9030],\n",
      "        [911.8478],\n",
      "        [915.4127],\n",
      "        [915.4167],\n",
      "        [914.2070],\n",
      "        [914.9197],\n",
      "        [915.4305],\n",
      "        [889.8747],\n",
      "        [891.4696],\n",
      "        [636.4894],\n",
      "        [916.1641],\n",
      "        [892.5746],\n",
      "        [892.6345],\n",
      "        [915.5139]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.1000e+03],\n",
      "        [2.2000e+03],\n",
      "        [4.3000e+03],\n",
      "        [6.5100e+02],\n",
      "        [9.1700e+01],\n",
      "        [1.5000e+03],\n",
      "        [6.7000e+01],\n",
      "        [2.2600e+04],\n",
      "        [2.1000e+03],\n",
      "        [5.7000e+03],\n",
      "        [1.4600e+04],\n",
      "        [1.8700e+01],\n",
      "        [2.7000e+03],\n",
      "        [5.5000e+01],\n",
      "        [6.6330e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[915.6563],\n",
      "        [916.3969],\n",
      "        [900.3457],\n",
      "        [916.4418],\n",
      "        [915.4010],\n",
      "        [916.1831],\n",
      "        [893.6263],\n",
      "        [915.3445],\n",
      "        [899.0651],\n",
      "        [913.7139],\n",
      "        [916.3322],\n",
      "        [880.5531],\n",
      "        [916.1311],\n",
      "        [915.8470],\n",
      "        [889.0730]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.0600e+02],\n",
      "        [1.1000e+03],\n",
      "        [9.4450e+02],\n",
      "        [2.9000e+03],\n",
      "        [1.6400e+04],\n",
      "        [4.6000e+03],\n",
      "        [7.0700e+04],\n",
      "        [7.9800e+01],\n",
      "        [1.2100e+04],\n",
      "        [9.3000e+03],\n",
      "        [7.0000e+03],\n",
      "        [1.9000e+01],\n",
      "        [3.9000e+03],\n",
      "        [3.8000e+03],\n",
      "        [1.9700e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[916.2090],\n",
      "        [915.4005],\n",
      "        [915.8181],\n",
      "        [916.4220],\n",
      "        [916.2912],\n",
      "        [916.1672],\n",
      "        [915.5074],\n",
      "        [915.4269],\n",
      "        [911.7672],\n",
      "        [915.2372],\n",
      "        [915.3651],\n",
      "        [915.1664],\n",
      "        [916.1816],\n",
      "        [915.0378],\n",
      "        [886.2469]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.8000e+03],\n",
      "        [2.0000e+03],\n",
      "        [5.4980e+02],\n",
      "        [1.8700e+04],\n",
      "        [4.1300e+01],\n",
      "        [2.6450e+02],\n",
      "        [3.9000e+03],\n",
      "        [1.0450e+02],\n",
      "        [7.7000e+03],\n",
      "        [1.6000e+01],\n",
      "        [5.8340e+03],\n",
      "        [3.7000e+03],\n",
      "        [3.1360e+02],\n",
      "        [2.3000e+03],\n",
      "        [1.3300e+01]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[916.2185],\n",
      "        [916.1214],\n",
      "        [915.9254],\n",
      "        [915.2977],\n",
      "        [915.2880],\n",
      "        [916.3804],\n",
      "        [892.5218],\n",
      "        [914.8324],\n",
      "        [912.7740],\n",
      "        [914.0802],\n",
      "        [916.0059],\n",
      "        [915.8595],\n",
      "        [915.3044],\n",
      "        [912.6972],\n",
      "        [916.1909]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 315.3000],\n",
      "        [  25.5000],\n",
      "        [2100.0000],\n",
      "        [1000.0000],\n",
      "        [4942.0000],\n",
      "        [1700.0000],\n",
      "        [ 995.5000],\n",
      "        [3300.0000],\n",
      "        [ 114.9000],\n",
      "        [ 239.1000],\n",
      "        [  12.7000],\n",
      "        [6500.0000],\n",
      "        [ 196.2000],\n",
      "        [1100.0000],\n",
      "        [  75.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([5, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([5, 1])): tensor([[916.0542],\n",
      "        [915.4747],\n",
      "        [916.2947],\n",
      "        [916.3854],\n",
      "        [913.0540]])\n",
      "Target (shape: torch.Size([5, 1])): tensor([[1300.0000],\n",
      "        [ 370.3000],\n",
      "        [8947.0000],\n",
      "        [5217.0000],\n",
      "        [  38.7000]])\n",
      "Adjusting learning rate of group 0 to 8.6667e-05.\n",
      "Epoch 8/20, Train_Loss: 366896.39, Avg: 6794.38; Val_Loss: 59541.93, Avg: 4252.99\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1041.7552],\n",
      "        [1025.8987],\n",
      "        [1046.1835],\n",
      "        [ 974.9678],\n",
      "        [1023.7388],\n",
      "        [1046.1559],\n",
      "        [1043.7117],\n",
      "        [1044.7026],\n",
      "        [1046.1840],\n",
      "        [1045.9323],\n",
      "        [1046.1726],\n",
      "        [1029.2540],\n",
      "        [1046.2013],\n",
      "        [1046.1937],\n",
      "        [1044.2195]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  462.4000],\n",
      "        [ 2100.0000],\n",
      "        [  413.8000],\n",
      "        [  855.7000],\n",
      "        [ 7500.0000],\n",
      "        [ 7100.0000],\n",
      "        [ 3700.0000],\n",
      "        [ 1100.0000],\n",
      "        [10300.0000],\n",
      "        [ 9000.0000],\n",
      "        [ 1400.0000],\n",
      "        [ 2200.0000],\n",
      "        [ 2000.0000],\n",
      "        [  178.4000],\n",
      "        [ 1400.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1045.8744],\n",
      "        [1015.0342],\n",
      "        [1009.1451],\n",
      "        [1042.5380],\n",
      "        [1044.5260],\n",
      "        [1046.1721],\n",
      "        [1044.2037],\n",
      "        [1046.1162],\n",
      "        [1037.8497],\n",
      "        [1044.1613],\n",
      "        [1039.0228],\n",
      "        [1033.5094],\n",
      "        [1034.6633],\n",
      "        [1046.2339],\n",
      "        [1046.1423]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.5000e+03],\n",
      "        [3.7000e+03],\n",
      "        [4.0000e+03],\n",
      "        [5.8910e+02],\n",
      "        [1.3200e+01],\n",
      "        [1.4800e+04],\n",
      "        [1.8300e+01],\n",
      "        [1.0600e+04],\n",
      "        [6.8000e+03],\n",
      "        [6.6910e+02],\n",
      "        [9.9100e+01],\n",
      "        [4.5700e+01],\n",
      "        [7.6100e+03],\n",
      "        [1.3000e+03],\n",
      "        [4.7000e+03]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1023.6456],\n",
      "        [1046.1721],\n",
      "        [1031.6661],\n",
      "        [1045.9740],\n",
      "        [1026.1708],\n",
      "        [1044.6832],\n",
      "        [1045.8224],\n",
      "        [1025.8984],\n",
      "        [1043.1229],\n",
      "        [1046.2085],\n",
      "        [1046.2069],\n",
      "        [1025.5919],\n",
      "        [1045.0991],\n",
      "        [1046.1964],\n",
      "        [1045.1090]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[3200.0000],\n",
      "        [8900.0000],\n",
      "        [  14.6000],\n",
      "        [5200.0000],\n",
      "        [ 369.8000],\n",
      "        [2324.0000],\n",
      "        [ 626.9000],\n",
      "        [  10.5000],\n",
      "        [1800.0000],\n",
      "        [ 118.0000],\n",
      "        [4200.0000],\n",
      "        [  10.3000],\n",
      "        [2000.0000],\n",
      "        [2400.0000],\n",
      "        [4600.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1046.1837],\n",
      "        [1046.1334],\n",
      "        [1034.7897],\n",
      "        [1045.9213],\n",
      "        [1045.9203],\n",
      "        [1025.9062],\n",
      "        [1045.8489],\n",
      "        [1035.4857],\n",
      "        [1046.1692],\n",
      "        [1025.3177],\n",
      "        [1046.1721],\n",
      "        [1046.1652],\n",
      "        [1043.3402],\n",
      "        [1025.8752],\n",
      "        [1035.1589]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 6000.0000],\n",
      "        [ 3180.0000],\n",
      "        [ 1900.0000],\n",
      "        [  153.6000],\n",
      "        [  514.3000],\n",
      "        [ 6245.0000],\n",
      "        [ 1100.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 1300.0000],\n",
      "        [  319.8000],\n",
      "        [ 1100.0000],\n",
      "        [  285.7000],\n",
      "        [15100.0000],\n",
      "        [ 4900.0000],\n",
      "        [ 1000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1040.0510],\n",
      "        [1042.9188],\n",
      "        [1043.3788],\n",
      "        [1024.1107],\n",
      "        [ 739.9296],\n",
      "        [1036.1503],\n",
      "        [1045.9967],\n",
      "        [1044.4531],\n",
      "        [1046.1625],\n",
      "        [1018.3486],\n",
      "        [1045.7345],\n",
      "        [1045.8936],\n",
      "        [1046.1595],\n",
      "        [1046.1075],\n",
      "        [1045.0095]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.9250e+03],\n",
      "        [3.8750e+02],\n",
      "        [8.5900e+01],\n",
      "        [2.2000e+03],\n",
      "        [4.1000e+03],\n",
      "        [9.4000e+03],\n",
      "        [1.0600e+01],\n",
      "        [2.5000e+03],\n",
      "        [2.6700e+01],\n",
      "        [1.7920e+02],\n",
      "        [1.1400e+04],\n",
      "        [7.0000e+01],\n",
      "        [1.3330e+02],\n",
      "        [9.7100e+02],\n",
      "        [8.2500e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1046.1741],\n",
      "        [ 738.5090],\n",
      "        [1043.4379],\n",
      "        [1045.8768],\n",
      "        [1046.0767],\n",
      "        [1043.4093],\n",
      "        [1046.1593],\n",
      "        [1045.1178],\n",
      "        [1043.4017],\n",
      "        [1045.9967],\n",
      "        [1044.4230],\n",
      "        [1043.8596],\n",
      "        [1046.2100],\n",
      "        [1046.1361],\n",
      "        [1046.1824]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  177.4000],\n",
      "        [ 1600.0000],\n",
      "        [ 3000.0000],\n",
      "        [ 2300.0000],\n",
      "        [ 4000.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5700.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 1800.0000],\n",
      "        [11500.0000],\n",
      "        [ 8800.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 6542.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 5000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1043.9608],\n",
      "        [ 979.6808],\n",
      "        [1046.1522],\n",
      "        [1046.1844],\n",
      "        [1039.2906],\n",
      "        [1040.0283],\n",
      "        [1044.8698],\n",
      "        [1045.6425],\n",
      "        [1046.1656],\n",
      "        [1046.0226],\n",
      "        [1037.0865],\n",
      "        [1034.6288],\n",
      "        [1046.1829],\n",
      "        [1044.9932],\n",
      "        [1044.3593]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[19400.0000],\n",
      "        [12500.0000],\n",
      "        [  959.8000],\n",
      "        [  360.8000],\n",
      "        [ 1500.0000],\n",
      "        [  470.5000],\n",
      "        [12800.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 4400.0000],\n",
      "        [ 2500.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5400.0000],\n",
      "        [ 8500.0000],\n",
      "        [ 4600.0000],\n",
      "        [  233.7000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1046.0765],\n",
      "        [1046.0935],\n",
      "        [1045.9497],\n",
      "        [1046.0809],\n",
      "        [1046.1605],\n",
      "        [1046.1542],\n",
      "        [1046.1631],\n",
      "        [1046.1433],\n",
      "        [1027.7869],\n",
      "        [1043.4031],\n",
      "        [1018.4971],\n",
      "        [1043.4814],\n",
      "        [1037.2581],\n",
      "        [1046.1797],\n",
      "        [1046.1571]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.8900e+04],\n",
      "        [1.5000e+03],\n",
      "        [7.5080e+02],\n",
      "        [8.5110e+03],\n",
      "        [6.7000e+03],\n",
      "        [4.0000e+04],\n",
      "        [1.0900e+01],\n",
      "        [5.0890e+03],\n",
      "        [6.9900e+01],\n",
      "        [3.0000e+03],\n",
      "        [6.3700e+01],\n",
      "        [1.8200e+04],\n",
      "        [2.3300e+04],\n",
      "        [7.2000e+03],\n",
      "        [7.2190e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1046.1868],\n",
      "        [1034.6281],\n",
      "        [1045.6696],\n",
      "        [1043.1854],\n",
      "        [1034.8705],\n",
      "        [1039.8628],\n",
      "        [1013.6375],\n",
      "        [1045.7161],\n",
      "        [1024.9645],\n",
      "        [1045.9325],\n",
      "        [1046.2169],\n",
      "        [1046.1691],\n",
      "        [1032.6068],\n",
      "        [1028.8881],\n",
      "        [1024.9247]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 1200.0000],\n",
      "        [  220.3000],\n",
      "        [ 2100.0000],\n",
      "        [ 1600.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 9800.0000],\n",
      "        [ 9800.0000],\n",
      "        [  233.4000],\n",
      "        [ 3600.0000],\n",
      "        [ 4100.0000],\n",
      "        [  604.7000],\n",
      "        [ 3885.0000],\n",
      "        [31500.0000],\n",
      "        [ 3200.0000],\n",
      "        [  794.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1046.0542],\n",
      "        [1044.9476],\n",
      "        [1035.3861],\n",
      "        [1043.8126],\n",
      "        [1046.0109],\n",
      "        [1036.3467],\n",
      "        [ 981.6319],\n",
      "        [1043.3739],\n",
      "        [1024.9858],\n",
      "        [1024.3705],\n",
      "        [ 740.6844],\n",
      "        [1046.2020],\n",
      "        [1025.2120],\n",
      "        [1025.3955],\n",
      "        [1046.0247]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.1000e+03],\n",
      "        [2.2000e+03],\n",
      "        [4.3000e+03],\n",
      "        [6.5100e+02],\n",
      "        [9.1700e+01],\n",
      "        [1.5000e+03],\n",
      "        [6.7000e+01],\n",
      "        [2.2600e+04],\n",
      "        [2.1000e+03],\n",
      "        [5.7000e+03],\n",
      "        [1.4600e+04],\n",
      "        [1.8700e+01],\n",
      "        [2.7000e+03],\n",
      "        [5.5000e+01],\n",
      "        [6.6330e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1038.3947],\n",
      "        [1046.1381],\n",
      "        [1037.6520],\n",
      "        [1046.0840],\n",
      "        [1044.3103],\n",
      "        [1046.0670],\n",
      "        [1023.5369],\n",
      "        [1045.8721],\n",
      "        [1037.8746],\n",
      "        [1036.9978],\n",
      "        [1046.1112],\n",
      "        [ 999.4191],\n",
      "        [1046.1306],\n",
      "        [1045.8682],\n",
      "        [1022.6537]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.0600e+02],\n",
      "        [1.1000e+03],\n",
      "        [9.4450e+02],\n",
      "        [2.9000e+03],\n",
      "        [1.6400e+04],\n",
      "        [4.6000e+03],\n",
      "        [7.0700e+04],\n",
      "        [7.9800e+01],\n",
      "        [1.2100e+04],\n",
      "        [9.3000e+03],\n",
      "        [7.0000e+03],\n",
      "        [1.9000e+01],\n",
      "        [3.9000e+03],\n",
      "        [3.8000e+03],\n",
      "        [1.9700e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1046.1771],\n",
      "        [1043.1191],\n",
      "        [1045.9779],\n",
      "        [1046.1774],\n",
      "        [1046.0382],\n",
      "        [1046.1591],\n",
      "        [1045.9460],\n",
      "        [1042.9689],\n",
      "        [1034.7792],\n",
      "        [1045.9449],\n",
      "        [1043.2861],\n",
      "        [1045.8949],\n",
      "        [1045.6348],\n",
      "        [1042.6829],\n",
      "        [1012.2741]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.8000e+03],\n",
      "        [2.0000e+03],\n",
      "        [5.4980e+02],\n",
      "        [1.8700e+04],\n",
      "        [4.1300e+01],\n",
      "        [2.6450e+02],\n",
      "        [3.9000e+03],\n",
      "        [1.0450e+02],\n",
      "        [7.7000e+03],\n",
      "        [1.6000e+01],\n",
      "        [5.8340e+03],\n",
      "        [3.7000e+03],\n",
      "        [3.1360e+02],\n",
      "        [2.3000e+03],\n",
      "        [1.3300e+01]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1046.2137],\n",
      "        [1046.1947],\n",
      "        [1046.0934],\n",
      "        [1045.9414],\n",
      "        [1045.9976],\n",
      "        [1045.9092],\n",
      "        [1020.2071],\n",
      "        [ 975.8133],\n",
      "        [1018.8733],\n",
      "        [1041.6881],\n",
      "        [1046.0243],\n",
      "        [1045.9254],\n",
      "        [1044.3190],\n",
      "        [1038.7657],\n",
      "        [1046.2410]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 315.3000],\n",
      "        [  25.5000],\n",
      "        [2100.0000],\n",
      "        [1000.0000],\n",
      "        [4942.0000],\n",
      "        [1700.0000],\n",
      "        [ 995.5000],\n",
      "        [3300.0000],\n",
      "        [ 114.9000],\n",
      "        [ 239.1000],\n",
      "        [  12.7000],\n",
      "        [6500.0000],\n",
      "        [ 196.2000],\n",
      "        [1100.0000],\n",
      "        [  75.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([5, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([5, 1])): tensor([[1046.1713],\n",
      "        [1043.5026],\n",
      "        [1046.0321],\n",
      "        [1046.1042],\n",
      "        [ 985.7140]])\n",
      "Target (shape: torch.Size([5, 1])): tensor([[1300.0000],\n",
      "        [ 370.3000],\n",
      "        [8947.0000],\n",
      "        [5217.0000],\n",
      "        [  38.7000]])\n",
      "Adjusting learning rate of group 0 to 9.3333e-05.\n",
      "Epoch 9/20, Train_Loss: 363272.51, Avg: 6727.27; Val_Loss: 58962.00, Avg: 4211.57\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1166.7108],\n",
      "        [1137.3312],\n",
      "        [1171.1893],\n",
      "        [1170.9653],\n",
      "        [1134.9724],\n",
      "        [1171.0166],\n",
      "        [1169.1329],\n",
      "        [1170.1501],\n",
      "        [1170.9905],\n",
      "        [1171.0707],\n",
      "        [1170.9460],\n",
      "        [1138.8149],\n",
      "        [1170.9047],\n",
      "        [1171.0726],\n",
      "        [1167.7755]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  462.4000],\n",
      "        [ 2100.0000],\n",
      "        [  413.8000],\n",
      "        [  855.7000],\n",
      "        [ 7500.0000],\n",
      "        [ 7100.0000],\n",
      "        [ 3700.0000],\n",
      "        [ 1100.0000],\n",
      "        [10300.0000],\n",
      "        [ 9000.0000],\n",
      "        [ 1400.0000],\n",
      "        [ 2200.0000],\n",
      "        [ 2000.0000],\n",
      "        [  178.4000],\n",
      "        [ 1400.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1169.4967],\n",
      "        [1137.2991],\n",
      "        [1133.9231],\n",
      "        [1168.3079],\n",
      "        [1170.1849],\n",
      "        [1170.8899],\n",
      "        [1168.3544],\n",
      "        [1170.8384],\n",
      "        [1144.9558],\n",
      "        [1168.0472],\n",
      "        [1165.4363],\n",
      "        [1153.9775],\n",
      "        [1166.9894],\n",
      "        [1171.1470],\n",
      "        [1171.0854]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.5000e+03],\n",
      "        [3.7000e+03],\n",
      "        [4.0000e+03],\n",
      "        [5.8910e+02],\n",
      "        [1.3200e+01],\n",
      "        [1.4800e+04],\n",
      "        [1.8300e+01],\n",
      "        [1.0600e+04],\n",
      "        [6.8000e+03],\n",
      "        [6.6910e+02],\n",
      "        [9.9100e+01],\n",
      "        [4.5700e+01],\n",
      "        [7.6100e+03],\n",
      "        [1.3000e+03],\n",
      "        [4.7000e+03]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1137.1519],\n",
      "        [1171.0076],\n",
      "        [1146.4929],\n",
      "        [1169.7134],\n",
      "        [1137.2676],\n",
      "        [1168.3103],\n",
      "        [1169.4878],\n",
      "        [1137.7078],\n",
      "        [1169.3569],\n",
      "        [1170.8964],\n",
      "        [1171.0886],\n",
      "        [1138.1970],\n",
      "        [1170.4111],\n",
      "        [1171.0510],\n",
      "        [1171.5442]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[3200.0000],\n",
      "        [8900.0000],\n",
      "        [  14.6000],\n",
      "        [5200.0000],\n",
      "        [ 369.8000],\n",
      "        [2324.0000],\n",
      "        [ 626.9000],\n",
      "        [  10.5000],\n",
      "        [1800.0000],\n",
      "        [ 118.0000],\n",
      "        [4200.0000],\n",
      "        [  10.3000],\n",
      "        [2000.0000],\n",
      "        [2400.0000],\n",
      "        [4600.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1171.0142],\n",
      "        [1171.0662],\n",
      "        [1167.1381],\n",
      "        [1169.5354],\n",
      "        [1169.5177],\n",
      "        [1137.1440],\n",
      "        [1169.6099],\n",
      "        [1166.9302],\n",
      "        [1170.9351],\n",
      "        [1134.5553],\n",
      "        [1171.1946],\n",
      "        [1171.2026],\n",
      "        [1169.4211],\n",
      "        [1151.7468],\n",
      "        [1166.9595]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 6000.0000],\n",
      "        [ 3180.0000],\n",
      "        [ 1900.0000],\n",
      "        [  153.6000],\n",
      "        [  514.3000],\n",
      "        [ 6245.0000],\n",
      "        [ 1100.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 1300.0000],\n",
      "        [  319.8000],\n",
      "        [ 1100.0000],\n",
      "        [  285.7000],\n",
      "        [15100.0000],\n",
      "        [ 4900.0000],\n",
      "        [ 1000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1158.9883],\n",
      "        [1169.5391],\n",
      "        [1169.3914],\n",
      "        [1139.0042],\n",
      "        [ 838.8563],\n",
      "        [1169.4929],\n",
      "        [1169.5103],\n",
      "        [1170.0671],\n",
      "        [1170.8486],\n",
      "        [1115.4390],\n",
      "        [1171.1586],\n",
      "        [1171.0941],\n",
      "        [1171.1077],\n",
      "        [1171.1343],\n",
      "        [1170.2520]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.9250e+03],\n",
      "        [3.8750e+02],\n",
      "        [8.5900e+01],\n",
      "        [2.2000e+03],\n",
      "        [4.1000e+03],\n",
      "        [9.4000e+03],\n",
      "        [1.0600e+01],\n",
      "        [2.5000e+03],\n",
      "        [2.6700e+01],\n",
      "        [1.7920e+02],\n",
      "        [1.1400e+04],\n",
      "        [7.0000e+01],\n",
      "        [1.3330e+02],\n",
      "        [9.7100e+02],\n",
      "        [8.2500e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1171.0455],\n",
      "        [ 839.3733],\n",
      "        [1169.2841],\n",
      "        [1169.4563],\n",
      "        [1171.1028],\n",
      "        [1170.3799],\n",
      "        [1171.3770],\n",
      "        [1171.6410],\n",
      "        [1169.4170],\n",
      "        [1169.7546],\n",
      "        [1170.3066],\n",
      "        [1168.3708],\n",
      "        [1171.0836],\n",
      "        [1170.9756],\n",
      "        [1171.0962]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  177.4000],\n",
      "        [ 1600.0000],\n",
      "        [ 3000.0000],\n",
      "        [ 2300.0000],\n",
      "        [ 4000.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5700.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 1800.0000],\n",
      "        [11500.0000],\n",
      "        [ 8800.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 6542.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 5000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1168.0198],\n",
      "        [1170.7578],\n",
      "        [1171.0397],\n",
      "        [1171.0510],\n",
      "        [1157.5562],\n",
      "        [1167.7804],\n",
      "        [1171.4106],\n",
      "        [1169.5839],\n",
      "        [1171.0005],\n",
      "        [1171.1079],\n",
      "        [1144.8633],\n",
      "        [1167.0007],\n",
      "        [1171.0122],\n",
      "        [1170.1196],\n",
      "        [1168.1082]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[19400.0000],\n",
      "        [12500.0000],\n",
      "        [  959.8000],\n",
      "        [  360.8000],\n",
      "        [ 1500.0000],\n",
      "        [  470.5000],\n",
      "        [12800.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 4400.0000],\n",
      "        [ 2500.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5400.0000],\n",
      "        [ 8500.0000],\n",
      "        [ 4600.0000],\n",
      "        [  233.7000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1171.2118],\n",
      "        [1171.0684],\n",
      "        [1169.4858],\n",
      "        [1171.0378],\n",
      "        [1171.1088],\n",
      "        [1171.1006],\n",
      "        [1170.9945],\n",
      "        [1171.0933],\n",
      "        [1138.9456],\n",
      "        [1169.2245],\n",
      "        [1157.1340],\n",
      "        [1169.3871],\n",
      "        [1167.7327],\n",
      "        [1171.0029],\n",
      "        [1171.1112]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.8900e+04],\n",
      "        [1.5000e+03],\n",
      "        [7.5080e+02],\n",
      "        [8.5110e+03],\n",
      "        [6.7000e+03],\n",
      "        [4.0000e+04],\n",
      "        [1.0900e+01],\n",
      "        [5.0890e+03],\n",
      "        [6.9900e+01],\n",
      "        [3.0000e+03],\n",
      "        [6.3700e+01],\n",
      "        [1.8200e+04],\n",
      "        [2.3300e+04],\n",
      "        [7.2000e+03],\n",
      "        [7.2190e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1171.0361],\n",
      "        [1167.3009],\n",
      "        [1169.8875],\n",
      "        [1169.3545],\n",
      "        [1167.1030],\n",
      "        [1157.5809],\n",
      "        [1149.9404],\n",
      "        [1171.0796],\n",
      "        [1136.0027],\n",
      "        [1170.8066],\n",
      "        [1171.0199],\n",
      "        [1171.1848],\n",
      "        [1156.4546],\n",
      "        [1149.6111],\n",
      "        [1136.6128]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 1200.0000],\n",
      "        [  220.3000],\n",
      "        [ 2100.0000],\n",
      "        [ 1600.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 9800.0000],\n",
      "        [ 9800.0000],\n",
      "        [  233.4000],\n",
      "        [ 3600.0000],\n",
      "        [ 4100.0000],\n",
      "        [  604.7000],\n",
      "        [ 3885.0000],\n",
      "        [31500.0000],\n",
      "        [ 3200.0000],\n",
      "        [  794.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1170.8892],\n",
      "        [1171.0400],\n",
      "        [1166.9723],\n",
      "        [1169.1284],\n",
      "        [1169.6207],\n",
      "        [1169.5306],\n",
      "        [1170.7902],\n",
      "        [1169.2937],\n",
      "        [1137.9644],\n",
      "        [1134.8225],\n",
      "        [ 839.2728],\n",
      "        [1170.9841],\n",
      "        [1136.3615],\n",
      "        [1137.9786],\n",
      "        [1169.5938]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.1000e+03],\n",
      "        [2.2000e+03],\n",
      "        [4.3000e+03],\n",
      "        [6.5100e+02],\n",
      "        [9.1700e+01],\n",
      "        [1.5000e+03],\n",
      "        [6.7000e+01],\n",
      "        [2.2600e+04],\n",
      "        [2.1000e+03],\n",
      "        [5.7000e+03],\n",
      "        [1.4600e+04],\n",
      "        [1.8700e+01],\n",
      "        [2.7000e+03],\n",
      "        [5.5000e+01],\n",
      "        [6.6330e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1171.1136],\n",
      "        [1170.9558],\n",
      "        [1144.3040],\n",
      "        [1171.0315],\n",
      "        [1167.8093],\n",
      "        [1171.2690],\n",
      "        [1137.2975],\n",
      "        [1169.5626],\n",
      "        [1144.4756],\n",
      "        [1167.3845],\n",
      "        [1171.0676],\n",
      "        [1133.3625],\n",
      "        [1171.0823],\n",
      "        [1169.7877],\n",
      "        [1137.4421]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.0600e+02],\n",
      "        [1.1000e+03],\n",
      "        [9.4450e+02],\n",
      "        [2.9000e+03],\n",
      "        [1.6400e+04],\n",
      "        [4.6000e+03],\n",
      "        [7.0700e+04],\n",
      "        [7.9800e+01],\n",
      "        [1.2100e+04],\n",
      "        [9.3000e+03],\n",
      "        [7.0000e+03],\n",
      "        [1.9000e+01],\n",
      "        [3.9000e+03],\n",
      "        [3.8000e+03],\n",
      "        [1.9700e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1171.0122],\n",
      "        [1169.3451],\n",
      "        [1169.6869],\n",
      "        [1171.0870],\n",
      "        [1171.1392],\n",
      "        [1171.0300],\n",
      "        [1169.6616],\n",
      "        [1169.3632],\n",
      "        [1167.1309],\n",
      "        [1169.5178],\n",
      "        [1169.2766],\n",
      "        [1169.5276],\n",
      "        [1171.2982],\n",
      "        [1171.3279],\n",
      "        [1135.9146]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.8000e+03],\n",
      "        [2.0000e+03],\n",
      "        [5.4980e+02],\n",
      "        [1.8700e+04],\n",
      "        [4.1300e+01],\n",
      "        [2.6450e+02],\n",
      "        [3.9000e+03],\n",
      "        [1.0450e+02],\n",
      "        [7.7000e+03],\n",
      "        [1.6000e+01],\n",
      "        [5.8340e+03],\n",
      "        [3.7000e+03],\n",
      "        [3.1360e+02],\n",
      "        [2.3000e+03],\n",
      "        [1.3300e+01]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1171.0115],\n",
      "        [1171.1365],\n",
      "        [1171.2963],\n",
      "        [1169.6416],\n",
      "        [1169.5497],\n",
      "        [1171.0818],\n",
      "        [1138.4017],\n",
      "        [1170.8329],\n",
      "        [1158.7985],\n",
      "        [1170.2963],\n",
      "        [1171.0891],\n",
      "        [1169.7565],\n",
      "        [1168.0853],\n",
      "        [1163.7029],\n",
      "        [1170.9381]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 315.3000],\n",
      "        [  25.5000],\n",
      "        [2100.0000],\n",
      "        [1000.0000],\n",
      "        [4942.0000],\n",
      "        [1700.0000],\n",
      "        [ 995.5000],\n",
      "        [3300.0000],\n",
      "        [ 114.9000],\n",
      "        [ 239.1000],\n",
      "        [  12.7000],\n",
      "        [6500.0000],\n",
      "        [ 196.2000],\n",
      "        [1100.0000],\n",
      "        [  75.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([5, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([5, 1])): tensor([[1171.0267],\n",
      "        [1169.3406],\n",
      "        [1170.8558],\n",
      "        [1171.1338],\n",
      "        [1171.6213]])\n",
      "Target (shape: torch.Size([5, 1])): tensor([[1300.0000],\n",
      "        [ 370.3000],\n",
      "        [8947.0000],\n",
      "        [5217.0000],\n",
      "        [  38.7000]])\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 10/20, Train_Loss: 371283.56, Avg: 6875.62; Val_Loss: 58527.82, Avg: 4180.56\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1119.4017],\n",
      "        [1114.9824],\n",
      "        [1269.4303],\n",
      "        [1265.6205],\n",
      "        [1100.3210],\n",
      "        [1269.5332],\n",
      "        [1262.7518],\n",
      "        [1264.7045],\n",
      "        [1269.1658],\n",
      "        [1268.5972],\n",
      "        [1270.4536],\n",
      "        [1114.1243],\n",
      "        [1268.9723],\n",
      "        [1269.1925],\n",
      "        [1122.7389]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  462.4000],\n",
      "        [ 2100.0000],\n",
      "        [  413.8000],\n",
      "        [  855.7000],\n",
      "        [ 7500.0000],\n",
      "        [ 7100.0000],\n",
      "        [ 3700.0000],\n",
      "        [ 1100.0000],\n",
      "        [10300.0000],\n",
      "        [ 9000.0000],\n",
      "        [ 1400.0000],\n",
      "        [ 2200.0000],\n",
      "        [ 2000.0000],\n",
      "        [  178.4000],\n",
      "        [ 1400.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1264.0173],\n",
      "        [1115.5696],\n",
      "        [1102.0745],\n",
      "        [1117.5730],\n",
      "        [1264.7891],\n",
      "        [1269.5820],\n",
      "        [1114.5341],\n",
      "        [1268.9347],\n",
      "        [1102.6289],\n",
      "        [1122.7928],\n",
      "        [1113.2725],\n",
      "        [1121.1460],\n",
      "        [1106.3687],\n",
      "        [1269.6898],\n",
      "        [1269.6329]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.5000e+03],\n",
      "        [3.7000e+03],\n",
      "        [4.0000e+03],\n",
      "        [5.8910e+02],\n",
      "        [1.3200e+01],\n",
      "        [1.4800e+04],\n",
      "        [1.8300e+01],\n",
      "        [1.0600e+04],\n",
      "        [6.8000e+03],\n",
      "        [6.6910e+02],\n",
      "        [9.9100e+01],\n",
      "        [4.5700e+01],\n",
      "        [7.6100e+03],\n",
      "        [1.3000e+03],\n",
      "        [4.7000e+03]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1114.9580],\n",
      "        [1269.3826],\n",
      "        [1102.1296],\n",
      "        [1264.2451],\n",
      "        [1114.9142],\n",
      "        [1118.1403],\n",
      "        [1264.3738],\n",
      "        [1114.8469],\n",
      "        [1262.0509],\n",
      "        [1269.2693],\n",
      "        [1269.1213],\n",
      "        [1114.8440],\n",
      "        [1264.6460],\n",
      "        [1269.2208],\n",
      "        [1265.5424]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[3200.0000],\n",
      "        [8900.0000],\n",
      "        [  14.6000],\n",
      "        [5200.0000],\n",
      "        [ 369.8000],\n",
      "        [2324.0000],\n",
      "        [ 626.9000],\n",
      "        [  10.5000],\n",
      "        [1800.0000],\n",
      "        [ 118.0000],\n",
      "        [4200.0000],\n",
      "        [  10.3000],\n",
      "        [2000.0000],\n",
      "        [2400.0000],\n",
      "        [4600.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1269.0186],\n",
      "        [1268.7245],\n",
      "        [1106.0742],\n",
      "        [1264.1582],\n",
      "        [1264.0541],\n",
      "        [1114.5123],\n",
      "        [1264.2344],\n",
      "        [1107.1821],\n",
      "        [1268.6976],\n",
      "        [1114.7651],\n",
      "        [1269.1482],\n",
      "        [1269.6290],\n",
      "        [1262.3624],\n",
      "        [1118.1240],\n",
      "        [1105.8353]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 6000.0000],\n",
      "        [ 3180.0000],\n",
      "        [ 1900.0000],\n",
      "        [  153.6000],\n",
      "        [  514.3000],\n",
      "        [ 6245.0000],\n",
      "        [ 1100.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 1300.0000],\n",
      "        [  319.8000],\n",
      "        [ 1100.0000],\n",
      "        [  285.7000],\n",
      "        [15100.0000],\n",
      "        [ 4900.0000],\n",
      "        [ 1000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1103.3928],\n",
      "        [1262.4282],\n",
      "        [1262.3646],\n",
      "        [1115.1377],\n",
      "        [1032.0549],\n",
      "        [1122.4387],\n",
      "        [1264.0344],\n",
      "        [1264.7349],\n",
      "        [1268.8900],\n",
      "        [1119.5525],\n",
      "        [1269.4373],\n",
      "        [1269.4854],\n",
      "        [1268.8131],\n",
      "        [1269.2267],\n",
      "        [1266.8191]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.9250e+03],\n",
      "        [3.8750e+02],\n",
      "        [8.5900e+01],\n",
      "        [2.2000e+03],\n",
      "        [4.1000e+03],\n",
      "        [9.4000e+03],\n",
      "        [1.0600e+01],\n",
      "        [2.5000e+03],\n",
      "        [2.6700e+01],\n",
      "        [1.7920e+02],\n",
      "        [1.1400e+04],\n",
      "        [7.0000e+01],\n",
      "        [1.3330e+02],\n",
      "        [9.7100e+02],\n",
      "        [8.2500e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1269.1760],\n",
      "        [1033.8235],\n",
      "        [1262.3589],\n",
      "        [1263.8796],\n",
      "        [1268.7570],\n",
      "        [1263.2775],\n",
      "        [1269.1584],\n",
      "        [1269.9541],\n",
      "        [1262.4646],\n",
      "        [1264.3042],\n",
      "        [1264.6207],\n",
      "        [1120.1292],\n",
      "        [1269.0778],\n",
      "        [1268.8019],\n",
      "        [1268.7916]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  177.4000],\n",
      "        [ 1600.0000],\n",
      "        [ 3000.0000],\n",
      "        [ 2300.0000],\n",
      "        [ 4000.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5700.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 1800.0000],\n",
      "        [11500.0000],\n",
      "        [ 8800.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 6542.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 5000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1119.8005],\n",
      "        [1265.3672],\n",
      "        [1269.1492],\n",
      "        [1268.9332],\n",
      "        [1102.8794],\n",
      "        [1106.8601],\n",
      "        [1265.8235],\n",
      "        [1263.6788],\n",
      "        [1269.2034],\n",
      "        [1269.3026],\n",
      "        [1103.0425],\n",
      "        [1106.6089],\n",
      "        [1268.9862],\n",
      "        [1266.9998],\n",
      "        [1117.3748]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[19400.0000],\n",
      "        [12500.0000],\n",
      "        [  959.8000],\n",
      "        [  360.8000],\n",
      "        [ 1500.0000],\n",
      "        [  470.5000],\n",
      "        [12800.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 4400.0000],\n",
      "        [ 2500.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5400.0000],\n",
      "        [ 8500.0000],\n",
      "        [ 4600.0000],\n",
      "        [  233.7000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1269.3782],\n",
      "        [1268.5453],\n",
      "        [1264.3088],\n",
      "        [1268.6521],\n",
      "        [1268.6849],\n",
      "        [1268.7539],\n",
      "        [1268.9241],\n",
      "        [1269.0854],\n",
      "        [1101.0704],\n",
      "        [1262.2776],\n",
      "        [1120.1458],\n",
      "        [1262.2974],\n",
      "        [1114.1835],\n",
      "        [1269.2034],\n",
      "        [1270.5865]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.8900e+04],\n",
      "        [1.5000e+03],\n",
      "        [7.5080e+02],\n",
      "        [8.5110e+03],\n",
      "        [6.7000e+03],\n",
      "        [4.0000e+04],\n",
      "        [1.0900e+01],\n",
      "        [5.0890e+03],\n",
      "        [6.9900e+01],\n",
      "        [3.0000e+03],\n",
      "        [6.3700e+01],\n",
      "        [1.8200e+04],\n",
      "        [2.3300e+04],\n",
      "        [7.2000e+03],\n",
      "        [7.2190e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1268.9048],\n",
      "        [1105.5659],\n",
      "        [1264.1787],\n",
      "        [1262.2595],\n",
      "        [1105.5911],\n",
      "        [1103.1710],\n",
      "        [1105.0465],\n",
      "        [1268.3452],\n",
      "        [1114.8231],\n",
      "        [1268.5557],\n",
      "        [1269.0151],\n",
      "        [1269.3535],\n",
      "        [1117.6044],\n",
      "        [1120.6083],\n",
      "        [1114.9192]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 1200.0000],\n",
      "        [  220.3000],\n",
      "        [ 2100.0000],\n",
      "        [ 1600.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 9800.0000],\n",
      "        [ 9800.0000],\n",
      "        [  233.4000],\n",
      "        [ 3600.0000],\n",
      "        [ 4100.0000],\n",
      "        [  604.7000],\n",
      "        [ 3885.0000],\n",
      "        [31500.0000],\n",
      "        [ 3200.0000],\n",
      "        [  794.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1268.5645],\n",
      "        [1263.9154],\n",
      "        [1105.4816],\n",
      "        [1262.1711],\n",
      "        [1264.3105],\n",
      "        [1121.6417],\n",
      "        [1265.6042],\n",
      "        [1262.2927],\n",
      "        [1100.9961],\n",
      "        [1100.3259],\n",
      "        [1030.2323],\n",
      "        [1269.0399],\n",
      "        [1114.8521],\n",
      "        [1114.9740],\n",
      "        [1264.2052]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.1000e+03],\n",
      "        [2.2000e+03],\n",
      "        [4.3000e+03],\n",
      "        [6.5100e+02],\n",
      "        [9.1700e+01],\n",
      "        [1.5000e+03],\n",
      "        [6.7000e+01],\n",
      "        [2.2600e+04],\n",
      "        [2.1000e+03],\n",
      "        [5.7000e+03],\n",
      "        [1.4600e+04],\n",
      "        [1.8700e+01],\n",
      "        [2.7000e+03],\n",
      "        [5.5000e+01],\n",
      "        [6.6330e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1268.7874],\n",
      "        [1268.6837],\n",
      "        [1102.7510],\n",
      "        [1268.6824],\n",
      "        [1123.2379],\n",
      "        [1268.9375],\n",
      "        [1115.2544],\n",
      "        [1264.2802],\n",
      "        [1102.8315],\n",
      "        [1122.5396],\n",
      "        [1268.8015],\n",
      "        [1101.9530],\n",
      "        [1268.9979],\n",
      "        [1264.4403],\n",
      "        [1102.1898]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.0600e+02],\n",
      "        [1.1000e+03],\n",
      "        [9.4450e+02],\n",
      "        [2.9000e+03],\n",
      "        [1.6400e+04],\n",
      "        [4.6000e+03],\n",
      "        [7.0700e+04],\n",
      "        [7.9800e+01],\n",
      "        [1.2100e+04],\n",
      "        [9.3000e+03],\n",
      "        [7.0000e+03],\n",
      "        [1.9000e+01],\n",
      "        [3.9000e+03],\n",
      "        [3.8000e+03],\n",
      "        [1.9700e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1268.9248],\n",
      "        [1262.3071],\n",
      "        [1264.2234],\n",
      "        [1268.7744],\n",
      "        [1268.9333],\n",
      "        [1269.0052],\n",
      "        [1264.2478],\n",
      "        [1262.3418],\n",
      "        [1106.3326],\n",
      "        [1264.1570],\n",
      "        [1262.2559],\n",
      "        [1264.0710],\n",
      "        [1269.2852],\n",
      "        [1265.4866],\n",
      "        [1102.4425]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.8000e+03],\n",
      "        [2.0000e+03],\n",
      "        [5.4980e+02],\n",
      "        [1.8700e+04],\n",
      "        [4.1300e+01],\n",
      "        [2.6450e+02],\n",
      "        [3.9000e+03],\n",
      "        [1.0450e+02],\n",
      "        [7.7000e+03],\n",
      "        [1.6000e+01],\n",
      "        [5.8340e+03],\n",
      "        [3.7000e+03],\n",
      "        [3.1360e+02],\n",
      "        [2.3000e+03],\n",
      "        [1.3300e+01]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1268.9146],\n",
      "        [1269.5127],\n",
      "        [1270.5334],\n",
      "        [1264.1111],\n",
      "        [1264.1311],\n",
      "        [1268.6879],\n",
      "        [1115.6152],\n",
      "        [1265.7993],\n",
      "        [1124.9580],\n",
      "        [1112.5928],\n",
      "        [1269.3220],\n",
      "        [1264.1255],\n",
      "        [1122.2310],\n",
      "        [1113.6765],\n",
      "        [1269.2845]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 315.3000],\n",
      "        [  25.5000],\n",
      "        [2100.0000],\n",
      "        [1000.0000],\n",
      "        [4942.0000],\n",
      "        [1700.0000],\n",
      "        [ 995.5000],\n",
      "        [3300.0000],\n",
      "        [ 114.9000],\n",
      "        [ 239.1000],\n",
      "        [  12.7000],\n",
      "        [6500.0000],\n",
      "        [ 196.2000],\n",
      "        [1100.0000],\n",
      "        [  75.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([5, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([5, 1])): tensor([[1269.1796],\n",
      "        [1262.6633],\n",
      "        [1269.2343],\n",
      "        [1269.0627],\n",
      "        [1270.8151]])\n",
      "Target (shape: torch.Size([5, 1])): tensor([[1300.0000],\n",
      "        [ 370.3000],\n",
      "        [8947.0000],\n",
      "        [5217.0000],\n",
      "        [  38.7000]])\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 11/20, Train_Loss: 369943.39, Avg: 6850.80; Val_Loss: 58329.86, Avg: 4166.42\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1383.6173],\n",
      "        [1183.4858],\n",
      "        [1397.7412],\n",
      "        [1399.2430],\n",
      "        [1192.1050],\n",
      "        [1398.1957],\n",
      "        [1397.2712],\n",
      "        [1396.1251],\n",
      "        [1398.5406],\n",
      "        [1398.8230],\n",
      "        [1397.5413],\n",
      "        [1182.6630],\n",
      "        [1398.6104],\n",
      "        [1398.8256],\n",
      "        [1393.7281]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  462.4000],\n",
      "        [ 2100.0000],\n",
      "        [  413.8000],\n",
      "        [  855.7000],\n",
      "        [ 7500.0000],\n",
      "        [ 7100.0000],\n",
      "        [ 3700.0000],\n",
      "        [ 1100.0000],\n",
      "        [10300.0000],\n",
      "        [ 9000.0000],\n",
      "        [ 1400.0000],\n",
      "        [ 2200.0000],\n",
      "        [ 2000.0000],\n",
      "        [  178.4000],\n",
      "        [ 1400.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1396.7333],\n",
      "        [1184.6754],\n",
      "        [1194.8800],\n",
      "        [1393.2944],\n",
      "        [1395.9375],\n",
      "        [1398.7966],\n",
      "        [1393.5927],\n",
      "        [1398.9250],\n",
      "        [1196.7837],\n",
      "        [1393.6082],\n",
      "        [1373.3633],\n",
      "        [1345.6698],\n",
      "        [1394.0809],\n",
      "        [1398.0820],\n",
      "        [1398.3761]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.5000e+03],\n",
      "        [3.7000e+03],\n",
      "        [4.0000e+03],\n",
      "        [5.8910e+02],\n",
      "        [1.3200e+01],\n",
      "        [1.4800e+04],\n",
      "        [1.8300e+01],\n",
      "        [1.0600e+04],\n",
      "        [6.8000e+03],\n",
      "        [6.6910e+02],\n",
      "        [9.9100e+01],\n",
      "        [4.5700e+01],\n",
      "        [7.6100e+03],\n",
      "        [1.3000e+03],\n",
      "        [4.7000e+03]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1183.5797],\n",
      "        [1398.8438],\n",
      "        [1209.4132],\n",
      "        [1396.8020],\n",
      "        [1183.7446],\n",
      "        [1393.8042],\n",
      "        [1396.7772],\n",
      "        [1183.4696],\n",
      "        [1397.0465],\n",
      "        [1398.4670],\n",
      "        [1398.4984],\n",
      "        [1183.3542],\n",
      "        [1396.9670],\n",
      "        [1398.8090],\n",
      "        [1397.9185]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[3200.0000],\n",
      "        [8900.0000],\n",
      "        [  14.6000],\n",
      "        [5200.0000],\n",
      "        [ 369.8000],\n",
      "        [2324.0000],\n",
      "        [ 626.9000],\n",
      "        [  10.5000],\n",
      "        [1800.0000],\n",
      "        [ 118.0000],\n",
      "        [4200.0000],\n",
      "        [  10.3000],\n",
      "        [2000.0000],\n",
      "        [2400.0000],\n",
      "        [4600.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1398.9199],\n",
      "        [1398.7498],\n",
      "        [1394.0342],\n",
      "        [1396.7357],\n",
      "        [1396.7617],\n",
      "        [1183.4747],\n",
      "        [1396.8195],\n",
      "        [1393.0142],\n",
      "        [1399.0228],\n",
      "        [1182.7123],\n",
      "        [1398.0217],\n",
      "        [1398.1372],\n",
      "        [1397.0413],\n",
      "        [1377.6935],\n",
      "        [1393.7441]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 6000.0000],\n",
      "        [ 3180.0000],\n",
      "        [ 1900.0000],\n",
      "        [  153.6000],\n",
      "        [  514.3000],\n",
      "        [ 6245.0000],\n",
      "        [ 1100.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 1300.0000],\n",
      "        [  319.8000],\n",
      "        [ 1100.0000],\n",
      "        [  285.7000],\n",
      "        [15100.0000],\n",
      "        [ 4900.0000],\n",
      "        [ 1000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1202.8212],\n",
      "        [1397.0570],\n",
      "        [1397.0059],\n",
      "        [1183.7158],\n",
      "        [1181.2742],\n",
      "        [1394.6964],\n",
      "        [1396.7371],\n",
      "        [1395.9669],\n",
      "        [1398.4883],\n",
      "        [1281.5702],\n",
      "        [1398.5283],\n",
      "        [1399.1704],\n",
      "        [1398.5906],\n",
      "        [1398.7179],\n",
      "        [1395.7689]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.9250e+03],\n",
      "        [3.8750e+02],\n",
      "        [8.5900e+01],\n",
      "        [2.2000e+03],\n",
      "        [4.1000e+03],\n",
      "        [9.4000e+03],\n",
      "        [1.0600e+01],\n",
      "        [2.5000e+03],\n",
      "        [2.6700e+01],\n",
      "        [1.7920e+02],\n",
      "        [1.1400e+04],\n",
      "        [7.0000e+01],\n",
      "        [1.3330e+02],\n",
      "        [9.7100e+02],\n",
      "        [8.2500e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1398.4432],\n",
      "        [1181.1848],\n",
      "        [1397.5958],\n",
      "        [1396.7180],\n",
      "        [1398.6431],\n",
      "        [1397.3481],\n",
      "        [1398.5184],\n",
      "        [1399.4812],\n",
      "        [1397.1115],\n",
      "        [1396.7908],\n",
      "        [1395.8964],\n",
      "        [1393.1853],\n",
      "        [1398.8513],\n",
      "        [1398.4156],\n",
      "        [1398.7183]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  177.4000],\n",
      "        [ 1600.0000],\n",
      "        [ 3000.0000],\n",
      "        [ 2300.0000],\n",
      "        [ 4000.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5700.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 1800.0000],\n",
      "        [11500.0000],\n",
      "        [ 8800.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 6542.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 5000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1394.0271],\n",
      "        [1399.2737],\n",
      "        [1398.5627],\n",
      "        [1398.7019],\n",
      "        [1203.1252],\n",
      "        [1364.3236],\n",
      "        [1399.1091],\n",
      "        [1396.7426],\n",
      "        [1398.7679],\n",
      "        [1399.1343],\n",
      "        [1196.0337],\n",
      "        [1393.8523],\n",
      "        [1398.7831],\n",
      "        [1395.7190],\n",
      "        [1393.3912]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[19400.0000],\n",
      "        [12500.0000],\n",
      "        [  959.8000],\n",
      "        [  360.8000],\n",
      "        [ 1500.0000],\n",
      "        [  470.5000],\n",
      "        [12800.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 4400.0000],\n",
      "        [ 2500.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5400.0000],\n",
      "        [ 8500.0000],\n",
      "        [ 4600.0000],\n",
      "        [  233.7000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1398.6969],\n",
      "        [1398.7904],\n",
      "        [1396.7483],\n",
      "        [1398.9412],\n",
      "        [1398.7432],\n",
      "        [1398.7625],\n",
      "        [1398.6451],\n",
      "        [1398.4348],\n",
      "        [1193.2439],\n",
      "        [1397.0103],\n",
      "        [1304.5034],\n",
      "        [1397.0227],\n",
      "        [1380.3947],\n",
      "        [1398.6592],\n",
      "        [1398.4464]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.8900e+04],\n",
      "        [1.5000e+03],\n",
      "        [7.5080e+02],\n",
      "        [8.5110e+03],\n",
      "        [6.7000e+03],\n",
      "        [4.0000e+04],\n",
      "        [1.0900e+01],\n",
      "        [5.0890e+03],\n",
      "        [6.9900e+01],\n",
      "        [3.0000e+03],\n",
      "        [6.3700e+01],\n",
      "        [1.8200e+04],\n",
      "        [2.3300e+04],\n",
      "        [7.2000e+03],\n",
      "        [7.2190e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1398.7787],\n",
      "        [1393.8824],\n",
      "        [1396.7798],\n",
      "        [1397.0594],\n",
      "        [1394.1995],\n",
      "        [1204.5100],\n",
      "        [1281.7130],\n",
      "        [1399.2136],\n",
      "        [1183.6077],\n",
      "        [1398.2783],\n",
      "        [1398.8597],\n",
      "        [1398.7480],\n",
      "        [1344.5789],\n",
      "        [1366.6351],\n",
      "        [1183.5822]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 1200.0000],\n",
      "        [  220.3000],\n",
      "        [ 2100.0000],\n",
      "        [ 1600.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 9800.0000],\n",
      "        [ 9800.0000],\n",
      "        [  233.4000],\n",
      "        [ 3600.0000],\n",
      "        [ 4100.0000],\n",
      "        [  604.7000],\n",
      "        [ 3885.0000],\n",
      "        [31500.0000],\n",
      "        [ 3200.0000],\n",
      "        [  794.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1398.5000],\n",
      "        [1398.8655],\n",
      "        [1393.5608],\n",
      "        [1397.0620],\n",
      "        [1396.7341],\n",
      "        [1395.7427],\n",
      "        [1399.1022],\n",
      "        [1397.0154],\n",
      "        [1192.7855],\n",
      "        [1191.6848],\n",
      "        [1182.1768],\n",
      "        [1398.9093],\n",
      "        [1183.4803],\n",
      "        [1183.6283],\n",
      "        [1396.7571]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.1000e+03],\n",
      "        [2.2000e+03],\n",
      "        [4.3000e+03],\n",
      "        [6.5100e+02],\n",
      "        [9.1700e+01],\n",
      "        [1.5000e+03],\n",
      "        [6.7000e+01],\n",
      "        [2.2600e+04],\n",
      "        [2.1000e+03],\n",
      "        [5.7000e+03],\n",
      "        [1.4600e+04],\n",
      "        [1.8700e+01],\n",
      "        [2.7000e+03],\n",
      "        [5.5000e+01],\n",
      "        [6.6330e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1399.2688],\n",
      "        [1398.4321],\n",
      "        [1195.7703],\n",
      "        [1398.7891],\n",
      "        [1393.8145],\n",
      "        [1398.9919],\n",
      "        [1184.3611],\n",
      "        [1396.7435],\n",
      "        [1196.1877],\n",
      "        [1393.9038],\n",
      "        [1398.6096],\n",
      "        [1194.7471],\n",
      "        [1398.7417],\n",
      "        [1396.8041],\n",
      "        [1194.6034]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.0600e+02],\n",
      "        [1.1000e+03],\n",
      "        [9.4450e+02],\n",
      "        [2.9000e+03],\n",
      "        [1.6400e+04],\n",
      "        [4.6000e+03],\n",
      "        [7.0700e+04],\n",
      "        [7.9800e+01],\n",
      "        [1.2100e+04],\n",
      "        [9.3000e+03],\n",
      "        [7.0000e+03],\n",
      "        [1.9000e+01],\n",
      "        [3.9000e+03],\n",
      "        [3.8000e+03],\n",
      "        [1.9700e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1398.5627],\n",
      "        [1397.0569],\n",
      "        [1396.7994],\n",
      "        [1398.7527],\n",
      "        [1398.5568],\n",
      "        [1398.6990],\n",
      "        [1396.7246],\n",
      "        [1397.0271],\n",
      "        [1393.5546],\n",
      "        [1396.7341],\n",
      "        [1397.0237],\n",
      "        [1396.7224],\n",
      "        [1398.5994],\n",
      "        [1397.4535],\n",
      "        [1194.2323]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.8000e+03],\n",
      "        [2.0000e+03],\n",
      "        [5.4980e+02],\n",
      "        [1.8700e+04],\n",
      "        [4.1300e+01],\n",
      "        [2.6450e+02],\n",
      "        [3.9000e+03],\n",
      "        [1.0450e+02],\n",
      "        [7.7000e+03],\n",
      "        [1.6000e+01],\n",
      "        [5.8340e+03],\n",
      "        [3.7000e+03],\n",
      "        [3.1360e+02],\n",
      "        [2.3000e+03],\n",
      "        [1.3300e+01]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1398.6526],\n",
      "        [1398.8052],\n",
      "        [1397.4360],\n",
      "        [1396.7289],\n",
      "        [1396.7345],\n",
      "        [1398.9084],\n",
      "        [1184.1956],\n",
      "        [1399.2104],\n",
      "        [1347.7922],\n",
      "        [1393.7214],\n",
      "        [1398.8396],\n",
      "        [1396.7975],\n",
      "        [1393.7236],\n",
      "        [1376.9916],\n",
      "        [1398.6714]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 315.3000],\n",
      "        [  25.5000],\n",
      "        [2100.0000],\n",
      "        [1000.0000],\n",
      "        [4942.0000],\n",
      "        [1700.0000],\n",
      "        [ 995.5000],\n",
      "        [3300.0000],\n",
      "        [ 114.9000],\n",
      "        [ 239.1000],\n",
      "        [  12.7000],\n",
      "        [6500.0000],\n",
      "        [ 196.2000],\n",
      "        [1100.0000],\n",
      "        [  75.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([5, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([5, 1])): tensor([[1398.7861],\n",
      "        [1397.1243],\n",
      "        [1398.7385],\n",
      "        [1398.5828],\n",
      "        [1399.0502]])\n",
      "Target (shape: torch.Size([5, 1])): tensor([[1300.0000],\n",
      "        [ 370.3000],\n",
      "        [8947.0000],\n",
      "        [5217.0000],\n",
      "        [  38.7000]])\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 12/20, Train_Loss: 362119.39, Avg: 6705.91; Val_Loss: 57979.07, Avg: 4141.36\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1480.1766],\n",
      "        [1317.8571],\n",
      "        [1486.5055],\n",
      "        [1487.3204],\n",
      "        [1315.7589],\n",
      "        [1486.3429],\n",
      "        [1487.5497],\n",
      "        [1484.1080],\n",
      "        [1486.6422],\n",
      "        [1486.8251],\n",
      "        [1485.9598],\n",
      "        [1317.8038],\n",
      "        [1486.6665],\n",
      "        [1486.9476],\n",
      "        [1485.7814]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  462.4000],\n",
      "        [ 2100.0000],\n",
      "        [  413.8000],\n",
      "        [  855.7000],\n",
      "        [ 7500.0000],\n",
      "        [ 7100.0000],\n",
      "        [ 3700.0000],\n",
      "        [ 1100.0000],\n",
      "        [10300.0000],\n",
      "        [ 9000.0000],\n",
      "        [ 1400.0000],\n",
      "        [ 2200.0000],\n",
      "        [ 2000.0000],\n",
      "        [  178.4000],\n",
      "        [ 1400.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1487.4646],\n",
      "        [1317.5936],\n",
      "        [1316.4613],\n",
      "        [1485.5990],\n",
      "        [1483.6696],\n",
      "        [1486.8231],\n",
      "        [1485.6265],\n",
      "        [1486.7396],\n",
      "        [1317.9767],\n",
      "        [1485.7833],\n",
      "        [1479.0082],\n",
      "        [1478.3551],\n",
      "        [1485.5001],\n",
      "        [1486.3629],\n",
      "        [1486.4254]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.5000e+03],\n",
      "        [3.7000e+03],\n",
      "        [4.0000e+03],\n",
      "        [5.8910e+02],\n",
      "        [1.3200e+01],\n",
      "        [1.4800e+04],\n",
      "        [1.8300e+01],\n",
      "        [1.0600e+04],\n",
      "        [6.8000e+03],\n",
      "        [6.6910e+02],\n",
      "        [9.9100e+01],\n",
      "        [4.5700e+01],\n",
      "        [7.6100e+03],\n",
      "        [1.3000e+03],\n",
      "        [4.7000e+03]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1317.7914],\n",
      "        [1486.9259],\n",
      "        [1326.5758],\n",
      "        [1487.5000],\n",
      "        [1317.9525],\n",
      "        [1485.6591],\n",
      "        [1487.5179],\n",
      "        [1317.8121],\n",
      "        [1487.5402],\n",
      "        [1486.5179],\n",
      "        [1486.6632],\n",
      "        [1317.8741],\n",
      "        [1484.3661],\n",
      "        [1486.9589],\n",
      "        [1485.2869]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[3200.0000],\n",
      "        [8900.0000],\n",
      "        [  14.6000],\n",
      "        [5200.0000],\n",
      "        [ 369.8000],\n",
      "        [2324.0000],\n",
      "        [ 626.9000],\n",
      "        [  10.5000],\n",
      "        [1800.0000],\n",
      "        [ 118.0000],\n",
      "        [4200.0000],\n",
      "        [  10.3000],\n",
      "        [2000.0000],\n",
      "        [2400.0000],\n",
      "        [4600.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1486.7880],\n",
      "        [1486.8524],\n",
      "        [1485.3167],\n",
      "        [1487.4707],\n",
      "        [1487.4957],\n",
      "        [1317.7781],\n",
      "        [1487.4908],\n",
      "        [1485.0634],\n",
      "        [1486.9288],\n",
      "        [1317.6484],\n",
      "        [1486.4906],\n",
      "        [1486.2216],\n",
      "        [1487.5411],\n",
      "        [1477.1855],\n",
      "        [1485.1163]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 6000.0000],\n",
      "        [ 3180.0000],\n",
      "        [ 1900.0000],\n",
      "        [  153.6000],\n",
      "        [  514.3000],\n",
      "        [ 6245.0000],\n",
      "        [ 1100.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 1300.0000],\n",
      "        [  319.8000],\n",
      "        [ 1100.0000],\n",
      "        [  285.7000],\n",
      "        [15100.0000],\n",
      "        [ 4900.0000],\n",
      "        [ 1000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1321.2194],\n",
      "        [1487.5459],\n",
      "        [1487.5184],\n",
      "        [1317.8939],\n",
      "        [1314.3317],\n",
      "        [1485.8221],\n",
      "        [1487.4845],\n",
      "        [1482.6139],\n",
      "        [1486.6849],\n",
      "        [1469.9679],\n",
      "        [1486.4956],\n",
      "        [1486.6029],\n",
      "        [1486.8102],\n",
      "        [1486.6320],\n",
      "        [1482.1902]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.9250e+03],\n",
      "        [3.8750e+02],\n",
      "        [8.5900e+01],\n",
      "        [2.2000e+03],\n",
      "        [4.1000e+03],\n",
      "        [9.4000e+03],\n",
      "        [1.0600e+01],\n",
      "        [2.5000e+03],\n",
      "        [2.6700e+01],\n",
      "        [1.7920e+02],\n",
      "        [1.1400e+04],\n",
      "        [7.0000e+01],\n",
      "        [1.3330e+02],\n",
      "        [9.7100e+02],\n",
      "        [8.2500e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1486.8793],\n",
      "        [1314.2186],\n",
      "        [1487.5784],\n",
      "        [1487.4833],\n",
      "        [1486.8073],\n",
      "        [1487.2968],\n",
      "        [1486.2684],\n",
      "        [1485.9980],\n",
      "        [1487.5487],\n",
      "        [1487.5167],\n",
      "        [1483.3824],\n",
      "        [1485.5381],\n",
      "        [1486.8306],\n",
      "        [1486.7246],\n",
      "        [1486.8208]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  177.4000],\n",
      "        [ 1600.0000],\n",
      "        [ 3000.0000],\n",
      "        [ 2300.0000],\n",
      "        [ 4000.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5700.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 1800.0000],\n",
      "        [11500.0000],\n",
      "        [ 8800.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 6542.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 5000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1485.8313],\n",
      "        [1487.3018],\n",
      "        [1486.6779],\n",
      "        [1486.7780],\n",
      "        [1321.3877],\n",
      "        [1471.6758],\n",
      "        [1485.7211],\n",
      "        [1487.4235],\n",
      "        [1486.9130],\n",
      "        [1486.8483],\n",
      "        [1317.8777],\n",
      "        [1485.3464],\n",
      "        [1486.8070],\n",
      "        [1482.3788],\n",
      "        [1485.6366]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[19400.0000],\n",
      "        [12500.0000],\n",
      "        [  959.8000],\n",
      "        [  360.8000],\n",
      "        [ 1500.0000],\n",
      "        [  470.5000],\n",
      "        [12800.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 4400.0000],\n",
      "        [ 2500.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5400.0000],\n",
      "        [ 8500.0000],\n",
      "        [ 4600.0000],\n",
      "        [  233.7000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1486.8250],\n",
      "        [1486.9469],\n",
      "        [1487.4948],\n",
      "        [1486.8893],\n",
      "        [1486.8512],\n",
      "        [1486.8448],\n",
      "        [1486.7596],\n",
      "        [1486.6044],\n",
      "        [1316.2845],\n",
      "        [1487.5094],\n",
      "        [1485.0646],\n",
      "        [1487.5236],\n",
      "        [1459.2567],\n",
      "        [1486.8337],\n",
      "        [1486.5061]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.8900e+04],\n",
      "        [1.5000e+03],\n",
      "        [7.5080e+02],\n",
      "        [8.5110e+03],\n",
      "        [6.7000e+03],\n",
      "        [4.0000e+04],\n",
      "        [1.0900e+01],\n",
      "        [5.0890e+03],\n",
      "        [6.9900e+01],\n",
      "        [3.0000e+03],\n",
      "        [6.3700e+01],\n",
      "        [1.8200e+04],\n",
      "        [2.3300e+04],\n",
      "        [7.2000e+03],\n",
      "        [7.2190e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1486.8151],\n",
      "        [1485.2234],\n",
      "        [1487.4969],\n",
      "        [1487.5280],\n",
      "        [1485.3735],\n",
      "        [1321.4869],\n",
      "        [1445.2255],\n",
      "        [1486.9724],\n",
      "        [1318.1072],\n",
      "        [1486.6660],\n",
      "        [1486.7791],\n",
      "        [1486.9446],\n",
      "        [1485.1799],\n",
      "        [1468.1532],\n",
      "        [1317.8033]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 1200.0000],\n",
      "        [  220.3000],\n",
      "        [ 2100.0000],\n",
      "        [ 1600.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 9800.0000],\n",
      "        [ 9800.0000],\n",
      "        [  233.4000],\n",
      "        [ 3600.0000],\n",
      "        [ 4100.0000],\n",
      "        [  604.7000],\n",
      "        [ 3885.0000],\n",
      "        [31500.0000],\n",
      "        [ 3200.0000],\n",
      "        [  794.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1486.8118],\n",
      "        [1484.9574],\n",
      "        [1484.9642],\n",
      "        [1487.5707],\n",
      "        [1487.4850],\n",
      "        [1486.0648],\n",
      "        [1487.3705],\n",
      "        [1487.5162],\n",
      "        [1316.1085],\n",
      "        [1315.4437],\n",
      "        [1314.4795],\n",
      "        [1486.7810],\n",
      "        [1317.7681],\n",
      "        [1317.8606],\n",
      "        [1487.5085]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.1000e+03],\n",
      "        [2.2000e+03],\n",
      "        [4.3000e+03],\n",
      "        [6.5100e+02],\n",
      "        [9.1700e+01],\n",
      "        [1.5000e+03],\n",
      "        [6.7000e+01],\n",
      "        [2.2600e+04],\n",
      "        [2.1000e+03],\n",
      "        [5.7000e+03],\n",
      "        [1.4600e+04],\n",
      "        [1.8700e+01],\n",
      "        [2.7000e+03],\n",
      "        [5.5000e+01],\n",
      "        [6.6330e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1486.7009],\n",
      "        [1486.7550],\n",
      "        [1317.7169],\n",
      "        [1486.8475],\n",
      "        [1485.8978],\n",
      "        [1486.3993],\n",
      "        [1318.0348],\n",
      "        [1487.4913],\n",
      "        [1317.6829],\n",
      "        [1485.7390],\n",
      "        [1486.7411],\n",
      "        [1316.3936],\n",
      "        [1487.0018],\n",
      "        [1487.5150],\n",
      "        [1316.7902]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.0600e+02],\n",
      "        [1.1000e+03],\n",
      "        [9.4450e+02],\n",
      "        [2.9000e+03],\n",
      "        [1.6400e+04],\n",
      "        [4.6000e+03],\n",
      "        [7.0700e+04],\n",
      "        [7.9800e+01],\n",
      "        [1.2100e+04],\n",
      "        [9.3000e+03],\n",
      "        [7.0000e+03],\n",
      "        [1.9000e+01],\n",
      "        [3.9000e+03],\n",
      "        [3.8000e+03],\n",
      "        [1.9700e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1486.7548],\n",
      "        [1487.5369],\n",
      "        [1487.4977],\n",
      "        [1486.8334],\n",
      "        [1486.8319],\n",
      "        [1486.7474],\n",
      "        [1487.4879],\n",
      "        [1487.5189],\n",
      "        [1485.2609],\n",
      "        [1487.4696],\n",
      "        [1487.5118],\n",
      "        [1487.4677],\n",
      "        [1486.7632],\n",
      "        [1487.6957],\n",
      "        [1316.4602]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.8000e+03],\n",
      "        [2.0000e+03],\n",
      "        [5.4980e+02],\n",
      "        [1.8700e+04],\n",
      "        [4.1300e+01],\n",
      "        [2.6450e+02],\n",
      "        [3.9000e+03],\n",
      "        [1.0450e+02],\n",
      "        [7.7000e+03],\n",
      "        [1.6000e+01],\n",
      "        [5.8340e+03],\n",
      "        [3.7000e+03],\n",
      "        [3.1360e+02],\n",
      "        [2.3000e+03],\n",
      "        [1.3300e+01]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1486.7577],\n",
      "        [1486.9088],\n",
      "        [1485.9996],\n",
      "        [1487.4778],\n",
      "        [1487.4725],\n",
      "        [1486.8730],\n",
      "        [1318.1241],\n",
      "        [1487.2844],\n",
      "        [1485.1641],\n",
      "        [1486.1366],\n",
      "        [1487.0337],\n",
      "        [1487.4955],\n",
      "        [1485.8229],\n",
      "        [1461.7737],\n",
      "        [1486.6382]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 315.3000],\n",
      "        [  25.5000],\n",
      "        [2100.0000],\n",
      "        [1000.0000],\n",
      "        [4942.0000],\n",
      "        [1700.0000],\n",
      "        [ 995.5000],\n",
      "        [3300.0000],\n",
      "        [ 114.9000],\n",
      "        [ 239.1000],\n",
      "        [  12.7000],\n",
      "        [6500.0000],\n",
      "        [ 196.2000],\n",
      "        [1100.0000],\n",
      "        [  75.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([5, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([5, 1])): tensor([[1486.9457],\n",
      "        [1487.5673],\n",
      "        [1486.6448],\n",
      "        [1486.7500],\n",
      "        [1483.7478]])\n",
      "Target (shape: torch.Size([5, 1])): tensor([[1300.0000],\n",
      "        [ 370.3000],\n",
      "        [8947.0000],\n",
      "        [5217.0000],\n",
      "        [  38.7000]])\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 13/20, Train_Loss: 362972.01, Avg: 6721.70; Val_Loss: 57784.81, Avg: 4127.49\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1385.0264],\n",
      "        [1290.7561],\n",
      "        [1561.1199],\n",
      "        [1560.9218],\n",
      "        [1256.6104],\n",
      "        [1561.2764],\n",
      "        [1560.9446],\n",
      "        [1557.3826],\n",
      "        [1561.2056],\n",
      "        [1561.0905],\n",
      "        [1561.4722],\n",
      "        [1290.5210],\n",
      "        [1561.1743],\n",
      "        [1561.2373],\n",
      "        [1432.3132]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  462.4000],\n",
      "        [ 2100.0000],\n",
      "        [  413.8000],\n",
      "        [  855.7000],\n",
      "        [ 7500.0000],\n",
      "        [ 7100.0000],\n",
      "        [ 3700.0000],\n",
      "        [ 1100.0000],\n",
      "        [10300.0000],\n",
      "        [ 9000.0000],\n",
      "        [ 1400.0000],\n",
      "        [ 2200.0000],\n",
      "        [ 2000.0000],\n",
      "        [  178.4000],\n",
      "        [ 1400.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1560.4924],\n",
      "        [1290.5281],\n",
      "        [1256.8306],\n",
      "        [1436.9602],\n",
      "        [1558.4944],\n",
      "        [1561.3138],\n",
      "        [1432.5721],\n",
      "        [1561.2535],\n",
      "        [1258.0864],\n",
      "        [1438.0574],\n",
      "        [1375.0005],\n",
      "        [1452.0083],\n",
      "        [1441.5542],\n",
      "        [1561.2855],\n",
      "        [1561.3428]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.5000e+03],\n",
      "        [3.7000e+03],\n",
      "        [4.0000e+03],\n",
      "        [5.8910e+02],\n",
      "        [1.3200e+01],\n",
      "        [1.4800e+04],\n",
      "        [1.8300e+01],\n",
      "        [1.0600e+04],\n",
      "        [6.8000e+03],\n",
      "        [6.6910e+02],\n",
      "        [9.9100e+01],\n",
      "        [4.5700e+01],\n",
      "        [7.6100e+03],\n",
      "        [1.3000e+03],\n",
      "        [4.7000e+03]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1290.6744],\n",
      "        [1561.2965],\n",
      "        [1261.4724],\n",
      "        [1560.5519],\n",
      "        [1290.7850],\n",
      "        [1442.8951],\n",
      "        [1560.5095],\n",
      "        [1290.7097],\n",
      "        [1560.6746],\n",
      "        [1561.2905],\n",
      "        [1561.1431],\n",
      "        [1290.8044],\n",
      "        [1556.7457],\n",
      "        [1561.2394],\n",
      "        [1561.2260]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[3200.0000],\n",
      "        [8900.0000],\n",
      "        [  14.6000],\n",
      "        [5200.0000],\n",
      "        [ 369.8000],\n",
      "        [2324.0000],\n",
      "        [ 626.9000],\n",
      "        [  10.5000],\n",
      "        [1800.0000],\n",
      "        [ 118.0000],\n",
      "        [4200.0000],\n",
      "        [  10.3000],\n",
      "        [2000.0000],\n",
      "        [2400.0000],\n",
      "        [4600.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1561.2043],\n",
      "        [1561.0631],\n",
      "        [1423.3813],\n",
      "        [1560.4839],\n",
      "        [1560.5165],\n",
      "        [1290.6287],\n",
      "        [1560.5479],\n",
      "        [1465.3591],\n",
      "        [1561.2089],\n",
      "        [1290.7693],\n",
      "        [1561.1078],\n",
      "        [1561.4861],\n",
      "        [1560.6666],\n",
      "        [1423.8444],\n",
      "        [1424.3622]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 6000.0000],\n",
      "        [ 3180.0000],\n",
      "        [ 1900.0000],\n",
      "        [  153.6000],\n",
      "        [  514.3000],\n",
      "        [ 6245.0000],\n",
      "        [ 1100.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 1300.0000],\n",
      "        [  319.8000],\n",
      "        [ 1100.0000],\n",
      "        [  285.7000],\n",
      "        [15100.0000],\n",
      "        [ 4900.0000],\n",
      "        [ 1000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1260.4283],\n",
      "        [1560.6980],\n",
      "        [1560.6440],\n",
      "        [1290.7913],\n",
      "        [1287.3508],\n",
      "        [1472.9434],\n",
      "        [1560.5023],\n",
      "        [1558.6436],\n",
      "        [1561.0815],\n",
      "        [1468.4819],\n",
      "        [1561.2234],\n",
      "        [1561.4080],\n",
      "        [1561.0768],\n",
      "        [1561.2510],\n",
      "        [1559.5162]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.9250e+03],\n",
      "        [3.8750e+02],\n",
      "        [8.5900e+01],\n",
      "        [2.2000e+03],\n",
      "        [4.1000e+03],\n",
      "        [9.4000e+03],\n",
      "        [1.0600e+01],\n",
      "        [2.5000e+03],\n",
      "        [2.6700e+01],\n",
      "        [1.7920e+02],\n",
      "        [1.1400e+04],\n",
      "        [7.0000e+01],\n",
      "        [1.3330e+02],\n",
      "        [9.7100e+02],\n",
      "        [8.2500e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1561.2356],\n",
      "        [1287.3103],\n",
      "        [1562.5605],\n",
      "        [1560.4796],\n",
      "        [1561.0922],\n",
      "        [1561.0757],\n",
      "        [1561.3407],\n",
      "        [1561.9192],\n",
      "        [1560.7230],\n",
      "        [1560.5208],\n",
      "        [1558.6194],\n",
      "        [1442.3975],\n",
      "        [1561.2339],\n",
      "        [1561.0912],\n",
      "        [1561.0697]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  177.4000],\n",
      "        [ 1600.0000],\n",
      "        [ 3000.0000],\n",
      "        [ 2300.0000],\n",
      "        [ 4000.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5700.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 1800.0000],\n",
      "        [11500.0000],\n",
      "        [ 8800.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 6542.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 5000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1435.3593],\n",
      "        [1560.9260],\n",
      "        [1561.2815],\n",
      "        [1561.1924],\n",
      "        [1260.7490],\n",
      "        [1286.4938],\n",
      "        [1561.4652],\n",
      "        [1560.5425],\n",
      "        [1561.2729],\n",
      "        [1561.5923],\n",
      "        [1258.7490],\n",
      "        [1442.9816],\n",
      "        [1561.2206],\n",
      "        [1559.0522],\n",
      "        [1428.6140]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[19400.0000],\n",
      "        [12500.0000],\n",
      "        [  959.8000],\n",
      "        [  360.8000],\n",
      "        [ 1500.0000],\n",
      "        [  470.5000],\n",
      "        [12800.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 4400.0000],\n",
      "        [ 2500.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5400.0000],\n",
      "        [ 8500.0000],\n",
      "        [ 4600.0000],\n",
      "        [  233.7000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1561.2446],\n",
      "        [1561.0377],\n",
      "        [1560.5189],\n",
      "        [1561.0969],\n",
      "        [1561.0580],\n",
      "        [1561.0938],\n",
      "        [1561.2065],\n",
      "        [1561.1669],\n",
      "        [1256.8374],\n",
      "        [1560.6385],\n",
      "        [1466.2627],\n",
      "        [1560.6356],\n",
      "        [1356.9514],\n",
      "        [1561.1952],\n",
      "        [1561.5400]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.8900e+04],\n",
      "        [1.5000e+03],\n",
      "        [7.5080e+02],\n",
      "        [8.5110e+03],\n",
      "        [6.7000e+03],\n",
      "        [4.0000e+04],\n",
      "        [1.0900e+01],\n",
      "        [5.0890e+03],\n",
      "        [6.9900e+01],\n",
      "        [3.0000e+03],\n",
      "        [6.3700e+01],\n",
      "        [1.8200e+04],\n",
      "        [2.3300e+04],\n",
      "        [7.2000e+03],\n",
      "        [7.2190e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1561.1971],\n",
      "        [1423.4242],\n",
      "        [1560.4702],\n",
      "        [1560.6902],\n",
      "        [1424.1492],\n",
      "        [1260.6096],\n",
      "        [1333.3699],\n",
      "        [1561.1108],\n",
      "        [1291.0876],\n",
      "        [1560.9810],\n",
      "        [1561.2537],\n",
      "        [1561.2549],\n",
      "        [1490.7787],\n",
      "        [1367.9402],\n",
      "        [1290.6981]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 1200.0000],\n",
      "        [  220.3000],\n",
      "        [ 2100.0000],\n",
      "        [ 1600.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 9800.0000],\n",
      "        [ 9800.0000],\n",
      "        [  233.4000],\n",
      "        [ 3600.0000],\n",
      "        [ 4100.0000],\n",
      "        [  604.7000],\n",
      "        [ 3885.0000],\n",
      "        [31500.0000],\n",
      "        [ 3200.0000],\n",
      "        [  794.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1561.1157],\n",
      "        [1559.5996],\n",
      "        [1422.8542],\n",
      "        [1560.9637],\n",
      "        [1560.4631],\n",
      "        [1499.8972],\n",
      "        [1560.8667],\n",
      "        [1560.6538],\n",
      "        [1256.7400],\n",
      "        [1256.0072],\n",
      "        [1287.3630],\n",
      "        [1561.2955],\n",
      "        [1290.6774],\n",
      "        [1290.7208],\n",
      "        [1560.5162]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.1000e+03],\n",
      "        [2.2000e+03],\n",
      "        [4.3000e+03],\n",
      "        [6.5100e+02],\n",
      "        [9.1700e+01],\n",
      "        [1.5000e+03],\n",
      "        [6.7000e+01],\n",
      "        [2.2600e+04],\n",
      "        [2.1000e+03],\n",
      "        [5.7000e+03],\n",
      "        [1.4600e+04],\n",
      "        [1.8700e+01],\n",
      "        [2.7000e+03],\n",
      "        [5.5000e+01],\n",
      "        [6.6330e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1561.3916],\n",
      "        [1561.0764],\n",
      "        [1258.5649],\n",
      "        [1561.1226],\n",
      "        [1431.8499],\n",
      "        [1561.6626],\n",
      "        [1290.7393],\n",
      "        [1560.4938],\n",
      "        [1258.1981],\n",
      "        [1447.7031],\n",
      "        [1561.1469],\n",
      "        [1257.1133],\n",
      "        [1561.1776],\n",
      "        [1560.5509],\n",
      "        [1257.1064]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.0600e+02],\n",
      "        [1.1000e+03],\n",
      "        [9.4450e+02],\n",
      "        [2.9000e+03],\n",
      "        [1.6400e+04],\n",
      "        [4.6000e+03],\n",
      "        [7.0700e+04],\n",
      "        [7.9800e+01],\n",
      "        [1.2100e+04],\n",
      "        [9.3000e+03],\n",
      "        [7.0000e+03],\n",
      "        [1.9000e+01],\n",
      "        [3.9000e+03],\n",
      "        [3.8000e+03],\n",
      "        [1.9700e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1561.1655],\n",
      "        [1560.6663],\n",
      "        [1560.5315],\n",
      "        [1561.0885],\n",
      "        [1561.1113],\n",
      "        [1561.2094],\n",
      "        [1560.4565],\n",
      "        [1560.6433],\n",
      "        [1429.9500],\n",
      "        [1560.4917],\n",
      "        [1560.6672],\n",
      "        [1560.4661],\n",
      "        [1561.3376],\n",
      "        [1561.0428],\n",
      "        [1256.8679]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.8000e+03],\n",
      "        [2.0000e+03],\n",
      "        [5.4980e+02],\n",
      "        [1.8700e+04],\n",
      "        [4.1300e+01],\n",
      "        [2.6450e+02],\n",
      "        [3.9000e+03],\n",
      "        [1.0450e+02],\n",
      "        [7.7000e+03],\n",
      "        [1.6000e+01],\n",
      "        [5.8340e+03],\n",
      "        [3.7000e+03],\n",
      "        [3.1360e+02],\n",
      "        [2.3000e+03],\n",
      "        [1.3300e+01]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1561.1670],\n",
      "        [1561.2715],\n",
      "        [1561.4165],\n",
      "        [1560.4565],\n",
      "        [1560.5049],\n",
      "        [1561.1023],\n",
      "        [1291.1106],\n",
      "        [1560.9709],\n",
      "        [1506.0132],\n",
      "        [1454.1208],\n",
      "        [1561.3167],\n",
      "        [1560.5449],\n",
      "        [1432.3572],\n",
      "        [1340.6707],\n",
      "        [1561.2454]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 315.3000],\n",
      "        [  25.5000],\n",
      "        [2100.0000],\n",
      "        [1000.0000],\n",
      "        [4942.0000],\n",
      "        [1700.0000],\n",
      "        [ 995.5000],\n",
      "        [3300.0000],\n",
      "        [ 114.9000],\n",
      "        [ 239.1000],\n",
      "        [  12.7000],\n",
      "        [6500.0000],\n",
      "        [ 196.2000],\n",
      "        [1100.0000],\n",
      "        [  75.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([5, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([5, 1])): tensor([[1561.2404],\n",
      "        [1560.7532],\n",
      "        [1561.1681],\n",
      "        [1561.1152],\n",
      "        [1562.9297]])\n",
      "Target (shape: torch.Size([5, 1])): tensor([[1300.0000],\n",
      "        [ 370.3000],\n",
      "        [8947.0000],\n",
      "        [5217.0000],\n",
      "        [  38.7000]])\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 14/20, Train_Loss: 362852.04, Avg: 6719.48; Val_Loss: 57745.63, Avg: 4124.69\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1483.7952],\n",
      "        [1352.7592],\n",
      "        [1593.0861],\n",
      "        [1603.7561],\n",
      "        [1337.9683],\n",
      "        [1585.2898],\n",
      "        [1608.8486],\n",
      "        [1585.8853],\n",
      "        [1589.1211],\n",
      "        [1596.5387],\n",
      "        [1570.0214],\n",
      "        [1351.7607],\n",
      "        [1589.6317],\n",
      "        [1590.6260],\n",
      "        [1605.5048]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  462.4000],\n",
      "        [ 2100.0000],\n",
      "        [  413.8000],\n",
      "        [  855.7000],\n",
      "        [ 7500.0000],\n",
      "        [ 7100.0000],\n",
      "        [ 3700.0000],\n",
      "        [ 1100.0000],\n",
      "        [10300.0000],\n",
      "        [ 9000.0000],\n",
      "        [ 1400.0000],\n",
      "        [ 2200.0000],\n",
      "        [ 2000.0000],\n",
      "        [  178.4000],\n",
      "        [ 1400.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1609.0837],\n",
      "        [1353.7145],\n",
      "        [1342.7422],\n",
      "        [1605.0459],\n",
      "        [1583.4877],\n",
      "        [1585.0699],\n",
      "        [1604.7886],\n",
      "        [1591.2274],\n",
      "        [1341.1226],\n",
      "        [1605.3674],\n",
      "        [1487.2941],\n",
      "        [1514.4709],\n",
      "        [1605.7594],\n",
      "        [1586.2325],\n",
      "        [1576.0143]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.5000e+03],\n",
      "        [3.7000e+03],\n",
      "        [4.0000e+03],\n",
      "        [5.8910e+02],\n",
      "        [1.3200e+01],\n",
      "        [1.4800e+04],\n",
      "        [1.8300e+01],\n",
      "        [1.0600e+04],\n",
      "        [6.8000e+03],\n",
      "        [6.6910e+02],\n",
      "        [9.9100e+01],\n",
      "        [4.5700e+01],\n",
      "        [7.6100e+03],\n",
      "        [1.3000e+03],\n",
      "        [4.7000e+03]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1353.3806],\n",
      "        [1587.4441],\n",
      "        [1378.5940],\n",
      "        [1609.2224],\n",
      "        [1354.0762],\n",
      "        [1605.1731],\n",
      "        [1609.1329],\n",
      "        [1351.5842],\n",
      "        [1609.3563],\n",
      "        [1582.8159],\n",
      "        [1591.6567],\n",
      "        [1352.8113],\n",
      "        [1585.2416],\n",
      "        [1591.2179],\n",
      "        [1588.4650]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[3200.0000],\n",
      "        [8900.0000],\n",
      "        [  14.6000],\n",
      "        [5200.0000],\n",
      "        [ 369.8000],\n",
      "        [2324.0000],\n",
      "        [ 626.9000],\n",
      "        [  10.5000],\n",
      "        [1800.0000],\n",
      "        [ 118.0000],\n",
      "        [4200.0000],\n",
      "        [  10.3000],\n",
      "        [2000.0000],\n",
      "        [2400.0000],\n",
      "        [4600.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1592.9136],\n",
      "        [1597.5699],\n",
      "        [1604.9116],\n",
      "        [1609.1445],\n",
      "        [1609.1426],\n",
      "        [1352.5671],\n",
      "        [1609.2173],\n",
      "        [1605.6716],\n",
      "        [1593.4630],\n",
      "        [1350.8347],\n",
      "        [1593.3909],\n",
      "        [1579.9026],\n",
      "        [1609.3004],\n",
      "        [1553.6195],\n",
      "        [1604.8918]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 6000.0000],\n",
      "        [ 3180.0000],\n",
      "        [ 1900.0000],\n",
      "        [  153.6000],\n",
      "        [  514.3000],\n",
      "        [ 6245.0000],\n",
      "        [ 1100.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 1300.0000],\n",
      "        [  319.8000],\n",
      "        [ 1100.0000],\n",
      "        [  285.7000],\n",
      "        [15100.0000],\n",
      "        [ 4900.0000],\n",
      "        [ 1000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1350.3270],\n",
      "        [1609.2919],\n",
      "        [1609.3387],\n",
      "        [1352.6714],\n",
      "        [1342.8300],\n",
      "        [1599.9475],\n",
      "        [1609.1509],\n",
      "        [1584.5862],\n",
      "        [1593.0702],\n",
      "        [1525.1616],\n",
      "        [1581.5787],\n",
      "        [1585.2651],\n",
      "        [1597.1503],\n",
      "        [1594.1852],\n",
      "        [1578.7637]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.9250e+03],\n",
      "        [3.8750e+02],\n",
      "        [8.5900e+01],\n",
      "        [2.2000e+03],\n",
      "        [4.1000e+03],\n",
      "        [9.4000e+03],\n",
      "        [1.0600e+01],\n",
      "        [2.5000e+03],\n",
      "        [2.6700e+01],\n",
      "        [1.7920e+02],\n",
      "        [1.1400e+04],\n",
      "        [7.0000e+01],\n",
      "        [1.3330e+02],\n",
      "        [9.7100e+02],\n",
      "        [8.2500e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1592.1509],\n",
      "        [1346.6826],\n",
      "        [1596.4392],\n",
      "        [1609.1600],\n",
      "        [1596.3950],\n",
      "        [1602.8831],\n",
      "        [1586.7841],\n",
      "        [1586.6331],\n",
      "        [1609.1836],\n",
      "        [1609.2877],\n",
      "        [1586.8865],\n",
      "        [1604.8440],\n",
      "        [1591.9393],\n",
      "        [1597.3632],\n",
      "        [1597.4896]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  177.4000],\n",
      "        [ 1600.0000],\n",
      "        [ 3000.0000],\n",
      "        [ 2300.0000],\n",
      "        [ 4000.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5700.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 1800.0000],\n",
      "        [11500.0000],\n",
      "        [ 8800.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 6542.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 5000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1604.9634],\n",
      "        [1603.9199],\n",
      "        [1587.3091],\n",
      "        [1591.2543],\n",
      "        [1343.1914],\n",
      "        [1458.7733],\n",
      "        [1595.1150],\n",
      "        [1608.7771],\n",
      "        [1590.0723],\n",
      "        [1581.1678],\n",
      "        [1339.9495],\n",
      "        [1605.7085],\n",
      "        [1591.2589],\n",
      "        [1578.7338],\n",
      "        [1605.4279]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[19400.0000],\n",
      "        [12500.0000],\n",
      "        [  959.8000],\n",
      "        [  360.8000],\n",
      "        [ 1500.0000],\n",
      "        [  470.5000],\n",
      "        [12800.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 4400.0000],\n",
      "        [ 2500.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5400.0000],\n",
      "        [ 8500.0000],\n",
      "        [ 4600.0000],\n",
      "        [  233.7000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1584.8896],\n",
      "        [1598.4567],\n",
      "        [1609.1324],\n",
      "        [1597.4968],\n",
      "        [1597.6135],\n",
      "        [1597.3586],\n",
      "        [1592.3708],\n",
      "        [1590.7156],\n",
      "        [1341.2424],\n",
      "        [1609.3787],\n",
      "        [1597.8997],\n",
      "        [1609.3486],\n",
      "        [1521.0662],\n",
      "        [1589.6949],\n",
      "        [1573.8148]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.8900e+04],\n",
      "        [1.5000e+03],\n",
      "        [7.5080e+02],\n",
      "        [8.5110e+03],\n",
      "        [6.7000e+03],\n",
      "        [4.0000e+04],\n",
      "        [1.0900e+01],\n",
      "        [5.0890e+03],\n",
      "        [6.9900e+01],\n",
      "        [3.0000e+03],\n",
      "        [6.3700e+01],\n",
      "        [1.8200e+04],\n",
      "        [2.3300e+04],\n",
      "        [7.2000e+03],\n",
      "        [7.2190e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1591.6478],\n",
      "        [1603.6942],\n",
      "        [1608.6896],\n",
      "        [1609.2861],\n",
      "        [1604.9044],\n",
      "        [1343.8354],\n",
      "        [1507.0994],\n",
      "        [1598.2911],\n",
      "        [1352.6390],\n",
      "        [1597.0896],\n",
      "        [1590.5946],\n",
      "        [1588.6694],\n",
      "        [1602.2144],\n",
      "        [1517.1298],\n",
      "        [1352.5657]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 1200.0000],\n",
      "        [  220.3000],\n",
      "        [ 2100.0000],\n",
      "        [ 1600.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 9800.0000],\n",
      "        [ 9800.0000],\n",
      "        [  233.4000],\n",
      "        [ 3600.0000],\n",
      "        [ 4100.0000],\n",
      "        [  604.7000],\n",
      "        [ 3885.0000],\n",
      "        [31500.0000],\n",
      "        [ 3200.0000],\n",
      "        [  794.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1593.3776],\n",
      "        [1592.8558],\n",
      "        [1604.4807],\n",
      "        [1609.1196],\n",
      "        [1609.1810],\n",
      "        [1601.9398],\n",
      "        [1604.0343],\n",
      "        [1609.3418],\n",
      "        [1341.0513],\n",
      "        [1335.3967],\n",
      "        [1345.4849],\n",
      "        [1590.6825],\n",
      "        [1352.5969],\n",
      "        [1353.1337],\n",
      "        [1609.1820]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.1000e+03],\n",
      "        [2.2000e+03],\n",
      "        [4.3000e+03],\n",
      "        [6.5100e+02],\n",
      "        [9.1700e+01],\n",
      "        [1.5000e+03],\n",
      "        [6.7000e+01],\n",
      "        [2.2600e+04],\n",
      "        [2.1000e+03],\n",
      "        [5.7000e+03],\n",
      "        [1.4600e+04],\n",
      "        [1.8700e+01],\n",
      "        [2.7000e+03],\n",
      "        [5.5000e+01],\n",
      "        [6.6330e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1594.3676],\n",
      "        [1597.8213],\n",
      "        [1340.1949],\n",
      "        [1596.9919],\n",
      "        [1605.7865],\n",
      "        [1589.1274],\n",
      "        [1356.9766],\n",
      "        [1609.1685],\n",
      "        [1340.1760],\n",
      "        [1605.7355],\n",
      "        [1596.6339],\n",
      "        [1345.3799],\n",
      "        [1592.9750],\n",
      "        [1609.2389],\n",
      "        [1341.7743]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.0600e+02],\n",
      "        [1.1000e+03],\n",
      "        [9.4450e+02],\n",
      "        [2.9000e+03],\n",
      "        [1.6400e+04],\n",
      "        [4.6000e+03],\n",
      "        [7.0700e+04],\n",
      "        [7.9800e+01],\n",
      "        [1.2100e+04],\n",
      "        [9.3000e+03],\n",
      "        [7.0000e+03],\n",
      "        [1.9000e+01],\n",
      "        [3.9000e+03],\n",
      "        [3.8000e+03],\n",
      "        [1.9700e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1591.1501],\n",
      "        [1609.3477],\n",
      "        [1609.2369],\n",
      "        [1597.1387],\n",
      "        [1595.7109],\n",
      "        [1591.6257],\n",
      "        [1609.1218],\n",
      "        [1609.3560],\n",
      "        [1604.8661],\n",
      "        [1609.0901],\n",
      "        [1609.3049],\n",
      "        [1609.1682],\n",
      "        [1587.6493],\n",
      "        [1606.2686],\n",
      "        [1342.8937]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.8000e+03],\n",
      "        [2.0000e+03],\n",
      "        [5.4980e+02],\n",
      "        [1.8700e+04],\n",
      "        [4.1300e+01],\n",
      "        [2.6450e+02],\n",
      "        [3.9000e+03],\n",
      "        [1.0450e+02],\n",
      "        [7.7000e+03],\n",
      "        [1.6000e+01],\n",
      "        [5.8340e+03],\n",
      "        [3.7000e+03],\n",
      "        [3.1360e+02],\n",
      "        [2.3000e+03],\n",
      "        [1.3300e+01]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1592.6234],\n",
      "        [1587.5149],\n",
      "        [1581.8804],\n",
      "        [1609.1743],\n",
      "        [1609.0974],\n",
      "        [1596.7217],\n",
      "        [1354.6805],\n",
      "        [1603.4634],\n",
      "        [1597.8938],\n",
      "        [1604.3167],\n",
      "        [1586.4696],\n",
      "        [1609.2112],\n",
      "        [1605.5530],\n",
      "        [1508.9429],\n",
      "        [1588.3054]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 315.3000],\n",
      "        [  25.5000],\n",
      "        [2100.0000],\n",
      "        [1000.0000],\n",
      "        [4942.0000],\n",
      "        [1700.0000],\n",
      "        [ 995.5000],\n",
      "        [3300.0000],\n",
      "        [ 114.9000],\n",
      "        [ 239.1000],\n",
      "        [  12.7000],\n",
      "        [6500.0000],\n",
      "        [ 196.2000],\n",
      "        [1100.0000],\n",
      "        [  75.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([5, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([5, 1])): tensor([[1590.2771],\n",
      "        [1609.2456],\n",
      "        [1594.1514],\n",
      "        [1595.8652],\n",
      "        [1571.7904]])\n",
      "Target (shape: torch.Size([5, 1])): tensor([[1300.0000],\n",
      "        [ 370.3000],\n",
      "        [8947.0000],\n",
      "        [5217.0000],\n",
      "        [  38.7000]])\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 15/20, Train_Loss: 358006.03, Avg: 6629.74; Val_Loss: 57642.15, Avg: 4117.30\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1456.7847],\n",
      "        [1363.2820],\n",
      "        [1690.8082],\n",
      "        [1683.9133],\n",
      "        [1378.7637],\n",
      "        [1691.2485],\n",
      "        [1685.2625],\n",
      "        [1690.7197],\n",
      "        [1691.4094],\n",
      "        [1690.5205],\n",
      "        [1687.4124],\n",
      "        [1361.8596],\n",
      "        [1691.4048],\n",
      "        [1691.5164],\n",
      "        [1675.6980]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  462.4000],\n",
      "        [ 2100.0000],\n",
      "        [  413.8000],\n",
      "        [  855.7000],\n",
      "        [ 7500.0000],\n",
      "        [ 7100.0000],\n",
      "        [ 3700.0000],\n",
      "        [ 1100.0000],\n",
      "        [10300.0000],\n",
      "        [ 9000.0000],\n",
      "        [ 1400.0000],\n",
      "        [ 2200.0000],\n",
      "        [ 2000.0000],\n",
      "        [  178.4000],\n",
      "        [ 1400.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1682.6392],\n",
      "        [1362.2358],\n",
      "        [1382.2095],\n",
      "        [1672.8892],\n",
      "        [1690.7693],\n",
      "        [1691.3101],\n",
      "        [1672.8945],\n",
      "        [1691.5850],\n",
      "        [1378.6582],\n",
      "        [1675.7947],\n",
      "        [1463.1560],\n",
      "        [1486.4397],\n",
      "        [1666.7042],\n",
      "        [1691.0668],\n",
      "        [1690.9678]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.5000e+03],\n",
      "        [3.7000e+03],\n",
      "        [4.0000e+03],\n",
      "        [5.8910e+02],\n",
      "        [1.3200e+01],\n",
      "        [1.4800e+04],\n",
      "        [1.8300e+01],\n",
      "        [1.0600e+04],\n",
      "        [6.8000e+03],\n",
      "        [6.6910e+02],\n",
      "        [9.9100e+01],\n",
      "        [4.5700e+01],\n",
      "        [7.6100e+03],\n",
      "        [1.3000e+03],\n",
      "        [4.7000e+03]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1363.5847],\n",
      "        [1691.5347],\n",
      "        [1574.1201],\n",
      "        [1681.7290],\n",
      "        [1364.9844],\n",
      "        [1673.8103],\n",
      "        [1682.1860],\n",
      "        [1362.9841],\n",
      "        [1682.3281],\n",
      "        [1690.7849],\n",
      "        [1691.3425],\n",
      "        [1363.2957],\n",
      "        [1690.8234],\n",
      "        [1691.4697],\n",
      "        [1691.0143]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[3200.0000],\n",
      "        [8900.0000],\n",
      "        [  14.6000],\n",
      "        [5200.0000],\n",
      "        [ 369.8000],\n",
      "        [2324.0000],\n",
      "        [ 626.9000],\n",
      "        [  10.5000],\n",
      "        [1800.0000],\n",
      "        [ 118.0000],\n",
      "        [4200.0000],\n",
      "        [  10.3000],\n",
      "        [2000.0000],\n",
      "        [2400.0000],\n",
      "        [4600.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1691.4182],\n",
      "        [1690.5529],\n",
      "        [1660.1100],\n",
      "        [1682.3406],\n",
      "        [1682.3074],\n",
      "        [1362.6656],\n",
      "        [1681.6207],\n",
      "        [1656.0514],\n",
      "        [1691.2952],\n",
      "        [1357.7822],\n",
      "        [1691.0519],\n",
      "        [1690.4963],\n",
      "        [1682.4189],\n",
      "        [1550.6501],\n",
      "        [1658.9789]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 6000.0000],\n",
      "        [ 3180.0000],\n",
      "        [ 1900.0000],\n",
      "        [  153.6000],\n",
      "        [  514.3000],\n",
      "        [ 6245.0000],\n",
      "        [ 1100.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 1300.0000],\n",
      "        [  319.8000],\n",
      "        [ 1100.0000],\n",
      "        [  285.7000],\n",
      "        [15100.0000],\n",
      "        [ 4900.0000],\n",
      "        [ 1000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1385.3827],\n",
      "        [1682.7917],\n",
      "        [1682.0824],\n",
      "        [1362.0626],\n",
      "        [1279.1539],\n",
      "        [1688.7706],\n",
      "        [1681.9355],\n",
      "        [1690.8241],\n",
      "        [1691.3733],\n",
      "        [1549.4703],\n",
      "        [1691.0343],\n",
      "        [1691.3539],\n",
      "        [1690.4674],\n",
      "        [1690.9023],\n",
      "        [1689.9094]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.9250e+03],\n",
      "        [3.8750e+02],\n",
      "        [8.5900e+01],\n",
      "        [2.2000e+03],\n",
      "        [4.1000e+03],\n",
      "        [9.4000e+03],\n",
      "        [1.0600e+01],\n",
      "        [2.5000e+03],\n",
      "        [2.6700e+01],\n",
      "        [1.7920e+02],\n",
      "        [1.1400e+04],\n",
      "        [7.0000e+01],\n",
      "        [1.3330e+02],\n",
      "        [9.7100e+02],\n",
      "        [8.2500e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1691.3394],\n",
      "        [1279.1184],\n",
      "        [1522.9779],\n",
      "        [1682.1434],\n",
      "        [1690.3457],\n",
      "        [1671.2795],\n",
      "        [1691.1533],\n",
      "        [1691.0986],\n",
      "        [1683.0646],\n",
      "        [1681.2311],\n",
      "        [1690.5734],\n",
      "        [1673.0723],\n",
      "        [1691.5040],\n",
      "        [1690.3438],\n",
      "        [1690.4989]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  177.4000],\n",
      "        [ 1600.0000],\n",
      "        [ 3000.0000],\n",
      "        [ 2300.0000],\n",
      "        [ 4000.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5700.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 1800.0000],\n",
      "        [11500.0000],\n",
      "        [ 8800.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 6542.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 5000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1676.2914],\n",
      "        [1682.5300],\n",
      "        [1691.3953],\n",
      "        [1691.4773],\n",
      "        [1382.2521],\n",
      "        [1533.2104],\n",
      "        [1690.2570],\n",
      "        [1683.2612],\n",
      "        [1691.4739],\n",
      "        [1691.4590],\n",
      "        [1378.2856],\n",
      "        [1661.0471],\n",
      "        [1691.5188],\n",
      "        [1689.6614],\n",
      "        [1672.9482]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[19400.0000],\n",
      "        [12500.0000],\n",
      "        [  959.8000],\n",
      "        [  360.8000],\n",
      "        [ 1500.0000],\n",
      "        [  470.5000],\n",
      "        [12800.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 4400.0000],\n",
      "        [ 2500.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5400.0000],\n",
      "        [ 8500.0000],\n",
      "        [ 4600.0000],\n",
      "        [  233.7000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1691.4226],\n",
      "        [1690.0845],\n",
      "        [1682.3009],\n",
      "        [1690.5874],\n",
      "        [1690.4644],\n",
      "        [1690.5862],\n",
      "        [1691.4910],\n",
      "        [1691.3799],\n",
      "        [1379.9563],\n",
      "        [1682.1503],\n",
      "        [1689.3468],\n",
      "        [1682.0612],\n",
      "        [1546.1167],\n",
      "        [1691.4893],\n",
      "        [1689.9908]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.8900e+04],\n",
      "        [1.5000e+03],\n",
      "        [7.5080e+02],\n",
      "        [8.5110e+03],\n",
      "        [6.7000e+03],\n",
      "        [4.0000e+04],\n",
      "        [1.0900e+01],\n",
      "        [5.0890e+03],\n",
      "        [6.9900e+01],\n",
      "        [3.0000e+03],\n",
      "        [6.3700e+01],\n",
      "        [1.8200e+04],\n",
      "        [2.3300e+04],\n",
      "        [7.2000e+03],\n",
      "        [7.2190e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1691.3568],\n",
      "        [1662.1890],\n",
      "        [1682.5442],\n",
      "        [1682.7115],\n",
      "        [1662.2224],\n",
      "        [1381.9553],\n",
      "        [1540.6139],\n",
      "        [1690.2883],\n",
      "        [1362.3470],\n",
      "        [1690.1968],\n",
      "        [1691.5759],\n",
      "        [1691.4441],\n",
      "        [1684.1185],\n",
      "        [1552.8638],\n",
      "        [1362.1571]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 1200.0000],\n",
      "        [  220.3000],\n",
      "        [ 2100.0000],\n",
      "        [ 1600.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 9800.0000],\n",
      "        [ 9800.0000],\n",
      "        [  233.4000],\n",
      "        [ 3600.0000],\n",
      "        [ 4100.0000],\n",
      "        [  604.7000],\n",
      "        [ 3885.0000],\n",
      "        [31500.0000],\n",
      "        [ 3200.0000],\n",
      "        [  794.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1690.8845],\n",
      "        [1690.5669],\n",
      "        [1657.2037],\n",
      "        [1669.0793],\n",
      "        [1681.8530],\n",
      "        [1688.0266],\n",
      "        [1682.5645],\n",
      "        [1682.1991],\n",
      "        [1379.7898],\n",
      "        [1376.8627],\n",
      "        [1282.1709],\n",
      "        [1691.5514],\n",
      "        [1364.0363],\n",
      "        [1363.7555],\n",
      "        [1681.9680]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.1000e+03],\n",
      "        [2.2000e+03],\n",
      "        [4.3000e+03],\n",
      "        [6.5100e+02],\n",
      "        [9.1700e+01],\n",
      "        [1.5000e+03],\n",
      "        [6.7000e+01],\n",
      "        [2.2600e+04],\n",
      "        [2.1000e+03],\n",
      "        [5.7000e+03],\n",
      "        [1.4600e+04],\n",
      "        [1.8700e+01],\n",
      "        [2.7000e+03],\n",
      "        [5.5000e+01],\n",
      "        [6.6330e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1690.7883],\n",
      "        [1690.1858],\n",
      "        [1378.4917],\n",
      "        [1690.4594],\n",
      "        [1677.2308],\n",
      "        [1691.6292],\n",
      "        [1367.9990],\n",
      "        [1682.0229],\n",
      "        [1378.1306],\n",
      "        [1672.9170],\n",
      "        [1690.5481],\n",
      "        [1382.8167],\n",
      "        [1691.3926],\n",
      "        [1681.5765],\n",
      "        [1380.7756]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.0600e+02],\n",
      "        [1.1000e+03],\n",
      "        [9.4450e+02],\n",
      "        [2.9000e+03],\n",
      "        [1.6400e+04],\n",
      "        [4.6000e+03],\n",
      "        [7.0700e+04],\n",
      "        [7.9800e+01],\n",
      "        [1.2100e+04],\n",
      "        [9.3000e+03],\n",
      "        [7.0000e+03],\n",
      "        [1.9000e+01],\n",
      "        [3.9000e+03],\n",
      "        [3.8000e+03],\n",
      "        [1.9700e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1691.4574],\n",
      "        [1682.3284],\n",
      "        [1681.5474],\n",
      "        [1690.6440],\n",
      "        [1690.3429],\n",
      "        [1691.4204],\n",
      "        [1681.7483],\n",
      "        [1682.3521],\n",
      "        [1661.6361],\n",
      "        [1682.5243],\n",
      "        [1682.5818],\n",
      "        [1682.1714],\n",
      "        [1690.6417],\n",
      "        [1687.1138],\n",
      "        [1381.2350]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.8000e+03],\n",
      "        [2.0000e+03],\n",
      "        [5.4980e+02],\n",
      "        [1.8700e+04],\n",
      "        [4.1300e+01],\n",
      "        [2.6450e+02],\n",
      "        [3.9000e+03],\n",
      "        [1.0450e+02],\n",
      "        [7.7000e+03],\n",
      "        [1.6000e+01],\n",
      "        [5.8340e+03],\n",
      "        [3.7000e+03],\n",
      "        [3.1360e+02],\n",
      "        [2.3000e+03],\n",
      "        [1.3300e+01]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1691.4451],\n",
      "        [1691.5248],\n",
      "        [1690.6902],\n",
      "        [1682.0052],\n",
      "        [1682.5750],\n",
      "        [1690.3102],\n",
      "        [1365.0903],\n",
      "        [1683.4443],\n",
      "        [1689.7341],\n",
      "        [1683.2189],\n",
      "        [1691.3811],\n",
      "        [1681.9795],\n",
      "        [1677.4659],\n",
      "        [1556.9255],\n",
      "        [1691.4066]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 315.3000],\n",
      "        [  25.5000],\n",
      "        [2100.0000],\n",
      "        [1000.0000],\n",
      "        [4942.0000],\n",
      "        [1700.0000],\n",
      "        [ 995.5000],\n",
      "        [3300.0000],\n",
      "        [ 114.9000],\n",
      "        [ 239.1000],\n",
      "        [  12.7000],\n",
      "        [6500.0000],\n",
      "        [ 196.2000],\n",
      "        [1100.0000],\n",
      "        [  75.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([5, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([5, 1])): tensor([[1691.5277],\n",
      "        [1683.1920],\n",
      "        [1691.0615],\n",
      "        [1690.6289],\n",
      "        [1690.2307]])\n",
      "Target (shape: torch.Size([5, 1])): tensor([[1300.0000],\n",
      "        [ 370.3000],\n",
      "        [8947.0000],\n",
      "        [5217.0000],\n",
      "        [  38.7000]])\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 16/20, Train_Loss: 358140.55, Avg: 6632.23; Val_Loss: 57584.23, Avg: 4113.16\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1522.5748],\n",
      "        [1401.3824],\n",
      "        [1742.4818],\n",
      "        [1741.8492],\n",
      "        [1522.2317],\n",
      "        [1740.5126],\n",
      "        [1740.6292],\n",
      "        [1739.4884],\n",
      "        [1740.1490],\n",
      "        [1742.5839],\n",
      "        [1738.1486],\n",
      "        [1400.5809],\n",
      "        [1740.5966],\n",
      "        [1740.0487],\n",
      "        [1730.9158]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  462.4000],\n",
      "        [ 2100.0000],\n",
      "        [  413.8000],\n",
      "        [  855.7000],\n",
      "        [ 7500.0000],\n",
      "        [ 7100.0000],\n",
      "        [ 3700.0000],\n",
      "        [ 1100.0000],\n",
      "        [10300.0000],\n",
      "        [ 9000.0000],\n",
      "        [ 1400.0000],\n",
      "        [ 2200.0000],\n",
      "        [ 2000.0000],\n",
      "        [  178.4000],\n",
      "        [ 1400.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1743.2477],\n",
      "        [1395.6713],\n",
      "        [1512.7733],\n",
      "        [1728.8182],\n",
      "        [1739.6815],\n",
      "        [1738.2529],\n",
      "        [1722.4655],\n",
      "        [1740.6771],\n",
      "        [1553.7382],\n",
      "        [1731.8822],\n",
      "        [1522.3169],\n",
      "        [1506.4698],\n",
      "        [1730.1128],\n",
      "        [1741.2015],\n",
      "        [1739.2612]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.5000e+03],\n",
      "        [3.7000e+03],\n",
      "        [4.0000e+03],\n",
      "        [5.8910e+02],\n",
      "        [1.3200e+01],\n",
      "        [1.4800e+04],\n",
      "        [1.8300e+01],\n",
      "        [1.0600e+04],\n",
      "        [6.8000e+03],\n",
      "        [6.6910e+02],\n",
      "        [9.9100e+01],\n",
      "        [4.5700e+01],\n",
      "        [7.6100e+03],\n",
      "        [1.3000e+03],\n",
      "        [4.7000e+03]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1399.7931],\n",
      "        [1739.3114],\n",
      "        [1592.8668],\n",
      "        [1743.3253],\n",
      "        [1404.6898],\n",
      "        [1728.1375],\n",
      "        [1743.3951],\n",
      "        [1398.9869],\n",
      "        [1741.0593],\n",
      "        [1738.4551],\n",
      "        [1740.7372],\n",
      "        [1400.5927],\n",
      "        [1739.0638],\n",
      "        [1740.1940],\n",
      "        [1741.1489]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[3200.0000],\n",
      "        [8900.0000],\n",
      "        [  14.6000],\n",
      "        [5200.0000],\n",
      "        [ 369.8000],\n",
      "        [2324.0000],\n",
      "        [ 626.9000],\n",
      "        [  10.5000],\n",
      "        [1800.0000],\n",
      "        [ 118.0000],\n",
      "        [4200.0000],\n",
      "        [  10.3000],\n",
      "        [2000.0000],\n",
      "        [2400.0000],\n",
      "        [4600.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1741.9093],\n",
      "        [1742.3564],\n",
      "        [1728.2153],\n",
      "        [1743.2209],\n",
      "        [1743.3921],\n",
      "        [1401.0950],\n",
      "        [1743.0092],\n",
      "        [1730.5878],\n",
      "        [1741.5359],\n",
      "        [1392.7972],\n",
      "        [1741.8365],\n",
      "        [1739.8241],\n",
      "        [1741.2516],\n",
      "        [1516.1760],\n",
      "        [1728.6771]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 6000.0000],\n",
      "        [ 3180.0000],\n",
      "        [ 1900.0000],\n",
      "        [  153.6000],\n",
      "        [  514.3000],\n",
      "        [ 6245.0000],\n",
      "        [ 1100.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 1300.0000],\n",
      "        [  319.8000],\n",
      "        [ 1100.0000],\n",
      "        [  285.7000],\n",
      "        [15100.0000],\n",
      "        [ 4900.0000],\n",
      "        [ 1000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1696.6571],\n",
      "        [1740.7974],\n",
      "        [1741.4618],\n",
      "        [1399.7899],\n",
      "        [1371.5210],\n",
      "        [1547.5800],\n",
      "        [1743.2772],\n",
      "        [1738.9371],\n",
      "        [1740.9806],\n",
      "        [1585.0192],\n",
      "        [1740.2091],\n",
      "        [1739.1896],\n",
      "        [1742.5543],\n",
      "        [1742.7012],\n",
      "        [1739.0682]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.9250e+03],\n",
      "        [3.8750e+02],\n",
      "        [8.5900e+01],\n",
      "        [2.2000e+03],\n",
      "        [4.1000e+03],\n",
      "        [9.4000e+03],\n",
      "        [1.0600e+01],\n",
      "        [2.5000e+03],\n",
      "        [2.6700e+01],\n",
      "        [1.7920e+02],\n",
      "        [1.1400e+04],\n",
      "        [7.0000e+01],\n",
      "        [1.3330e+02],\n",
      "        [9.7100e+02],\n",
      "        [8.2500e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1740.2101],\n",
      "        [1376.2780],\n",
      "        [1740.2465],\n",
      "        [1743.2950],\n",
      "        [1742.5712],\n",
      "        [1739.9634],\n",
      "        [1739.9362],\n",
      "        [1741.5643],\n",
      "        [1740.8158],\n",
      "        [1743.3217],\n",
      "        [1740.2969],\n",
      "        [1728.5804],\n",
      "        [1740.8591],\n",
      "        [1742.6959],\n",
      "        [1742.5383]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  177.4000],\n",
      "        [ 1600.0000],\n",
      "        [ 3000.0000],\n",
      "        [ 2300.0000],\n",
      "        [ 4000.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5700.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 1800.0000],\n",
      "        [11500.0000],\n",
      "        [ 8800.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 6542.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 5000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1726.7031],\n",
      "        [1742.5455],\n",
      "        [1740.3987],\n",
      "        [1740.5455],\n",
      "        [1670.8495],\n",
      "        [1510.1122],\n",
      "        [1742.1785],\n",
      "        [1742.8781],\n",
      "        [1739.7367],\n",
      "        [1738.8195],\n",
      "        [1531.6960],\n",
      "        [1733.4912],\n",
      "        [1740.5476],\n",
      "        [1739.4850],\n",
      "        [1728.4054]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[19400.0000],\n",
      "        [12500.0000],\n",
      "        [  959.8000],\n",
      "        [  360.8000],\n",
      "        [ 1500.0000],\n",
      "        [  470.5000],\n",
      "        [12800.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 4400.0000],\n",
      "        [ 2500.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5400.0000],\n",
      "        [ 8500.0000],\n",
      "        [ 4600.0000],\n",
      "        [  233.7000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1739.6425],\n",
      "        [1742.7067],\n",
      "        [1743.3290],\n",
      "        [1742.6086],\n",
      "        [1742.4846],\n",
      "        [1742.4661],\n",
      "        [1740.4854],\n",
      "        [1740.3788],\n",
      "        [1534.8320],\n",
      "        [1741.2332],\n",
      "        [1503.2875],\n",
      "        [1741.2159],\n",
      "        [1541.3414],\n",
      "        [1740.1079],\n",
      "        [1738.7915]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.8900e+04],\n",
      "        [1.5000e+03],\n",
      "        [7.5080e+02],\n",
      "        [8.5110e+03],\n",
      "        [6.7000e+03],\n",
      "        [4.0000e+04],\n",
      "        [1.0900e+01],\n",
      "        [5.0890e+03],\n",
      "        [6.9900e+01],\n",
      "        [3.0000e+03],\n",
      "        [6.3700e+01],\n",
      "        [1.8200e+04],\n",
      "        [2.3300e+04],\n",
      "        [7.2000e+03],\n",
      "        [7.2190e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1740.8348],\n",
      "        [1724.3456],\n",
      "        [1742.3540],\n",
      "        [1741.0311],\n",
      "        [1728.2234],\n",
      "        [1671.2020],\n",
      "        [1531.2435],\n",
      "        [1742.4852],\n",
      "        [1403.0116],\n",
      "        [1742.3940],\n",
      "        [1740.2157],\n",
      "        [1740.3334],\n",
      "        [1546.8971],\n",
      "        [1546.2034],\n",
      "        [1401.3452]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 1200.0000],\n",
      "        [  220.3000],\n",
      "        [ 2100.0000],\n",
      "        [ 1600.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 9800.0000],\n",
      "        [ 9800.0000],\n",
      "        [  233.4000],\n",
      "        [ 3600.0000],\n",
      "        [ 4100.0000],\n",
      "        [  604.7000],\n",
      "        [ 3885.0000],\n",
      "        [31500.0000],\n",
      "        [ 3200.0000],\n",
      "        [  794.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1740.6749],\n",
      "        [1741.8953],\n",
      "        [1725.6941],\n",
      "        [1737.9121],\n",
      "        [1743.2368],\n",
      "        [1554.8728],\n",
      "        [1742.7869],\n",
      "        [1741.1667],\n",
      "        [1527.9781],\n",
      "        [1509.0386],\n",
      "        [1374.8528],\n",
      "        [1740.4401],\n",
      "        [1400.9357],\n",
      "        [1400.7981],\n",
      "        [1743.3713]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.1000e+03],\n",
      "        [2.2000e+03],\n",
      "        [4.3000e+03],\n",
      "        [6.5100e+02],\n",
      "        [9.1700e+01],\n",
      "        [1.5000e+03],\n",
      "        [6.7000e+01],\n",
      "        [2.2600e+04],\n",
      "        [2.1000e+03],\n",
      "        [5.7000e+03],\n",
      "        [1.4600e+04],\n",
      "        [1.8700e+01],\n",
      "        [2.7000e+03],\n",
      "        [5.5000e+01],\n",
      "        [6.6330e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1739.4838],\n",
      "        [1742.6724],\n",
      "        [1535.2039],\n",
      "        [1742.6124],\n",
      "        [1732.2225],\n",
      "        [1740.5594],\n",
      "        [1411.3479],\n",
      "        [1743.3773],\n",
      "        [1541.8593],\n",
      "        [1729.8424],\n",
      "        [1742.7712],\n",
      "        [1528.7462],\n",
      "        [1740.2609],\n",
      "        [1743.1741],\n",
      "        [1524.8390]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.0600e+02],\n",
      "        [1.1000e+03],\n",
      "        [9.4450e+02],\n",
      "        [2.9000e+03],\n",
      "        [1.6400e+04],\n",
      "        [4.6000e+03],\n",
      "        [7.0700e+04],\n",
      "        [7.9800e+01],\n",
      "        [1.2100e+04],\n",
      "        [9.3000e+03],\n",
      "        [7.0000e+03],\n",
      "        [1.9000e+01],\n",
      "        [3.9000e+03],\n",
      "        [3.8000e+03],\n",
      "        [1.9700e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1740.1080],\n",
      "        [1741.5818],\n",
      "        [1743.3109],\n",
      "        [1742.4790],\n",
      "        [1742.5624],\n",
      "        [1740.5990],\n",
      "        [1743.0902],\n",
      "        [1741.1147],\n",
      "        [1729.2487],\n",
      "        [1743.2019],\n",
      "        [1741.2220],\n",
      "        [1743.2941],\n",
      "        [1740.0143],\n",
      "        [1738.1616],\n",
      "        [1522.8624]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.8000e+03],\n",
      "        [2.0000e+03],\n",
      "        [5.4980e+02],\n",
      "        [1.8700e+04],\n",
      "        [4.1300e+01],\n",
      "        [2.6450e+02],\n",
      "        [3.9000e+03],\n",
      "        [1.0450e+02],\n",
      "        [7.7000e+03],\n",
      "        [1.6000e+01],\n",
      "        [5.8340e+03],\n",
      "        [3.7000e+03],\n",
      "        [3.1360e+02],\n",
      "        [2.3000e+03],\n",
      "        [1.3300e+01]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1740.7870],\n",
      "        [1740.0414],\n",
      "        [1741.9403],\n",
      "        [1743.2120],\n",
      "        [1743.2550],\n",
      "        [1742.4630],\n",
      "        [1401.4073],\n",
      "        [1741.8510],\n",
      "        [1520.5819],\n",
      "        [1625.2035],\n",
      "        [1738.9508],\n",
      "        [1743.3373],\n",
      "        [1731.2600],\n",
      "        [1615.0280],\n",
      "        [1741.4270]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 315.3000],\n",
      "        [  25.5000],\n",
      "        [2100.0000],\n",
      "        [1000.0000],\n",
      "        [4942.0000],\n",
      "        [1700.0000],\n",
      "        [ 995.5000],\n",
      "        [3300.0000],\n",
      "        [ 114.9000],\n",
      "        [ 239.1000],\n",
      "        [  12.7000],\n",
      "        [6500.0000],\n",
      "        [ 196.2000],\n",
      "        [1100.0000],\n",
      "        [  75.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([5, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([5, 1])): tensor([[1739.7400],\n",
      "        [1741.6711],\n",
      "        [1742.1786],\n",
      "        [1742.2909],\n",
      "        [1731.9437]])\n",
      "Target (shape: torch.Size([5, 1])): tensor([[1300.0000],\n",
      "        [ 370.3000],\n",
      "        [8947.0000],\n",
      "        [5217.0000],\n",
      "        [  38.7000]])\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 17/20, Train_Loss: 358639.67, Avg: 6641.48; Val_Loss: 57431.25, Avg: 4102.23\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1741.9287],\n",
      "        [1561.5599],\n",
      "        [1751.7649],\n",
      "        [1769.3201],\n",
      "        [1557.5737],\n",
      "        [1747.4725],\n",
      "        [1762.8685],\n",
      "        [1768.6031],\n",
      "        [1762.5718],\n",
      "        [1769.2998],\n",
      "        [1736.3640],\n",
      "        [1560.6377],\n",
      "        [1767.7003],\n",
      "        [1769.2715],\n",
      "        [1766.8239]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  462.4000],\n",
      "        [ 2100.0000],\n",
      "        [  413.8000],\n",
      "        [  855.7000],\n",
      "        [ 7500.0000],\n",
      "        [ 7100.0000],\n",
      "        [ 3700.0000],\n",
      "        [ 1100.0000],\n",
      "        [10300.0000],\n",
      "        [ 9000.0000],\n",
      "        [ 1400.0000],\n",
      "        [ 2200.0000],\n",
      "        [ 2000.0000],\n",
      "        [  178.4000],\n",
      "        [ 1400.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1762.6256],\n",
      "        [1560.4550],\n",
      "        [1556.7297],\n",
      "        [1766.4520],\n",
      "        [1763.1332],\n",
      "        [1767.4464],\n",
      "        [1767.1104],\n",
      "        [1765.9928],\n",
      "        [1557.8921],\n",
      "        [1766.3578],\n",
      "        [1735.9969],\n",
      "        [1600.9955],\n",
      "        [1767.9939],\n",
      "        [1750.8477],\n",
      "        [1746.2244]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.5000e+03],\n",
      "        [3.7000e+03],\n",
      "        [4.0000e+03],\n",
      "        [5.8910e+02],\n",
      "        [1.3200e+01],\n",
      "        [1.4800e+04],\n",
      "        [1.8300e+01],\n",
      "        [1.0600e+04],\n",
      "        [6.8000e+03],\n",
      "        [6.6910e+02],\n",
      "        [9.9100e+01],\n",
      "        [4.5700e+01],\n",
      "        [7.6100e+03],\n",
      "        [1.3000e+03],\n",
      "        [4.7000e+03]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1561.4391],\n",
      "        [1765.7349],\n",
      "        [1576.3334],\n",
      "        [1762.2418],\n",
      "        [1562.1342],\n",
      "        [1766.5033],\n",
      "        [1762.3931],\n",
      "        [1561.2377],\n",
      "        [1762.5333],\n",
      "        [1757.6433],\n",
      "        [1763.5367],\n",
      "        [1561.1779],\n",
      "        [1765.5768],\n",
      "        [1770.0165],\n",
      "        [1771.3989]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[3200.0000],\n",
      "        [8900.0000],\n",
      "        [  14.6000],\n",
      "        [5200.0000],\n",
      "        [ 369.8000],\n",
      "        [2324.0000],\n",
      "        [ 626.9000],\n",
      "        [  10.5000],\n",
      "        [1800.0000],\n",
      "        [ 118.0000],\n",
      "        [4200.0000],\n",
      "        [  10.3000],\n",
      "        [2000.0000],\n",
      "        [2400.0000],\n",
      "        [4600.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1765.6132],\n",
      "        [1772.8622],\n",
      "        [1768.0338],\n",
      "        [1762.6100],\n",
      "        [1762.2780],\n",
      "        [1561.4351],\n",
      "        [1762.3339],\n",
      "        [1767.9554],\n",
      "        [1768.7947],\n",
      "        [1560.8890],\n",
      "        [1761.4108],\n",
      "        [1743.6727],\n",
      "        [1762.6636],\n",
      "        [1770.6296],\n",
      "        [1768.0032]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 6000.0000],\n",
      "        [ 3180.0000],\n",
      "        [ 1900.0000],\n",
      "        [  153.6000],\n",
      "        [  514.3000],\n",
      "        [ 6245.0000],\n",
      "        [ 1100.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 1300.0000],\n",
      "        [  319.8000],\n",
      "        [ 1100.0000],\n",
      "        [  285.7000],\n",
      "        [15100.0000],\n",
      "        [ 4900.0000],\n",
      "        [ 1000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1564.8602],\n",
      "        [1762.6421],\n",
      "        [1762.3463],\n",
      "        [1560.8928],\n",
      "        [1557.8772],\n",
      "        [1767.9379],\n",
      "        [1762.1696],\n",
      "        [1770.5112],\n",
      "        [1767.3927],\n",
      "        [1749.7417],\n",
      "        [1748.8331],\n",
      "        [1764.1495],\n",
      "        [1770.7460],\n",
      "        [1762.2872],\n",
      "        [1730.7197]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.9250e+03],\n",
      "        [3.8750e+02],\n",
      "        [8.5900e+01],\n",
      "        [2.2000e+03],\n",
      "        [4.1000e+03],\n",
      "        [9.4000e+03],\n",
      "        [1.0600e+01],\n",
      "        [2.5000e+03],\n",
      "        [2.6700e+01],\n",
      "        [1.7920e+02],\n",
      "        [1.1400e+04],\n",
      "        [7.0000e+01],\n",
      "        [1.3330e+02],\n",
      "        [9.7100e+02],\n",
      "        [8.2500e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1769.9290],\n",
      "        [1558.7726],\n",
      "        [1762.5570],\n",
      "        [1762.4703],\n",
      "        [1768.7495],\n",
      "        [1763.7910],\n",
      "        [1763.6058],\n",
      "        [1766.1688],\n",
      "        [1762.8848],\n",
      "        [1762.1144],\n",
      "        [1769.5055],\n",
      "        [1766.3040],\n",
      "        [1767.2788],\n",
      "        [1765.1591],\n",
      "        [1772.2279]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  177.4000],\n",
      "        [ 1600.0000],\n",
      "        [ 3000.0000],\n",
      "        [ 2300.0000],\n",
      "        [ 4000.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5700.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 1800.0000],\n",
      "        [11500.0000],\n",
      "        [ 8800.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 6542.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 5000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1767.0272],\n",
      "        [1770.0131],\n",
      "        [1757.4369],\n",
      "        [1766.5275],\n",
      "        [1564.4906],\n",
      "        [1544.3944],\n",
      "        [1763.1512],\n",
      "        [1762.7207],\n",
      "        [1768.6853],\n",
      "        [1758.7023],\n",
      "        [1557.7856],\n",
      "        [1767.7150],\n",
      "        [1765.4073],\n",
      "        [1733.3463],\n",
      "        [1767.0153]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[19400.0000],\n",
      "        [12500.0000],\n",
      "        [  959.8000],\n",
      "        [  360.8000],\n",
      "        [ 1500.0000],\n",
      "        [  470.5000],\n",
      "        [12800.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 4400.0000],\n",
      "        [ 2500.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5400.0000],\n",
      "        [ 8500.0000],\n",
      "        [ 4600.0000],\n",
      "        [  233.7000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1758.6456],\n",
      "        [1773.2791],\n",
      "        [1762.2803],\n",
      "        [1771.3109],\n",
      "        [1772.5624],\n",
      "        [1772.4144],\n",
      "        [1768.0315],\n",
      "        [1763.8051],\n",
      "        [1558.1727],\n",
      "        [1762.5806],\n",
      "        [1768.3502],\n",
      "        [1762.6041],\n",
      "        [1712.1583],\n",
      "        [1767.4835],\n",
      "        [1745.4407]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.8900e+04],\n",
      "        [1.5000e+03],\n",
      "        [7.5080e+02],\n",
      "        [8.5110e+03],\n",
      "        [6.7000e+03],\n",
      "        [4.0000e+04],\n",
      "        [1.0900e+01],\n",
      "        [5.0890e+03],\n",
      "        [6.9900e+01],\n",
      "        [3.0000e+03],\n",
      "        [6.3700e+01],\n",
      "        [1.8200e+04],\n",
      "        [2.3300e+04],\n",
      "        [7.2000e+03],\n",
      "        [7.2190e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1764.7524],\n",
      "        [1768.3234],\n",
      "        [1763.0327],\n",
      "        [1762.5093],\n",
      "        [1768.0079],\n",
      "        [1564.3051],\n",
      "        [1678.7113],\n",
      "        [1773.9896],\n",
      "        [1561.9462],\n",
      "        [1773.1566],\n",
      "        [1765.2522],\n",
      "        [1765.4615],\n",
      "        [1768.4071],\n",
      "        [1732.1801],\n",
      "        [1561.4323]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 1200.0000],\n",
      "        [  220.3000],\n",
      "        [ 2100.0000],\n",
      "        [ 1600.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 9800.0000],\n",
      "        [ 9800.0000],\n",
      "        [  233.4000],\n",
      "        [ 3600.0000],\n",
      "        [ 4100.0000],\n",
      "        [  604.7000],\n",
      "        [ 3885.0000],\n",
      "        [31500.0000],\n",
      "        [ 3200.0000],\n",
      "        [  794.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1772.2257],\n",
      "        [1761.5404],\n",
      "        [1768.1605],\n",
      "        [1761.7726],\n",
      "        [1762.5640],\n",
      "        [1768.0701],\n",
      "        [1769.8646],\n",
      "        [1762.5514],\n",
      "        [1557.9175],\n",
      "        [1557.5903],\n",
      "        [1558.3704],\n",
      "        [1765.5892],\n",
      "        [1561.4059],\n",
      "        [1561.2944],\n",
      "        [1762.2756]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.1000e+03],\n",
      "        [2.2000e+03],\n",
      "        [4.3000e+03],\n",
      "        [6.5100e+02],\n",
      "        [9.1700e+01],\n",
      "        [1.5000e+03],\n",
      "        [6.7000e+01],\n",
      "        [2.2600e+04],\n",
      "        [2.1000e+03],\n",
      "        [5.7000e+03],\n",
      "        [1.4600e+04],\n",
      "        [1.8700e+01],\n",
      "        [2.7000e+03],\n",
      "        [5.5000e+01],\n",
      "        [6.6330e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1769.1376],\n",
      "        [1769.8118],\n",
      "        [1557.8129],\n",
      "        [1769.6027],\n",
      "        [1767.0492],\n",
      "        [1764.5570],\n",
      "        [1562.0546],\n",
      "        [1762.2421],\n",
      "        [1557.7797],\n",
      "        [1766.4615],\n",
      "        [1765.5553],\n",
      "        [1558.2040],\n",
      "        [1771.7628],\n",
      "        [1762.3215],\n",
      "        [1556.7964]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.0600e+02],\n",
      "        [1.1000e+03],\n",
      "        [9.4450e+02],\n",
      "        [2.9000e+03],\n",
      "        [1.6400e+04],\n",
      "        [4.6000e+03],\n",
      "        [7.0700e+04],\n",
      "        [7.9800e+01],\n",
      "        [1.2100e+04],\n",
      "        [9.3000e+03],\n",
      "        [7.0000e+03],\n",
      "        [1.9000e+01],\n",
      "        [3.9000e+03],\n",
      "        [3.8000e+03],\n",
      "        [1.9700e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1765.5632],\n",
      "        [1762.5936],\n",
      "        [1762.3114],\n",
      "        [1771.7448],\n",
      "        [1763.5930],\n",
      "        [1766.5177],\n",
      "        [1762.6710],\n",
      "        [1762.5800],\n",
      "        [1768.1445],\n",
      "        [1762.7054],\n",
      "        [1762.5341],\n",
      "        [1762.5139],\n",
      "        [1758.0607],\n",
      "        [1762.7279],\n",
      "        [1557.3602]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.8000e+03],\n",
      "        [2.0000e+03],\n",
      "        [5.4980e+02],\n",
      "        [1.8700e+04],\n",
      "        [4.1300e+01],\n",
      "        [2.6450e+02],\n",
      "        [3.9000e+03],\n",
      "        [1.0450e+02],\n",
      "        [7.7000e+03],\n",
      "        [1.6000e+01],\n",
      "        [5.8340e+03],\n",
      "        [3.7000e+03],\n",
      "        [3.1360e+02],\n",
      "        [2.3000e+03],\n",
      "        [1.3300e+01]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1768.6329],\n",
      "        [1766.6287],\n",
      "        [1729.3845],\n",
      "        [1762.5750],\n",
      "        [1762.6117],\n",
      "        [1768.8719],\n",
      "        [1560.9481],\n",
      "        [1769.5559],\n",
      "        [1768.0986],\n",
      "        [1768.1161],\n",
      "        [1767.0258],\n",
      "        [1762.4083],\n",
      "        [1766.9940],\n",
      "        [1726.0732],\n",
      "        [1759.0165]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 315.3000],\n",
      "        [  25.5000],\n",
      "        [2100.0000],\n",
      "        [1000.0000],\n",
      "        [4942.0000],\n",
      "        [1700.0000],\n",
      "        [ 995.5000],\n",
      "        [3300.0000],\n",
      "        [ 114.9000],\n",
      "        [ 239.1000],\n",
      "        [  12.7000],\n",
      "        [6500.0000],\n",
      "        [ 196.2000],\n",
      "        [1100.0000],\n",
      "        [  75.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([5, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([5, 1])): tensor([[1770.1495],\n",
      "        [1762.7422],\n",
      "        [1765.6493],\n",
      "        [1767.5863],\n",
      "        [1763.8237]])\n",
      "Target (shape: torch.Size([5, 1])): tensor([[1300.0000],\n",
      "        [ 370.3000],\n",
      "        [8947.0000],\n",
      "        [5217.0000],\n",
      "        [  38.7000]])\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 18/20, Train_Loss: 358850.06, Avg: 6645.37; Val_Loss: 57393.70, Avg: 4099.55\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1655.9082],\n",
      "        [1436.9762],\n",
      "        [1845.0200],\n",
      "        [1847.1122],\n",
      "        [1459.4911],\n",
      "        [1844.6069],\n",
      "        [1846.9268],\n",
      "        [1843.7930],\n",
      "        [1845.3943],\n",
      "        [1846.1786],\n",
      "        [1843.1123],\n",
      "        [1435.7057],\n",
      "        [1845.5959],\n",
      "        [1845.5983],\n",
      "        [1841.8058]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  462.4000],\n",
      "        [ 2100.0000],\n",
      "        [  413.8000],\n",
      "        [  855.7000],\n",
      "        [ 7500.0000],\n",
      "        [ 7100.0000],\n",
      "        [ 3700.0000],\n",
      "        [ 1100.0000],\n",
      "        [10300.0000],\n",
      "        [ 9000.0000],\n",
      "        [ 1400.0000],\n",
      "        [ 2200.0000],\n",
      "        [ 2000.0000],\n",
      "        [  178.4000],\n",
      "        [ 1400.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1846.7122],\n",
      "        [1434.3043],\n",
      "        [1458.3630],\n",
      "        [1841.8481],\n",
      "        [1842.8738],\n",
      "        [1845.2449],\n",
      "        [1841.0535],\n",
      "        [1845.4939],\n",
      "        [1462.0476],\n",
      "        [1842.2568],\n",
      "        [1652.7886],\n",
      "        [1517.0288],\n",
      "        [1831.3135],\n",
      "        [1844.5992],\n",
      "        [1844.4076]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.5000e+03],\n",
      "        [3.7000e+03],\n",
      "        [4.0000e+03],\n",
      "        [5.8910e+02],\n",
      "        [1.3200e+01],\n",
      "        [1.4800e+04],\n",
      "        [1.8300e+01],\n",
      "        [1.0600e+04],\n",
      "        [6.8000e+03],\n",
      "        [6.6910e+02],\n",
      "        [9.9100e+01],\n",
      "        [4.5700e+01],\n",
      "        [7.6100e+03],\n",
      "        [1.3000e+03],\n",
      "        [4.7000e+03]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1436.8031],\n",
      "        [1845.4253],\n",
      "        [1459.4247],\n",
      "        [1846.6733],\n",
      "        [1437.8662],\n",
      "        [1842.2029],\n",
      "        [1846.6693],\n",
      "        [1436.4832],\n",
      "        [1846.9705],\n",
      "        [1844.9585],\n",
      "        [1845.4698],\n",
      "        [1436.0720],\n",
      "        [1843.5491],\n",
      "        [1845.6547],\n",
      "        [1845.7582]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[3200.0000],\n",
      "        [8900.0000],\n",
      "        [  14.6000],\n",
      "        [5200.0000],\n",
      "        [ 369.8000],\n",
      "        [2324.0000],\n",
      "        [ 626.9000],\n",
      "        [  10.5000],\n",
      "        [1800.0000],\n",
      "        [ 118.0000],\n",
      "        [4200.0000],\n",
      "        [  10.3000],\n",
      "        [2000.0000],\n",
      "        [2400.0000],\n",
      "        [4600.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1845.5884],\n",
      "        [1846.2423],\n",
      "        [1822.7056],\n",
      "        [1846.6921],\n",
      "        [1846.6345],\n",
      "        [1437.1710],\n",
      "        [1846.6960],\n",
      "        [1832.0674],\n",
      "        [1845.8346],\n",
      "        [1436.9211],\n",
      "        [1845.5364],\n",
      "        [1844.0404],\n",
      "        [1846.9497],\n",
      "        [1646.0078],\n",
      "        [1824.5138]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 6000.0000],\n",
      "        [ 3180.0000],\n",
      "        [ 1900.0000],\n",
      "        [  153.6000],\n",
      "        [  514.3000],\n",
      "        [ 6245.0000],\n",
      "        [ 1100.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 1300.0000],\n",
      "        [  319.8000],\n",
      "        [ 1100.0000],\n",
      "        [  285.7000],\n",
      "        [15100.0000],\n",
      "        [ 4900.0000],\n",
      "        [ 1000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1477.7131],\n",
      "        [1846.9604],\n",
      "        [1846.9746],\n",
      "        [1436.0498],\n",
      "        [1432.3110],\n",
      "        [1831.4034],\n",
      "        [1846.6514],\n",
      "        [1843.4800],\n",
      "        [1845.6853],\n",
      "        [1698.5461],\n",
      "        [1844.6008],\n",
      "        [1845.1792],\n",
      "        [1846.1102],\n",
      "        [1845.5387],\n",
      "        [1838.3331]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.9250e+03],\n",
      "        [3.8750e+02],\n",
      "        [8.5900e+01],\n",
      "        [2.2000e+03],\n",
      "        [4.1000e+03],\n",
      "        [9.4000e+03],\n",
      "        [1.0600e+01],\n",
      "        [2.5000e+03],\n",
      "        [2.6700e+01],\n",
      "        [1.7920e+02],\n",
      "        [1.1400e+04],\n",
      "        [7.0000e+01],\n",
      "        [1.3330e+02],\n",
      "        [9.7100e+02],\n",
      "        [8.2500e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1845.6062],\n",
      "        [1432.7606],\n",
      "        [1846.6732],\n",
      "        [1846.6731],\n",
      "        [1846.1155],\n",
      "        [1846.5923],\n",
      "        [1845.2522],\n",
      "        [1845.6167],\n",
      "        [1846.9459],\n",
      "        [1846.6497],\n",
      "        [1844.3811],\n",
      "        [1843.2733],\n",
      "        [1845.6052],\n",
      "        [1846.0543],\n",
      "        [1846.2128]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  177.4000],\n",
      "        [ 1600.0000],\n",
      "        [ 3000.0000],\n",
      "        [ 2300.0000],\n",
      "        [ 4000.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5700.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 1800.0000],\n",
      "        [11500.0000],\n",
      "        [ 8800.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 6542.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 5000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1841.2723],\n",
      "        [1847.1528],\n",
      "        [1845.1887],\n",
      "        [1845.6477],\n",
      "        [1476.2472],\n",
      "        [1450.9730],\n",
      "        [1845.8243],\n",
      "        [1846.6722],\n",
      "        [1845.5621],\n",
      "        [1845.2646],\n",
      "        [1460.2031],\n",
      "        [1834.7134],\n",
      "        [1845.5831],\n",
      "        [1838.8322],\n",
      "        [1840.3103]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[19400.0000],\n",
      "        [12500.0000],\n",
      "        [  959.8000],\n",
      "        [  360.8000],\n",
      "        [ 1500.0000],\n",
      "        [  470.5000],\n",
      "        [12800.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 4400.0000],\n",
      "        [ 2500.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5400.0000],\n",
      "        [ 8500.0000],\n",
      "        [ 4600.0000],\n",
      "        [  233.7000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1845.0609],\n",
      "        [1846.4089],\n",
      "        [1846.6499],\n",
      "        [1846.2212],\n",
      "        [1846.2700],\n",
      "        [1846.2372],\n",
      "        [1845.6567],\n",
      "        [1845.3657],\n",
      "        [1461.2843],\n",
      "        [1846.9561],\n",
      "        [1818.7695],\n",
      "        [1846.9521],\n",
      "        [1736.7368],\n",
      "        [1845.4835],\n",
      "        [1844.1498]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.8900e+04],\n",
      "        [1.5000e+03],\n",
      "        [7.5080e+02],\n",
      "        [8.5110e+03],\n",
      "        [6.7000e+03],\n",
      "        [4.0000e+04],\n",
      "        [1.0900e+01],\n",
      "        [5.0890e+03],\n",
      "        [6.9900e+01],\n",
      "        [3.0000e+03],\n",
      "        [6.3700e+01],\n",
      "        [1.8200e+04],\n",
      "        [2.3300e+04],\n",
      "        [7.2000e+03],\n",
      "        [7.2190e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1845.6202],\n",
      "        [1820.3633],\n",
      "        [1846.7219],\n",
      "        [1846.9645],\n",
      "        [1825.5348],\n",
      "        [1476.4731],\n",
      "        [1590.0371],\n",
      "        [1846.4409],\n",
      "        [1437.1725],\n",
      "        [1846.2355],\n",
      "        [1845.5936],\n",
      "        [1845.3969],\n",
      "        [1830.8073],\n",
      "        [1495.9493],\n",
      "        [1436.6168]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 1200.0000],\n",
      "        [  220.3000],\n",
      "        [ 2100.0000],\n",
      "        [ 1600.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 9800.0000],\n",
      "        [ 9800.0000],\n",
      "        [  233.4000],\n",
      "        [ 3600.0000],\n",
      "        [ 4100.0000],\n",
      "        [  604.7000],\n",
      "        [ 3885.0000],\n",
      "        [31500.0000],\n",
      "        [ 3200.0000],\n",
      "        [  794.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1845.7985],\n",
      "        [1845.4268],\n",
      "        [1822.2783],\n",
      "        [1847.0796],\n",
      "        [1846.6919],\n",
      "        [1836.4114],\n",
      "        [1847.2046],\n",
      "        [1846.9535],\n",
      "        [1461.1074],\n",
      "        [1459.4915],\n",
      "        [1432.4675],\n",
      "        [1845.4657],\n",
      "        [1437.0537],\n",
      "        [1436.6700],\n",
      "        [1846.6617]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.1000e+03],\n",
      "        [2.2000e+03],\n",
      "        [4.3000e+03],\n",
      "        [6.5100e+02],\n",
      "        [9.1700e+01],\n",
      "        [1.5000e+03],\n",
      "        [6.7000e+01],\n",
      "        [2.2600e+04],\n",
      "        [2.1000e+03],\n",
      "        [5.7000e+03],\n",
      "        [1.4600e+04],\n",
      "        [1.8700e+01],\n",
      "        [2.7000e+03],\n",
      "        [5.5000e+01],\n",
      "        [6.6330e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1846.1901],\n",
      "        [1846.1659],\n",
      "        [1460.8391],\n",
      "        [1846.0972],\n",
      "        [1841.5093],\n",
      "        [1845.6537],\n",
      "        [1437.2957],\n",
      "        [1846.6453],\n",
      "        [1460.8420],\n",
      "        [1843.1757],\n",
      "        [1845.9963],\n",
      "        [1460.4021],\n",
      "        [1845.7385],\n",
      "        [1846.7216],\n",
      "        [1458.9034]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.0600e+02],\n",
      "        [1.1000e+03],\n",
      "        [9.4450e+02],\n",
      "        [2.9000e+03],\n",
      "        [1.6400e+04],\n",
      "        [4.6000e+03],\n",
      "        [7.0700e+04],\n",
      "        [7.9800e+01],\n",
      "        [1.2100e+04],\n",
      "        [9.3000e+03],\n",
      "        [7.0000e+03],\n",
      "        [1.9000e+01],\n",
      "        [3.9000e+03],\n",
      "        [3.8000e+03],\n",
      "        [1.9700e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1845.5754],\n",
      "        [1846.9574],\n",
      "        [1846.6760],\n",
      "        [1846.1526],\n",
      "        [1845.8717],\n",
      "        [1845.5884],\n",
      "        [1846.7065],\n",
      "        [1846.9631],\n",
      "        [1823.3320],\n",
      "        [1846.7012],\n",
      "        [1846.9492],\n",
      "        [1846.6827],\n",
      "        [1845.4567],\n",
      "        [1846.7307],\n",
      "        [1459.8829]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.8000e+03],\n",
      "        [2.0000e+03],\n",
      "        [5.4980e+02],\n",
      "        [1.8700e+04],\n",
      "        [4.1300e+01],\n",
      "        [2.6450e+02],\n",
      "        [3.9000e+03],\n",
      "        [1.0450e+02],\n",
      "        [7.7000e+03],\n",
      "        [1.6000e+01],\n",
      "        [5.8340e+03],\n",
      "        [3.7000e+03],\n",
      "        [3.1360e+02],\n",
      "        [2.3000e+03],\n",
      "        [1.3300e+01]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1845.7028],\n",
      "        [1845.3811],\n",
      "        [1843.3970],\n",
      "        [1846.6887],\n",
      "        [1846.7161],\n",
      "        [1846.1350],\n",
      "        [1435.8494],\n",
      "        [1847.1028],\n",
      "        [1822.6418],\n",
      "        [1829.5935],\n",
      "        [1845.3610],\n",
      "        [1846.6968],\n",
      "        [1841.4025],\n",
      "        [1701.9739],\n",
      "        [1845.3644]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 315.3000],\n",
      "        [  25.5000],\n",
      "        [2100.0000],\n",
      "        [1000.0000],\n",
      "        [4942.0000],\n",
      "        [1700.0000],\n",
      "        [ 995.5000],\n",
      "        [3300.0000],\n",
      "        [ 114.9000],\n",
      "        [ 239.1000],\n",
      "        [  12.7000],\n",
      "        [6500.0000],\n",
      "        [ 196.2000],\n",
      "        [1100.0000],\n",
      "        [  75.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([5, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([5, 1])): tensor([[1845.5857],\n",
      "        [1846.9498],\n",
      "        [1845.9668],\n",
      "        [1845.8557],\n",
      "        [1845.9115]])\n",
      "Target (shape: torch.Size([5, 1])): tensor([[1300.0000],\n",
      "        [ 370.3000],\n",
      "        [8947.0000],\n",
      "        [5217.0000],\n",
      "        [  38.7000]])\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 19/20, Train_Loss: 359704.48, Avg: 6661.19; Val_Loss: 57436.24, Avg: 4102.59\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1704.5531],\n",
      "        [1360.7706],\n",
      "        [1884.1571],\n",
      "        [1881.7169],\n",
      "        [1366.0587],\n",
      "        [1884.2759],\n",
      "        [1881.0571],\n",
      "        [1884.3956],\n",
      "        [1883.7614],\n",
      "        [1883.1263],\n",
      "        [1884.9896],\n",
      "        [1359.0809],\n",
      "        [1883.7462],\n",
      "        [1883.6973],\n",
      "        [1875.9238]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  462.4000],\n",
      "        [ 2100.0000],\n",
      "        [  413.8000],\n",
      "        [  855.7000],\n",
      "        [ 7500.0000],\n",
      "        [ 7100.0000],\n",
      "        [ 3700.0000],\n",
      "        [ 1100.0000],\n",
      "        [10300.0000],\n",
      "        [ 9000.0000],\n",
      "        [ 1400.0000],\n",
      "        [ 2200.0000],\n",
      "        [ 2000.0000],\n",
      "        [  178.4000],\n",
      "        [ 1400.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1880.4315],\n",
      "        [1359.2635],\n",
      "        [1366.8053],\n",
      "        [1871.8719],\n",
      "        [1884.7705],\n",
      "        [1884.0533],\n",
      "        [1861.0182],\n",
      "        [1883.8268],\n",
      "        [1366.7439],\n",
      "        [1874.9611],\n",
      "        [1494.6715],\n",
      "        [1546.9771],\n",
      "        [1385.7749],\n",
      "        [1884.3545],\n",
      "        [1884.3796]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.5000e+03],\n",
      "        [3.7000e+03],\n",
      "        [4.0000e+03],\n",
      "        [5.8910e+02],\n",
      "        [1.3200e+01],\n",
      "        [1.4800e+04],\n",
      "        [1.8300e+01],\n",
      "        [1.0600e+04],\n",
      "        [6.8000e+03],\n",
      "        [6.6910e+02],\n",
      "        [9.9100e+01],\n",
      "        [4.5700e+01],\n",
      "        [7.6100e+03],\n",
      "        [1.3000e+03],\n",
      "        [4.7000e+03]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1360.4795],\n",
      "        [1883.9138],\n",
      "        [1369.7230],\n",
      "        [1880.3304],\n",
      "        [1361.2831],\n",
      "        [1868.2909],\n",
      "        [1880.3428],\n",
      "        [1360.4462],\n",
      "        [1880.8087],\n",
      "        [1884.2260],\n",
      "        [1883.6456],\n",
      "        [1359.6790],\n",
      "        [1883.6702],\n",
      "        [1883.6687],\n",
      "        [1882.2616]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[3200.0000],\n",
      "        [8900.0000],\n",
      "        [  14.6000],\n",
      "        [5200.0000],\n",
      "        [ 369.8000],\n",
      "        [2324.0000],\n",
      "        [ 626.9000],\n",
      "        [  10.5000],\n",
      "        [1800.0000],\n",
      "        [ 118.0000],\n",
      "        [4200.0000],\n",
      "        [  10.3000],\n",
      "        [2000.0000],\n",
      "        [2400.0000],\n",
      "        [4600.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1883.7379],\n",
      "        [1882.8766],\n",
      "        [1386.2572],\n",
      "        [1880.4102],\n",
      "        [1880.2711],\n",
      "        [1360.7833],\n",
      "        [1880.4135],\n",
      "        [1389.0465],\n",
      "        [1883.4686],\n",
      "        [1360.4169],\n",
      "        [1883.5021],\n",
      "        [1884.6917],\n",
      "        [1880.8203],\n",
      "        [1852.7845],\n",
      "        [1385.5121]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 6000.0000],\n",
      "        [ 3180.0000],\n",
      "        [ 1900.0000],\n",
      "        [  153.6000],\n",
      "        [  514.3000],\n",
      "        [ 6245.0000],\n",
      "        [ 1100.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 1300.0000],\n",
      "        [  319.8000],\n",
      "        [ 1100.0000],\n",
      "        [  285.7000],\n",
      "        [15100.0000],\n",
      "        [ 4900.0000],\n",
      "        [ 1000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1370.3564],\n",
      "        [1880.8610],\n",
      "        [1880.7535],\n",
      "        [1359.5851],\n",
      "        [1363.9821],\n",
      "        [1872.0177],\n",
      "        [1880.2137],\n",
      "        [1884.5308],\n",
      "        [1883.5199],\n",
      "        [1743.7827],\n",
      "        [1884.4818],\n",
      "        [1883.4473],\n",
      "        [1883.0342],\n",
      "        [1883.7791],\n",
      "        [1885.4192]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.9250e+03],\n",
      "        [3.8750e+02],\n",
      "        [8.5900e+01],\n",
      "        [2.2000e+03],\n",
      "        [4.1000e+03],\n",
      "        [9.4000e+03],\n",
      "        [1.0600e+01],\n",
      "        [2.5000e+03],\n",
      "        [2.6700e+01],\n",
      "        [1.7920e+02],\n",
      "        [1.1400e+04],\n",
      "        [7.0000e+01],\n",
      "        [1.3330e+02],\n",
      "        [9.7100e+02],\n",
      "        [8.2500e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1883.5774],\n",
      "        [1363.1669],\n",
      "        [1881.5688],\n",
      "        [1880.3055],\n",
      "        [1883.0345],\n",
      "        [1880.9329],\n",
      "        [1883.9020],\n",
      "        [1882.8436],\n",
      "        [1880.9319],\n",
      "        [1880.2448],\n",
      "        [1883.4650],\n",
      "        [1875.0250],\n",
      "        [1883.5608],\n",
      "        [1883.1951],\n",
      "        [1882.9672]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[  177.4000],\n",
      "        [ 1600.0000],\n",
      "        [ 3000.0000],\n",
      "        [ 2300.0000],\n",
      "        [ 4000.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5700.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 1800.0000],\n",
      "        [11500.0000],\n",
      "        [ 8800.0000],\n",
      "        [ 3200.0000],\n",
      "        [ 6542.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 5000.0000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1874.3710],\n",
      "        [1881.7155],\n",
      "        [1884.3691],\n",
      "        [1883.5353],\n",
      "        [1369.6034],\n",
      "        [1385.3947],\n",
      "        [1883.1820],\n",
      "        [1880.3473],\n",
      "        [1883.7220],\n",
      "        [1883.8197],\n",
      "        [1365.8062],\n",
      "        [1388.7474],\n",
      "        [1883.6199],\n",
      "        [1885.4792],\n",
      "        [1873.3477]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[19400.0000],\n",
      "        [12500.0000],\n",
      "        [  959.8000],\n",
      "        [  360.8000],\n",
      "        [ 1500.0000],\n",
      "        [  470.5000],\n",
      "        [12800.0000],\n",
      "        [ 1200.0000],\n",
      "        [ 4400.0000],\n",
      "        [ 2500.0000],\n",
      "        [ 1900.0000],\n",
      "        [ 5400.0000],\n",
      "        [ 8500.0000],\n",
      "        [ 4600.0000],\n",
      "        [  233.7000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1884.4056],\n",
      "        [1882.8268],\n",
      "        [1880.2802],\n",
      "        [1883.0441],\n",
      "        [1882.8818],\n",
      "        [1882.9243],\n",
      "        [1883.5135],\n",
      "        [1883.5714],\n",
      "        [1366.8356],\n",
      "        [1880.7941],\n",
      "        [1726.0131],\n",
      "        [1880.7810],\n",
      "        [1857.5657],\n",
      "        [1883.8323],\n",
      "        [1884.7594]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[1.8900e+04],\n",
      "        [1.5000e+03],\n",
      "        [7.5080e+02],\n",
      "        [8.5110e+03],\n",
      "        [6.7000e+03],\n",
      "        [4.0000e+04],\n",
      "        [1.0900e+01],\n",
      "        [5.0890e+03],\n",
      "        [6.9900e+01],\n",
      "        [3.0000e+03],\n",
      "        [6.3700e+01],\n",
      "        [1.8200e+04],\n",
      "        [2.3300e+04],\n",
      "        [7.2000e+03],\n",
      "        [7.2190e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1883.6395],\n",
      "        [1386.9312],\n",
      "        [1880.5846],\n",
      "        [1880.8499],\n",
      "        [1385.5306],\n",
      "        [1369.9736],\n",
      "        [1507.5516],\n",
      "        [1882.6938],\n",
      "        [1361.2819],\n",
      "        [1882.9287],\n",
      "        [1883.8103],\n",
      "        [1884.0012],\n",
      "        [1750.9587],\n",
      "        [1721.5791],\n",
      "        [1359.9298]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 1200.0000],\n",
      "        [  220.3000],\n",
      "        [ 2100.0000],\n",
      "        [ 1600.0000],\n",
      "        [ 1700.0000],\n",
      "        [ 9800.0000],\n",
      "        [ 9800.0000],\n",
      "        [  233.4000],\n",
      "        [ 3600.0000],\n",
      "        [ 4100.0000],\n",
      "        [  604.7000],\n",
      "        [ 3885.0000],\n",
      "        [31500.0000],\n",
      "        [ 3200.0000],\n",
      "        [  794.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1883.2111],\n",
      "        [1882.5162],\n",
      "        [1385.8502],\n",
      "        [1881.1492],\n",
      "        [1880.3729],\n",
      "        [1873.9631],\n",
      "        [1881.6682],\n",
      "        [1880.7980],\n",
      "        [1366.7450],\n",
      "        [1366.3564],\n",
      "        [1363.9613],\n",
      "        [1883.6925],\n",
      "        [1361.0237],\n",
      "        [1360.7346],\n",
      "        [1880.2665]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.1000e+03],\n",
      "        [2.2000e+03],\n",
      "        [4.3000e+03],\n",
      "        [6.5100e+02],\n",
      "        [9.1700e+01],\n",
      "        [1.5000e+03],\n",
      "        [6.7000e+01],\n",
      "        [2.2600e+04],\n",
      "        [2.1000e+03],\n",
      "        [5.7000e+03],\n",
      "        [1.4600e+04],\n",
      "        [1.8700e+01],\n",
      "        [2.7000e+03],\n",
      "        [5.5000e+01],\n",
      "        [6.6330e+02]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1882.9137],\n",
      "        [1883.0529],\n",
      "        [1366.2035],\n",
      "        [1882.9309],\n",
      "        [1876.1122],\n",
      "        [1883.8573],\n",
      "        [1361.8722],\n",
      "        [1880.2972],\n",
      "        [1365.9028],\n",
      "        [1875.8707],\n",
      "        [1883.4460],\n",
      "        [1367.7186],\n",
      "        [1883.4508],\n",
      "        [1880.3635],\n",
      "        [1366.6890]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[9.0600e+02],\n",
      "        [1.1000e+03],\n",
      "        [9.4450e+02],\n",
      "        [2.9000e+03],\n",
      "        [1.6400e+04],\n",
      "        [4.6000e+03],\n",
      "        [7.0700e+04],\n",
      "        [7.9800e+01],\n",
      "        [1.2100e+04],\n",
      "        [9.3000e+03],\n",
      "        [7.0000e+03],\n",
      "        [1.9000e+01],\n",
      "        [3.9000e+03],\n",
      "        [3.8000e+03],\n",
      "        [1.9700e+04]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1883.6373],\n",
      "        [1880.8311],\n",
      "        [1880.3535],\n",
      "        [1882.9623],\n",
      "        [1883.5052],\n",
      "        [1883.4789],\n",
      "        [1880.3654],\n",
      "        [1880.8096],\n",
      "        [1386.2629],\n",
      "        [1880.4144],\n",
      "        [1880.8065],\n",
      "        [1880.3789],\n",
      "        [1883.3187],\n",
      "        [1881.1841],\n",
      "        [1367.6666]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[5.8000e+03],\n",
      "        [2.0000e+03],\n",
      "        [5.4980e+02],\n",
      "        [1.8700e+04],\n",
      "        [4.1300e+01],\n",
      "        [2.6450e+02],\n",
      "        [3.9000e+03],\n",
      "        [1.0450e+02],\n",
      "        [7.7000e+03],\n",
      "        [1.6000e+01],\n",
      "        [5.8340e+03],\n",
      "        [3.7000e+03],\n",
      "        [3.1360e+02],\n",
      "        [2.3000e+03],\n",
      "        [1.3300e+01]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([15, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([15, 1])): tensor([[1883.4376],\n",
      "        [1883.8910],\n",
      "        [1885.4026],\n",
      "        [1880.3738],\n",
      "        [1880.4136],\n",
      "        [1883.0841],\n",
      "        [1359.8932],\n",
      "        [1881.7375],\n",
      "        [1760.2286],\n",
      "        [1396.5450],\n",
      "        [1883.7347],\n",
      "        [1880.3838],\n",
      "        [1875.6732],\n",
      "        [1627.9890],\n",
      "        [1884.4773]])\n",
      "Target (shape: torch.Size([15, 1])): tensor([[ 315.3000],\n",
      "        [  25.5000],\n",
      "        [2100.0000],\n",
      "        [1000.0000],\n",
      "        [4942.0000],\n",
      "        [1700.0000],\n",
      "        [ 995.5000],\n",
      "        [3300.0000],\n",
      "        [ 114.9000],\n",
      "        [ 239.1000],\n",
      "        [  12.7000],\n",
      "        [6500.0000],\n",
      "        [ 196.2000],\n",
      "        [1100.0000],\n",
      "        [  75.1000]])\n",
      "\n",
      "\n",
      "Evaluating on batch with size: torch.Size([5, 3, 20, 128, 72])\n",
      "Model Output (shape: torch.Size([5, 1])): tensor([[1883.7075],\n",
      "        [1880.8842],\n",
      "        [1883.5262],\n",
      "        [1883.2228],\n",
      "        [1882.8220]])\n",
      "Target (shape: torch.Size([5, 1])): tensor([[1300.0000],\n",
      "        [ 370.3000],\n",
      "        [8947.0000],\n",
      "        [5217.0000],\n",
      "        [  38.7000]])\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 20/20, Train_Loss: 355958.30, Avg: 6591.82; Val_Loss: 57523.39, Avg: 4108.81\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, avg_train_loss = train(model, train_loader, criterion, optimizer, device, verbose=False)\n",
    "    \n",
    "    # model.train(mode=False)\n",
    "    val_loss, avg_val_loss = evaluate(model, val_loader, criterion, device, verbose=True)\n",
    "    \n",
    "    scheduler.step()\n",
    "    # record the losses\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    # print every num times epoch only\n",
    "    num = 1\n",
    "    if ((epoch+1) % num == 0) or epoch == 0:\n",
    "        if epoch == 0:\n",
    "            time_took = (time.time() - start_time) / 60\n",
    "            print(f'First epoch took {time_took:.1f} minutes.')\n",
    "        print(f'Epoch {epoch+1}/{EPOCHS}, Train_Loss: {train_loss:.2f}, Avg: {avg_train_loss:.2f}; Val_Loss: {val_loss:.2f}, Avg: {avg_val_loss:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model if better or not exists\n",
    "model_weights = {'model_state_dict': model.state_dict(), 'val_loss': avg_val_loss}\n",
    "weights_file = '../models/save/SWIN_weights.pt'\n",
    "if not os.path.isfile(weights_file):\n",
    "    # save new\n",
    "    torch.save(model_weights, weights_file)\n",
    "elif model_weights['val_loss'] < torch.load(weights_file)['val_loss']:\n",
    "    # replace\n",
    "    torch.save(model_weights, weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# lost plot\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to validation set\n",
    "val_values = []\n",
    "predicted_values = []\n",
    "\n",
    "for inputs, targets in val_loader:\n",
    "    model.eval()\n",
    "    inputs, targets = inputs.to(torch.float32).to(device), targets.to(torch.float32).to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # Append the values\n",
    "    val_values.extend(targets.tolist())\n",
    "    predicted_values.extend(outputs.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(range(len(val_values)), val_values, label='Test Values')\n",
    "plt.scatter(range(len(predicted_values)), predicted_values, label='Predicted Values')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Test vs Predicted Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test value: [462.3999938964844], Predicted Value: [1704.5531005859375]\n",
      "Test value: [2100.0], Predicted Value: [1360.7706298828125]\n",
      "Test value: [413.79998779296875], Predicted Value: [1884.1571044921875]\n",
      "Test value: [855.7000122070312], Predicted Value: [1881.7169189453125]\n",
      "Test value: [7500.0], Predicted Value: [1366.0587158203125]\n",
      "Test value: [7100.0], Predicted Value: [1884.27587890625]\n",
      "Test value: [3700.0], Predicted Value: [1881.05712890625]\n",
      "Test value: [1100.0], Predicted Value: [1884.3956298828125]\n",
      "Test value: [10300.0], Predicted Value: [1883.7613525390625]\n",
      "Test value: [9000.0], Predicted Value: [1883.1263427734375]\n",
      "Test value: [1400.0], Predicted Value: [1884.9896240234375]\n",
      "Test value: [2200.0], Predicted Value: [1359.0809326171875]\n",
      "Test value: [2000.0], Predicted Value: [1883.7462158203125]\n",
      "Test value: [178.39999389648438], Predicted Value: [1883.697265625]\n",
      "Test value: [1400.0], Predicted Value: [1875.923828125]\n",
      "Test value: [1500.0], Predicted Value: [1880.4315185546875]\n",
      "Test value: [3700.0], Predicted Value: [1359.2635498046875]\n",
      "Test value: [4000.0], Predicted Value: [1366.8052978515625]\n",
      "Test value: [589.0999755859375], Predicted Value: [1871.8719482421875]\n",
      "Test value: [13.199999809265137], Predicted Value: [1884.7705078125]\n",
      "Test value: [14800.0], Predicted Value: [1884.0533447265625]\n",
      "Test value: [18.299999237060547], Predicted Value: [1861.0181884765625]\n",
      "Test value: [10600.0], Predicted Value: [1883.8267822265625]\n",
      "Test value: [6800.0], Predicted Value: [1366.743896484375]\n",
      "Test value: [669.0999755859375], Predicted Value: [1874.9610595703125]\n",
      "Test value: [99.0999984741211], Predicted Value: [1494.6715087890625]\n",
      "Test value: [45.70000076293945], Predicted Value: [1546.97705078125]\n",
      "Test value: [7610.0], Predicted Value: [1385.77490234375]\n",
      "Test value: [1300.0], Predicted Value: [1884.3544921875]\n",
      "Test value: [4700.0], Predicted Value: [1884.379638671875]\n",
      "Test value: [3200.0], Predicted Value: [1360.4794921875]\n",
      "Test value: [8900.0], Predicted Value: [1883.913818359375]\n",
      "Test value: [14.600000381469727], Predicted Value: [1369.7230224609375]\n",
      "Test value: [5200.0], Predicted Value: [1880.3304443359375]\n",
      "Test value: [369.79998779296875], Predicted Value: [1361.2830810546875]\n",
      "Test value: [2324.0], Predicted Value: [1868.2908935546875]\n",
      "Test value: [626.9000244140625], Predicted Value: [1880.3427734375]\n",
      "Test value: [10.5], Predicted Value: [1360.4461669921875]\n",
      "Test value: [1800.0], Predicted Value: [1880.8087158203125]\n",
      "Test value: [118.0], Predicted Value: [1884.2259521484375]\n",
      "Test value: [4200.0], Predicted Value: [1883.6456298828125]\n",
      "Test value: [10.300000190734863], Predicted Value: [1359.678955078125]\n",
      "Test value: [2000.0], Predicted Value: [1883.670166015625]\n",
      "Test value: [2400.0], Predicted Value: [1883.668701171875]\n",
      "Test value: [4600.0], Predicted Value: [1882.2615966796875]\n",
      "Test value: [6000.0], Predicted Value: [1883.7379150390625]\n",
      "Test value: [3180.0], Predicted Value: [1882.8765869140625]\n",
      "Test value: [1900.0], Predicted Value: [1386.2572021484375]\n",
      "Test value: [153.60000610351562], Predicted Value: [1880.41015625]\n",
      "Test value: [514.2999877929688], Predicted Value: [1880.2711181640625]\n",
      "Test value: [6245.0], Predicted Value: [1360.7833251953125]\n",
      "Test value: [1100.0], Predicted Value: [1880.4134521484375]\n",
      "Test value: [1700.0], Predicted Value: [1389.0465087890625]\n",
      "Test value: [1300.0], Predicted Value: [1883.4686279296875]\n",
      "Test value: [319.79998779296875], Predicted Value: [1360.4168701171875]\n",
      "Test value: [1100.0], Predicted Value: [1883.5020751953125]\n",
      "Test value: [285.70001220703125], Predicted Value: [1884.691650390625]\n",
      "Test value: [15100.0], Predicted Value: [1880.8203125]\n",
      "Test value: [4900.0], Predicted Value: [1852.7845458984375]\n",
      "Test value: [1000.0], Predicted Value: [1385.5120849609375]\n",
      "Test value: [9925.0], Predicted Value: [1370.3564453125]\n",
      "Test value: [387.5], Predicted Value: [1880.8609619140625]\n",
      "Test value: [85.9000015258789], Predicted Value: [1880.7535400390625]\n",
      "Test value: [2200.0], Predicted Value: [1359.5850830078125]\n",
      "Test value: [4100.0], Predicted Value: [1363.9820556640625]\n",
      "Test value: [9400.0], Predicted Value: [1872.0177001953125]\n",
      "Test value: [10.600000381469727], Predicted Value: [1880.2137451171875]\n",
      "Test value: [2500.0], Predicted Value: [1884.53076171875]\n",
      "Test value: [26.700000762939453], Predicted Value: [1883.5198974609375]\n",
      "Test value: [179.1999969482422], Predicted Value: [1743.78271484375]\n",
      "Test value: [11400.0], Predicted Value: [1884.4818115234375]\n",
      "Test value: [70.0], Predicted Value: [1883.447265625]\n",
      "Test value: [133.3000030517578], Predicted Value: [1883.0341796875]\n",
      "Test value: [971.0], Predicted Value: [1883.779052734375]\n",
      "Test value: [82500.0], Predicted Value: [1885.419189453125]\n",
      "Test value: [177.39999389648438], Predicted Value: [1883.577392578125]\n",
      "Test value: [1600.0], Predicted Value: [1363.1668701171875]\n",
      "Test value: [3000.0], Predicted Value: [1881.56884765625]\n",
      "Test value: [2300.0], Predicted Value: [1880.3055419921875]\n",
      "Test value: [4000.0], Predicted Value: [1883.0345458984375]\n",
      "Test value: [1900.0], Predicted Value: [1880.932861328125]\n",
      "Test value: [5700.0], Predicted Value: [1883.9019775390625]\n",
      "Test value: [3200.0], Predicted Value: [1882.8436279296875]\n",
      "Test value: [1800.0], Predicted Value: [1880.931884765625]\n",
      "Test value: [11500.0], Predicted Value: [1880.2447509765625]\n",
      "Test value: [8800.0], Predicted Value: [1883.4649658203125]\n",
      "Test value: [3200.0], Predicted Value: [1875.0250244140625]\n",
      "Test value: [6542.0], Predicted Value: [1883.560791015625]\n",
      "Test value: [1200.0], Predicted Value: [1883.195068359375]\n",
      "Test value: [5000.0], Predicted Value: [1882.9671630859375]\n",
      "Test value: [19400.0], Predicted Value: [1874.3709716796875]\n",
      "Test value: [12500.0], Predicted Value: [1881.7154541015625]\n",
      "Test value: [959.7999877929688], Predicted Value: [1884.369140625]\n",
      "Test value: [360.79998779296875], Predicted Value: [1883.5352783203125]\n",
      "Test value: [1500.0], Predicted Value: [1369.6033935546875]\n",
      "Test value: [470.5], Predicted Value: [1385.3946533203125]\n",
      "Test value: [12800.0], Predicted Value: [1883.1820068359375]\n",
      "Test value: [1200.0], Predicted Value: [1880.3472900390625]\n",
      "Test value: [4400.0], Predicted Value: [1883.7220458984375]\n",
      "Test value: [2500.0], Predicted Value: [1883.8197021484375]\n",
      "Test value: [1900.0], Predicted Value: [1365.80615234375]\n",
      "Test value: [5400.0], Predicted Value: [1388.7474365234375]\n",
      "Test value: [8500.0], Predicted Value: [1883.619873046875]\n",
      "Test value: [4600.0], Predicted Value: [1885.479248046875]\n",
      "Test value: [233.6999969482422], Predicted Value: [1873.34765625]\n",
      "Test value: [18900.0], Predicted Value: [1884.4056396484375]\n",
      "Test value: [1500.0], Predicted Value: [1882.8267822265625]\n",
      "Test value: [750.7999877929688], Predicted Value: [1880.2801513671875]\n",
      "Test value: [8511.0], Predicted Value: [1883.0440673828125]\n",
      "Test value: [6700.0], Predicted Value: [1882.8818359375]\n",
      "Test value: [40000.0], Predicted Value: [1882.92431640625]\n",
      "Test value: [10.899999618530273], Predicted Value: [1883.5135498046875]\n",
      "Test value: [5089.0], Predicted Value: [1883.5714111328125]\n",
      "Test value: [69.9000015258789], Predicted Value: [1366.8355712890625]\n",
      "Test value: [3000.0], Predicted Value: [1880.7940673828125]\n",
      "Test value: [63.70000076293945], Predicted Value: [1726.0130615234375]\n",
      "Test value: [18200.0], Predicted Value: [1880.781005859375]\n",
      "Test value: [23300.0], Predicted Value: [1857.565673828125]\n",
      "Test value: [7200.0], Predicted Value: [1883.832275390625]\n",
      "Test value: [721.9000244140625], Predicted Value: [1884.7593994140625]\n",
      "Test value: [1200.0], Predicted Value: [1883.6395263671875]\n",
      "Test value: [220.3000030517578], Predicted Value: [1386.93115234375]\n",
      "Test value: [2100.0], Predicted Value: [1880.5845947265625]\n",
      "Test value: [1600.0], Predicted Value: [1880.849853515625]\n",
      "Test value: [1700.0], Predicted Value: [1385.5306396484375]\n",
      "Test value: [9800.0], Predicted Value: [1369.9736328125]\n",
      "Test value: [9800.0], Predicted Value: [1507.5516357421875]\n",
      "Test value: [233.39999389648438], Predicted Value: [1882.69384765625]\n",
      "Test value: [3600.0], Predicted Value: [1361.2818603515625]\n",
      "Test value: [4100.0], Predicted Value: [1882.9287109375]\n",
      "Test value: [604.7000122070312], Predicted Value: [1883.810302734375]\n",
      "Test value: [3885.0], Predicted Value: [1884.001220703125]\n",
      "Test value: [31500.0], Predicted Value: [1750.958740234375]\n",
      "Test value: [3200.0], Predicted Value: [1721.5791015625]\n",
      "Test value: [794.0999755859375], Predicted Value: [1359.9298095703125]\n",
      "Test value: [5100.0], Predicted Value: [1883.2110595703125]\n",
      "Test value: [2200.0], Predicted Value: [1882.5162353515625]\n",
      "Test value: [4300.0], Predicted Value: [1385.8502197265625]\n",
      "Test value: [651.0], Predicted Value: [1881.149169921875]\n",
      "Test value: [91.69999694824219], Predicted Value: [1880.3729248046875]\n",
      "Test value: [1500.0], Predicted Value: [1873.963134765625]\n",
      "Test value: [67.0], Predicted Value: [1881.668212890625]\n",
      "Test value: [22600.0], Predicted Value: [1880.7979736328125]\n",
      "Test value: [2100.0], Predicted Value: [1366.7449951171875]\n",
      "Test value: [5700.0], Predicted Value: [1366.3564453125]\n",
      "Test value: [14600.0], Predicted Value: [1363.9613037109375]\n",
      "Test value: [18.700000762939453], Predicted Value: [1883.6925048828125]\n",
      "Test value: [2700.0], Predicted Value: [1361.023681640625]\n",
      "Test value: [55.0], Predicted Value: [1360.734619140625]\n",
      "Test value: [663.2999877929688], Predicted Value: [1880.2664794921875]\n",
      "Test value: [906.0], Predicted Value: [1882.9136962890625]\n",
      "Test value: [1100.0], Predicted Value: [1883.0528564453125]\n",
      "Test value: [944.5], Predicted Value: [1366.2034912109375]\n",
      "Test value: [2900.0], Predicted Value: [1882.930908203125]\n",
      "Test value: [16400.0], Predicted Value: [1876.1121826171875]\n",
      "Test value: [4600.0], Predicted Value: [1883.8572998046875]\n",
      "Test value: [70700.0], Predicted Value: [1361.8721923828125]\n",
      "Test value: [79.80000305175781], Predicted Value: [1880.2972412109375]\n",
      "Test value: [12100.0], Predicted Value: [1365.90283203125]\n",
      "Test value: [9300.0], Predicted Value: [1875.8707275390625]\n",
      "Test value: [7000.0], Predicted Value: [1883.446044921875]\n",
      "Test value: [19.0], Predicted Value: [1367.7186279296875]\n",
      "Test value: [3900.0], Predicted Value: [1883.4508056640625]\n",
      "Test value: [3800.0], Predicted Value: [1880.363525390625]\n",
      "Test value: [19700.0], Predicted Value: [1366.68896484375]\n",
      "Test value: [5800.0], Predicted Value: [1883.6373291015625]\n",
      "Test value: [2000.0], Predicted Value: [1880.8310546875]\n",
      "Test value: [549.7999877929688], Predicted Value: [1880.353515625]\n",
      "Test value: [18700.0], Predicted Value: [1882.9622802734375]\n",
      "Test value: [41.29999923706055], Predicted Value: [1883.5052490234375]\n",
      "Test value: [264.5], Predicted Value: [1883.4788818359375]\n",
      "Test value: [3900.0], Predicted Value: [1880.3653564453125]\n",
      "Test value: [104.5], Predicted Value: [1880.8095703125]\n",
      "Test value: [7700.0], Predicted Value: [1386.262939453125]\n",
      "Test value: [16.0], Predicted Value: [1880.4144287109375]\n",
      "Test value: [5834.0], Predicted Value: [1880.8065185546875]\n",
      "Test value: [3700.0], Predicted Value: [1880.37890625]\n",
      "Test value: [313.6000061035156], Predicted Value: [1883.3187255859375]\n",
      "Test value: [2300.0], Predicted Value: [1881.18408203125]\n",
      "Test value: [13.300000190734863], Predicted Value: [1367.6666259765625]\n",
      "Test value: [315.29998779296875], Predicted Value: [1883.4376220703125]\n",
      "Test value: [25.5], Predicted Value: [1883.8909912109375]\n",
      "Test value: [2100.0], Predicted Value: [1885.402587890625]\n",
      "Test value: [1000.0], Predicted Value: [1880.373779296875]\n",
      "Test value: [4942.0], Predicted Value: [1880.41357421875]\n",
      "Test value: [1700.0], Predicted Value: [1883.0841064453125]\n",
      "Test value: [995.5], Predicted Value: [1359.8931884765625]\n",
      "Test value: [3300.0], Predicted Value: [1881.737548828125]\n",
      "Test value: [114.9000015258789], Predicted Value: [1760.2286376953125]\n",
      "Test value: [239.10000610351562], Predicted Value: [1396.5450439453125]\n",
      "Test value: [12.699999809265137], Predicted Value: [1883.7347412109375]\n",
      "Test value: [6500.0], Predicted Value: [1880.3837890625]\n",
      "Test value: [196.1999969482422], Predicted Value: [1875.6732177734375]\n",
      "Test value: [1100.0], Predicted Value: [1627.989013671875]\n",
      "Test value: [75.0999984741211], Predicted Value: [1884.477294921875]\n",
      "Test value: [1300.0], Predicted Value: [1883.70751953125]\n",
      "Test value: [370.29998779296875], Predicted Value: [1880.8841552734375]\n",
      "Test value: [8947.0], Predicted Value: [1883.5262451171875]\n",
      "Test value: [5217.0], Predicted Value: [1883.2227783203125]\n",
      "Test value: [38.70000076293945], Predicted Value: [1882.822021484375]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(predicted_values)):\n",
    "    print(f'Test value: {val_values[i]}, Predicted Value: {predicted_values[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4170.897338647843"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model_mae = np.absolute(np.subtract(val_values, predicted_values)).mean()\n",
    "model_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6154.229260564041"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_targets = []\n",
    "for inputs, targets in train_loader:\n",
    "    training_targets.extend([i.item() for i in targets])\n",
    "\n",
    "training_targets = np.array(training_targets)\n",
    "training_mean_as_prediction = training_targets.mean()\n",
    "training_mean_as_predicted_values = [training_mean_as_prediction for i in range(len(predicted_values))]\n",
    "training_mean_mae = np.absolute(np.subtract(val_values, training_mean_as_predicted_values)).mean()\n",
    "training_mean_mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mae < training_mean_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
